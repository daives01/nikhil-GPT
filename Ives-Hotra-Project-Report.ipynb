{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 445 Project Report: Nikhil-GPT, Machine Learning Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*by Daniel Ives and Kenny Hotra, May ??, 2023*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document is just a suggestion on how to structure your final project report.  You may choose to structure your report differently.\n",
    "\n",
    "At the end is a code cell that counts words for you.\n",
    "\n",
    "Do not include any of the text in this document, except possibly for the section headings, in your project report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What, why, very brief overview of methods and results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm very interested in the grammar, or lack thereof, used in tweets.  I will try to automatically recognize presidential tweets by counting occurrences of the word \"covfefe\"...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps I took.  Resources I used, such as code from the class, on-line resources, research articles, books [Goodfellow, et al., 2016], ....\n",
    "\n",
    "REQUIRED: If this is a team project, clearly describe in detail what each team member did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With no starting prompt, here are five samples that nikhil-GPT output with a maximum of 100 tokens:\n",
    "\n",
    "\n",
    "```\n",
    "Any questions about the policy. And you have your path so if I want it's a little bit. You want to handle a little bit data and an time to do this, you know, this for this. They're not going to be doing this is not going to be going to have a lot of different properties of the samples, and the value to be able to predict different weights that are actually always a single vector. So let's create the first one thing. And so that is the\n",
    "---------------\n",
    " we don't want to do to say I'm going to take the forward pass more what I'm not going to be going to be taking the training training data. So this is going to be my predictions, then the second layer. I'm going to show the 10 by two. So I see how I'm going to do we'll get this, I'm going to see that we can see this, and then I can also use the last class two, and then I'm going to be\n",
    "---------------\n",
    " I want to be able to do a bunch of study that if there's a three of things for each time, you can take the data kind of sort of say, which is the second set that you don't go to a lot of them that kind of a bunch of different of feature, you don't want to get to take like different types of training data which output or less complicated. And so you have to find a lot of training training data that you can use other things that of training\n",
    "---------------\n",
    " Just yeah, yeah, all, you know, you know, let's say, you know, you use the assignment two. So if I go through this, yes. So I'm going to put I'm just getting no different outcomes. So I'm getting something like this, you know, kind of say, finally, what I'm going to do is I'm going to start trying to be, I'm going to say, I can try to do that to see what you can do\n",
    "---------------\n",
    " Thanks, it's just not in a lecture. Yes. So you're not going to have a good job. You should be in time, but you got a couple of things like the project. So, that you're going to be able to look at this data. If you're going to use to keep in this data that. So you're going to keep in each time. And I'm just trying to do this functions as we'll show is, the value for this is that's\n",
    "---------------\n",
    "```\n",
    "With no starting prompt, here are five samples that nikhil-GPT output with a maximum of 100 tokens:\n",
    "\n",
    "\n",
    "```\n",
    "Any questions about the policy. And you have your path so if I want it's a little bit. You want to handle a little bit data and an time to do this, you know, this for this. They're not going to be doing this is not going to be going to have a lot of different properties of the samples, and the value to be able to predict different weights that are actually always a single vector. So let's create the first one thing. And so that is the\n",
    "\n",
    "we don't want to do to say I'm going to take the forward pass more what I'm not going to be going to be taking the training training data. So this is going to be my predictions, then the second layer. I'm going to show the 10 by two. So I see how I'm going to do we'll get this, I'm going to see that we can see this, and then I can also use the last class two, and then I'm going to be\n",
    "\n",
    "I want to be able to do a bunch of study that if there's a three of things for each time, you can take the data kind of sort of say, which is the second set that you don't go to a lot of them that kind of a bunch of different of feature, you don't want to get to take like different types of training data which output or less complicated. And so you have to find a lot of training training data that you can use other things that of training\n",
    "\n",
    "Just yeah, yeah, all, you know, you know, let's say, you know, you use the assignment two. So if I go through this, yes. So I'm going to put I'm just getting no different outcomes. So I'm getting something like this, you know, kind of say, finally, what I'm going to do is I'm going to start trying to be, I'm going to say, I can try to do that to see what you can do\n",
    "\n",
    "Thanks, it's just not in a lecture. Yes. So you're not going to have a good job. You should be in time, but you got a couple of things like the project. So, that you're going to be able to look at this data. If you're going to use to keep in this data that. So you're going to keep in each time. And I'm just trying to do this functions as we'll show is, the value for this is that's\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell downloads a zip file of our model weights and code to try out the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://github.com/daives01/nikhil-GPT/raw/main/tryNikhilGPT.zip\n",
    "! unzip tryNikhilGPT.zip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you downloaded and unzipped in the same directory, and have the python dependencies installed, you can run the following code cells to try out the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to adjust some parameters here\n",
    "num_samples = 5 # number of samples to generate\n",
    "max_new_tokens = 100 # maximum number of tokens to generate\n",
    "temperature = 0.8 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions\n",
    "top_k = 200 # retain only the top_k most likely tokens, clamp others to have 0 probability\n",
    "seed = 1337"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell runs the model with no starting prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 sample.py --out_dir=out-nikhil-gpt-final_clean --num_samples=$num_samples --max_new_tokens=$max_new_tokens --temperature=$temperature --top_k=$top_k --seed=$seed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell runs the model with a starting prompt of your choosing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user input\n",
    "prompt = input(\"Enter a prompt: \")\n",
    "\n",
    "# Generate text\n",
    "! python3 sample.py --start=\"$prompt\" --out_dir=out-nikhil-gpt-final_clean --num_samples=$num_samples --max_new_tokens=$max_new_tokens --temperature=$temperature --top_k=$top_k --seed=$seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I learned.  What was difficult.  Changes I had to make to timeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Your report for a single person team should contain **approximately** 2,000 words times number of team members, in markdown cells.  You can count words by running the following python code in your report directory.  Projects with two people, for example, should contain about 4,000 words, a four-person team should submit a report of approximately 8,000 words.\n",
    "\n",
    "Of course, your results and analysis speak much more than the word count.  Deep analysis in a shorter form is better than vague, over-wordy non-analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count for file Ives-Hotra-Project-Report.ipynb is 254\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from nbformat import current\n",
    "import glob\n",
    "nbfile = glob.glob('Ives-Hotra-Project-Report.ipynb')\n",
    "if len(nbfile) > 1:\n",
    "    print('More than one ipynb file. Using the first one.  nbfile=', nbfile)\n",
    "with io.open(nbfile[0], 'r', encoding='utf-8') as f:\n",
    "    nb = current.read(f, 'json')\n",
    "word_count = 0\n",
    "for cell in nb.worksheets[0].cells:\n",
    "    if cell.cell_type == \"markdown\":\n",
    "        word_count += len(cell['source'].replace('#', '').lstrip().split(' '))\n",
    "print('Word count for file', nbfile[0], 'is', word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
