 Okay, let's get started. Sorry I'm running late. I was late bringing your faculty candidates back from lunch. All right, so today I'm going to finish up the introduction to neural networks notebook and then time permitting I'll start the next one which I think is atom optimizer if I remember correctly. So, what I'll do, I'll just recap kind of gradient descent where we left off last time, and then continue to the end with demonstration, and the code. So, assignment one is due a week from today for most of you. So I hope you all have made progress I had some people come to office hours. So clearly, some of you are working on it. So I just recommend that, you know, everybody take advantage of office hours if you need help, because things are only going to get more complicated from here. So if there are any other any questions before I get started, let me share the screen to zoom. All right, no questions, but the material or general class procedures. All right, so let's get going then. Here it is. Alright, so just recall how we train my gradient descent is pretty much the same neural networks as training in linear operations, in that we are taking the error between some prediction y and some target T, and then you square it. And then you sum that squared error for all of our samples. So the only trick here is that we may have some n number of samples for each sample we want to predict some k number of outputs. Right. So now you're having a many to many correspondence. And so for every sample for every output, you need to compute the equivalent error between your prediction of that output for that sample to the target value. So just to clarify a point, the targets, this is just a question that came up in office hours. The targets are the things that's known, right, known data that you're trying to optimize the model to predict. So target T, y is the output of a function. So if we assume that there is some function f of x parameterized by w, x is your input, that function outputs y, your task is then to solve for w. The trick with neural networks is that there may be a nonlinear function. And your goal is to optimize the weights for a nonlinear function. And we do that by basically performing linear operations and then taking some nonlinear function and taking the output linear operation as the input to the nonlinear function. The nonlinear function is an activation function. The one we're working with currently is tan h. There are others that I will go to go into in within a few lectures. But for the moment, we can assume that the tan h function is the nonlinear function of choice. And it has some nice properties such as being linear near zero and less linear as the inputs go to more extreme values. So the trick, because the error is not a linear function of the parameters, we have to set the derivative, we cannot set the derivative equal to zero and solve for them. But you can do gradient descent the same way, right? So the only thing is you just have to update the equivalent weights for every input to the said weight matrix, be that v or w, for everything that that weight matrix is intended to output. So as we saw the update, the delta rule for v, the hidden layer weights is pretty straightforward. So if we break down what happens here with the DEDV, we end up with something that's fairly familiar. So for example, this is the two outputs, if you look at one output here, the DEDV is simply the partial derivative of the squared error, right, with respect to v. We then can use the chain rule to break down what everything in this term actually means in terms of other values in our equation. So just recall that z is at this point, the output of the hidden layer, there's a scalar value that's not intended to be inherently meaningful. But when the network is optimized, the output of this hidden layer should be useful information for the computation in the subsequent layer, which is in this case for a two layer neural network, the output layer. What is z is actually the is actually h of a, where a is the scalar value that comes out of the linear operation. We perform a nonlinear operation, in this case, tan h over it. So therefore, we're going to use the partial derivative of tan h or the derivative of tan h to compute the partial derivative, which is going to be 1 minus tan h squared. So similarly, we have a constant, we have the weights, we have the partial derivative of the activation function, we have the input. When we add another output, the only real difference is that we now have to sum the squared errors for each output. So this is just a recap of what we did last time. So what we end up with is that the delta rule for the hidden layer, where there are two outputs of this hidden layer, we need to sum that error for each output. And in this case, if we were only trying to optimize the weights for a single output node, so the function remains the same. So we have this error term, z, which is the input to that layer, and then a constant. So now the delta rules involving the delta rules involving the deltas look like this, we have the learning rate for the output layer, the error term, the input. The error term can also be written delta sub 1, 0. And so then for the hidden layer, the error term is going to be the sum of the errors for each of the individual outputs times those respective weights. Okay, so that was just a recap of what we talked about Tuesday. Any questions after that refresher? All right. Now the full version of backpropagation is going to look something like this. So take just look at a single weight here. Let's take v sub d1, which I think this is actually d0 here. This one here looks like maybe a typo. So if we're looking at just how we update this single weight given some set of outputs that depend on the output of this node, right, this should look familiar compared to the one above here. The only difference is we're now dealing with an arbitrary number of outputs. So what we do here is this error term is going to be output y1 minus the equivalent target, and then output y2 minus t2, and output yk minus tk. And this should be k's, they're not 2's. I didn't make this figure. I'll try and see if I can Photoshop it to be correct. So what we do then is these things will need to be summed. And then we will take, so if you look at the function here, effectively what we're doing here is now this generalizes to whatever number of outputs we actually have. So this is t1 minus y1 times w1 plus t2 minus y2 times w2, and so on and so on until we get to tk minus yk times wk, right? So we only have to use the derivative of the activation function once because we're simply looking at how to update one weight in one node. So here this h is going to be the activation function produces z. And so all of these then will need to be summed, multiplied by 1 minus the activation function, or the activation, derivative of the activation function squared times the input to this node. So now the only real thing that I need to do here that is different with multiple nodes is I'm going to be doing this at scale for every single one of these. So as you can imagine, this starts to grow somewhat out of control if I were to try to do it element-wise using these update rules. So what we're going to do then is we're simply going to apply matrix multiplication and matrix operations to do this. So here we have the update rule for an individual weight, v sub jm. I'm going to take the current value of that minus the learning rate times the error derivative with respect to that weight. Same thing for the output layer weights, and we saw how these terms here will break down into the full formula depending on whether I'm looking at a hidden layer weight whose update rule depends on what happens in the output layer, or if I'm simply looking at the output layer weight where the only real thing that I have to calculate is the error in that output term. So the reason that neural networks get more complicated is really entirely because of these hidden layers. So what this means then is that you can represent a purely linear function as a neural network that doesn't have any hidden layers. So if I have, if instead of this, if these yellow nodes weren't here and are going straight from input to output, it would be the same as a linear function, and I'm simply just trying to optimize the weights here because the assumption is that there's no non-linearity, this is a regressor, there's no non-linearity being applied here, so there's no non-linear function whose derivative I need to take in order to... So what this means then is that one neat trick you can do is that you can actually create neural networks that you can use to just do like rich regression, and you can, if you set up the code correctly, you can use it the exact same way and basically just say, I want to have no hidden layers in this, and it'll perform the same as a linear model, which means that a linear model is a good baseline, and also when we get to certain assignments, you can set up your neural network in that way to compare the neural network to effectively a linear model with no significant changes to the code except for specifying some of those hyperparameters about the hidden layers. So we took these original update rules, we saw the operations that lead us to these expressions for doing gradient descent, so right here is the element-wise error term times the relevant weight. One thing here now is for simplicity's sake, before we ignored the addition of the bias column just to show how the math worked, but now we can add it back in order to make the matrix operations work correctly. So why are we doing this? If we're just looking at how to update a single weight, it doesn't matter whether that weight is sort of a meaningful weight or a bias weight, the update is the same. If I want to make these into matrix operations, remember the math works out much more cleanly if I have this bias column so that I can assume that W0 times X0 is simply W0 times 1, because that first column X0 for every sample is 1, and so we can turn this into basically your standard and dimensional linear function with some sort of Y intercept. So hence being the Z tilde and the X tilde, if you remember from last time, we're using the tilde notation to signify some weight matrix that comes with the addition of a bias column. So if we look at these, let's work on driving this result using the output layer weights. So here this is kind of our standard formula for computing the total squared error for all sample for the output. So here what I will do then is I will simply take the derivative of both sides. This allows me to bring this negative 2 down in front. So now I'm simply summing over for all n for all k the error terms and then multiplying that by the derivative of the weight, the output with respect to the weight. So what is Y sub nk prime? Well, this is equal to for all m, which remember that's the output of our hidden layer, for this other step, that's the weights that are in our layer. So for all m, I'm going to take weight m prime k prime times Z n m prime. And so now this works out eventually, I'm kind of skipping through the math here, but eventually if I take the derivative of both sides here, I can then take the derivative of the thing that we just saw here. So we're driving this. This is how it can be rewritten. So I can put that into the partial derivative function there. And then eventually this will kind of cancel out to this part here. So now we have basically a constant times 1 over n times 1 over k times the sum for all n, remember that's all samples, times the sum for all n of the target n sub k or target t sub nk minus Y sub nk. So that is the target value for that sample for that output minus the predicted value for that sample for that output times the relevant inputs to the output layer. So I apologize for alternating in terms of input and output. Z is going to be that input to the output layer for sample n for output of the hidden layer m. So m here is just one of those columns in that hidden layer weight matrix. This is not something that is again a meaningful like scalar value that has any real interpretation. It's simply some sort of feature that will inform what t sub nk would be. So we can think of this as if I had a single layer, just some linear function where I have kind of random outputs or stochastic outputs or arbitrarily derived outputs, this part of the neural network, this hidden layer that output Z will allow me to approximate those values. Now the intuition there is that those values are somehow useful numerical features for predicting the true output that we're actually interested in. So questions about that intuition? Okay, so that was just for the output layer. So now the harder one of course is going to be optimizing those hidden layer weights because we are dependent upon how wrong those outputs of the hidden layer weights were when predicting the final output. So again you can think of it as a function over X produces Z and a function over Z produces Z. So we can think of that as a function of the final output. So again you can think of it as a function over X produces Z and a function over Z produces Y. I'm trying to update the appropriate, I'm trying to get the appropriate values of Z to map from X to Y, right, but you'll notice that Z does not directly involve Y even though it does directly involve X. So I have to use some error in Y to correctly update Z for the appropriate weights for processing X. So therefore I need to know how many outputs, how wrong are all the outputs that derive from a particular term in Z. So we'll begin with the same formula. So the error formula is the same and the derivative is going to be the same as above. Now knowing that Y sub nk is equal to the formula given previously, so then I can substitute this in for Z. So remember Z is going to be the output of the hidden layer over some function of X, right. So if I take V, my hidden layer weights times X, my inputs, and then I apply some function H to it, this is going to be equivalent to Z. So now we can rewrite this and so now if I'm looking at basically what is, I'm trying to calculate what dz dv is, I can take all this whole monster here and stick it in where I'm trying to calculate Z. Okay, so now I'll just, because this is really gnarly and hard to read, I will just let H of VX equal, be equal to A. Yes. The D, this one here, this is going to be the number of things I measure about X. So we'll talk about X as being an n by d matrix, meaning that every X is like a number, is some sample number n and then there's some thing about that end that I'm measuring d and I have d things. Okay. All right, so let A equal H of big V times B big X and so then I can just all use A in place of this this gnarly equation there. So now I can rewrite this as below. So then after some simplification, I end up with the following equation. So negative two times one over n times one over k times the sum for all n times the sum for all k of, again, the error term here, times the sum for all m, that is all outputs of the hidden layer, of W sub m prime k prime times effectively dz because we wrote z as this dz da where A is the input to Z times X. Okay, so let's now work backwards. Remember what all these things refer to. X is the inputs, A is going to be sum weights times X, right, so this occurs both in the numerator and the denominator of this derivative. The trick is that in the numerator, applying some activation function, nonlinear function H to this, the tilde is there because that output has to have this column of ones appended to it so that it can be an argument to another linear operation in the next layer. That next layer is parameterized by weights W, right, and so every W is going to take in n, like we can call them inputs, right, this is just inputs of the hidden layer, not the same as the raw inputs to the network, but there are m things that go into W and for each of those m things we want to produce k things, okay, so m by k matrix. So that's this part and then this part here is effectively what you should be familiar with now, error term, average overall samples, and all outputs. So to summarize, error function that you should be familiar with is a squared error, and then the derivative of that error with respect to each weight is going to differ depending on which layer that weight is in, okay, so we can have arbitrarily large networks where all the hidden layers have update functions that are some form of this, this one here at the bottom, here I'm kind of mousing over, and then the output function is going to just be a version of this for this to update the output weights, all right. So that was backpropagation, that is how do we update those individual weights based on prediction error, but how do we get that prediction in the first place? This is going to be the forward pass, so when you're writing a neural network you basically have the forward function which is I'm going to use my network in its current state, and if I'm in training I'm going to assume that current state is not optimized and that's going to give me some error that I can use to better optimize those weights using the backward pass. So the forward pass, this is effectively, right, we remember what this is, this is going to be big matrix V times big matrix X, this is just broken down in terms of the individual elements, then I apply H some activation function over it, this gives me Z, right, so each individual element of Z, Z for sample n, and then quote hidden output m will be defined by this, and then finally I'm going to take all of that, add a column of, add a one on front if necessary, and then for each element in that updated matrix I'm going to multiply that by the equivalent weight, and then take the sum over that for all m, that is all things that go into the output, the output, and the backwards pass is given by the equations that we derived previously, okay. So that was all the mathematics which took us probably in total an hour to get through between Tuesday and today, so you can go through this and this is I believe the most math heavy notebook in terms of like individual equations that I have written out, but if you are interested in how all this comes together you can review this, but you don't have to actually worry about this so much for doing the assignments, which I think is going to be a relief to most people, so let's actually go through the process of turning the mathematical equations into functional Python code. So the first thing we're going to need to do is, right, we've been looking at these individual scalar operations, I'm operating over some individual input sample for some individual measurement about that sample, right, that's going to be x sub nd. I also have let's say z sub nm, which is going to be some function over some individual x times some weight v, right, this is going to produce some value nm, which is going to be for every input sample of all n, I want to produce m measurable scalars about it, right, so these are just unit list numbers effectively, and then finally I'm going to take that whole thing for each one of those, apply some activation function to it, the tanh function, and then for each of those outputs I'm going to pass it into another set of weights that's going to give me the k things I actually care about, and then I use the error to optimize both weights in v and w. Of course, what I said in lecture three is basically don't use for loops because that they're slow and it just introduces a lot more opportunity for error, so we're going to take advantage of matrix multiplication. So the first thing we're going to do is convert these individual scalar operations into matrix expressions, so if you have the version of how we define z sub nm as this, I basically want to try and get rid of this sum operation here by combining things into rows and vectors or rows and columns, so we have h for v, some arbitrary column or arbitrary row, times x for some arbitrary column, okay, so now as long as these things match up, then I can start to rewrite my equation, so z sub nm will basically be, I'm going to take, I don't care about the row, I'm just going to take all of the m in whichever row it is, times all of the n rows in whichever column it is, right, this allows me to actually perform a single matrix operation to get one term of the output matrix. I'm just going to use the commutative property, swap these two things around here, and so now for every row and every column, I can just collapse this into one big matrix, so x tilde is going to be my input with the bias, and then v tilde is just going to be my hidden layer weights. As long as these things are the right shape, they're going to multiply, because all I have to do is make sure that these two inner terms are the same, right, so the star here is going to be some variable, and as long as these two have the same number of items, I can perform the whole thing as a single matrix operation, so now I do that, if I just perform this nonlinear function over there, that's just going to operate element-wise, right, so I'll take the tanh of now every element of this resulting matrix, and that will give me z, and then the same thing basically applies there, so I just want to get rid of the sum sign, and so all I need to do is make sure that I can rewrite my operation so that I have some input that has the same number of columns as the other thing has the same number of rows, and so if I can manage that, then I can collapse both z and w into big matrices too, and so now I have z tilde times w, and that's going to give me y, okay, so this part is should be pretty straightforward, I'm just looking to make sure that for every individual element, I have a matrix of the appropriate shape that can be multiplied to something else, the backwards path for v looks, is well, is more complicated, so we just have to do some more manipulations of the individual numbers in order to get the matrices to be in the right shape, so here's the individual operation, I'm trying to get rid of these sum signs, I can get rid of the sum over k by basically taking the column k to be some arbitrary number, so this will allow me to do that, so we write those as the stars here, the only thing I need to do to make sure, sorry what was that, it wasn't me, okay, that's like, I've never heard that sound like Peter before, so I was a little worried, oh press here to power off the projector now, press here to keep the projector on, I guess the projector must have been on time, on for a long time, okay, we will hope that it doesn't die before class is over, if it does we have to spend another day on neural networks, okay, so backwards pass, so what I'm trying to do is, I'm trying to, first I'm trying to get rid of the sum signs, I can get rid of the sum over k by turning this into just some arbitrary column, the only thing I need to do there is I need to make sure to transpose the weight matrix here, so because I don't have any commutative property that I can just use to swap these two things to make sure that the dimensions align, instead because I'm going to take this to be a column matrix minus a column matrix times a column matrix, the result of this is going to be a column matrix, and so then I will, or sorry, my bad, result, this is a row matrix minus a row matrix times a row matrix, so the result of this will be a row matrix, so in order to turn this into a column matrix, I'm just going to have to transpose it, all right, in NumPy you do not actually have to do this for individual rows, remember, because if I have a one-dimensional array, I can just multiply them together, and then using the matmul operator it will give me a single number, so NumPy will basically coerce the shape for you, but you're almost never going to have single row or column matrices in dealing with neural networks, so you can assume that this is always going to be the case. All right, so the next thing I want to get rid of now is the sum over n, so what do I do there? So this remains the same as before, and so now I need to do something with the n's to turn them into arbitrary rows, right, so if I rewrite these as stars, I just have to make sure that I'm doing this basically for all n for each individual n in that row. Similarly, because I again don't really have a nice, what I want to do is I want to make sure that the inner dimensions of this thing aligns with this thing, right, this is not really easy, I have to compute all of this in order to figure out whether the dimensions are right, but I can already tell that I'm going to have, I've got n items that have m individual corresponding columns, and then I have multiply that by something that also has n rows for j columns, so in order to get basically the two n size dimensions on the inner, all I'm going to do is just transpose this whole thing, right, so the shapes of this line up such that I end up with n by m, and so if I transpose it then I'm going to have m by n, which is going to multiply nicely. Okay, so I'm almost there except I have this problem in that the right side has subscripts written in terms of mj or m and some other elements, whereas the left side is jm, so I have to make sure to line these up because I can't take v sub jm and then add something that is in terms of something sub mj, right, because then I will want the dimensions are going to line up and I'll be adding or subtracting like the wrong element from the in the update matrix from the wrong element in the thing to be updated. Okay, so then what I will do here is, so I have this is the update function according to what I had computed previously, so what I will do is first I'm going to transpose it, okay, now this allows me to swap the individual dimensions, and then what I can do is I can treat for v for every row j, every column m, then I will be able to take the learning rate times 1 over n times 1 over k, so for all inputs and all outputs, times the transpose input, times the whole error function, times the transpose weights element-wise multiplied by the derivative of the activation function. So the end result now is now I've got things all lined up, I've got I can treat these arbitrary members elements of the of the matrix just as individuals, so if I can handle them all the same, now I can collapse everything into a big matrix, so given this I can take, so v is going to be some new hidden layer weights, and for that I'll take the previous hidden layer weights plus the learning rate times 1 over n times 1 over k, times the transpose input, times the error, times the output, times 1 over or 1 minus z, in this case the derivative of tanh. So this w with the caret is going to be w without the constant input row, so this is just going to be sort of raw w or w tilde with the bias, and so now the backwards pass for w works out rather similarly. So the first thing I'm going to get rid of is the sum. This is pretty easy because I only have one sum to get rid of, so we can basically do it the same way. Again all I need to do is transpose the resulting array that results from taking the error term for every row, and then multiply that by z tilde. Again my subscripts are a little bit inverted, so the right side has mk, or so the left side is mk, but the right side has k and m, so then what I will do is I'll take these two terms and just switch them using the commutative property, and so now this allows me to turn these into arbitrary rows or arbitrary columns, and therefore I can collapse now everything in this into a big matrix. So w is going to be old w plus the learning rate times 1 over n times 1 over k times the transpose input to the hidden layer, so this is now playing the same role as x tilde did in the above, so these two are kind of playing equivalent roles here, and then this is just the raw error. All my t's minus all my y. Okay, and so now the shapes of these should work out correctly, and so now all together in math right what is z? z is some function h applied over bias x times v, and then I apply I append a prependum bias to my my z multiply that by w I get I get y, and then the update for v is going to have to incorporate a couple of other things right not only the inputs and the error, but also the weights things that are to be updated in the subsequent layer, and then the derivative of the activation function the non-linear functions being applied, and then w is kind of the same just simplified basically the only thing different this is this can be considered the w update can be considered a special case of the v update where the activation function is just a linear pass through so x equals x what's the derivative of y equals x it's one so this is just the same as multiplying by the derivative of y equals x which is one, and there are no weights there are no subsequent weights to be updated so I don't need to add I don't need to multiply by anything here. Okay, so that was the mathematics now how do we do this in python so your code is going to look something like this right this is not necessarily going to be exactly what you're going to do in assignment two, but this is generally the shape of the code so first of all I'm going to take an input x and a target t what I want to do is I want to do this forward pass right that's these two things or the first two things up here is a z and y so what I'm going to do for that is I will just add ones to x so this is this add ones function oops can be assumed to be some function that's just going to put a constant column of ones on the front of your input matrix okay so now I'll just call that x1 this allows me to keep things straight so then I will multiply x1 and v this is going to give me what I was previously referring to as a I take the 10h my nonlinear function this is going to give me z here right so z equals h of xv is that's what's happening in these first two lines I have to add a column of ones on the front of z so I'll apply that same add ones function and then I take the z1 multiply it by w this gives me my output y so now for the back prop step I'm going to do gradient descent on the derivative of the squared error with respect to each weight to update v and w so first thing I'm going to reuse t minus y to much places so I'll just calculate that as the error and so now if you look at these two columns here or these two rows here you should be able to see that they're basically just reproducing in Python what we did here so what is v it is the previous value of v plus some learning rate times x1 x1 transpose times the error times w transpose and then element wise multiplied by the derivative of the tan h function and then w is going to be the same thing so why am I not really using one over n or one over k well I know the sizes of n or k so this is just a constant so I don't really need to worry about that all right questions all right so the above equation is going to this is going to be like a single gradient descent step so we're going to be using all of our training data in x and t to calculate the the gradient of of e with respect to the weights so we don't want to use the for loop so we're going to actually use instead of writing the for loop we're going to be using the full gradient so here's an example this is just dummy data so this data doesn't signify anything what I'm going to do is I want to create a non-linear function that I can fit a neural network to like this so if you recall from like assignment three if this loads so we had like we did some exercises where we had this function that was at best only vague at best vaguely linear this god it's a long notebook like this one here right so we created some function that this is really a non-linear function right because I created a some some dummy data and then applied a polynomial over it so we know that that's likely to be a non-linear function and so now my goal is instead of just fitting a line to that which is a pretty lousy fit I want to try and fit a non-linear function to it using a neural network so there so for example here is a function that has clearly some non-linearities in it with the use of sign and I'm going to try and fit a neural network to this using a using non-linear functions so I will apply some noise to make things a little bit more interesting so this epsilon is going to be a random variable drawn from the standard normal distribution between with a range of negative 10 and 10 okay so let's see what it looks like so let me do my imports so first I'll make some training data and I'll create some helper functions so this is I'm just going to create some training data that is where the inputs are evenly spaced across some some domain and then I'll take the this function and apply that to that to that data to create this non-linear function and I'll do the same thing with some testing data where I have just different inputs that are random that are sampled differently so these are generated using the linspace function the x test is basically I take the train data and add a little bit of noise to it not so much that the testing data is going to be completely out of distribution but enough that it like it's close but it hasn't been seen before so that's just the idea here and so that is even though this is dealing with random random inputs here this is what you should expect for pretty much any type of machine learning problem if you want it to behave well that is the training the training data and the testing data should be more or less resemblance right if I'm trying to use my network fitted to weather to classify miles per gallon it's not going to work very well and the same is true for for neural networks as well okay so now I'm going to add this helper function uh which I'm running a resell so I'll add this helper function add ones and so this is just doing what we did previously in in notebook three just in a convenient wrapper function so I'll standardize standardization in this case is the same as we did for for linear regression so I'll compute means and standard deviations over the training data and then I will standardize both the training data and the testing data using those computed means and standards take this now I apply the add ones function to both my training and my testing data I'll do this right now so that when I get to the evaluation phase my testing data is the shape that I might never expect so generally good practice is just to make sure that you have your data all set up in advance before you before you're going to use it and then just make sure that you're not accidentally like inputting the testing data into your training function or something okay so previously we did our weight initialization in in assignment one and in lecture three using just initializing them all to zeros so here with the neural network we're going to actually initialize the weights to random values so if all the weights are initialized to zero all those hidden units will earn identical weight updates and that would be as if we have only like one hidden units okay and so basically you cannot reliably get your network to fit when you are initializing your rates to zeros with most network architectures you could also you could do assignment three using random initialization of the weights it's just that well a couple things happen one your code may not pass the automated greater because we have no expected values assuming that you initialize using zero but also even if you even if that weren't a factor different initializations will take longer or different times to converge because you don't know exactly what the initialized weights are and so you don't know how many gradient update steps you need to get to the same level of root mean squared error so with neural networks this is a pitfall in that if you have different weight initializations you may get different results usually if the data is such that the network and the network architecture is such that it can converge you don't end up with a radical difference in in many cases but generally it's good practice for reproducibility to do things like set a constant random seed to make sure that you're initializing effectively two deterministic values all right so now let's set the parameters of our of our neural network the first thing i want to specify is how big is this hidden layer right so i have n samples and i have d things that i'm i want to measure about this and i have k things that i want to predict but somewhere in there there's a transformation by some dimensionality m right i basically have to decide the size of them so i'll use 20 the the the number of layers that you choose has certain implications for the the results of your training based on the nature of the data and normally people arrive at the appropriate number of hidden layers or hidden units by some sort of empirical evaluation or trial and error or grid search there are more sophisticated techniques that you can use that are somewhat outside the scope of this class but there are some toolkits that will do things like hyperparameter search for you all right for the moment we'll just say okay we'll use 20 hidden hidden units i'm going to specify two learning rates one for the one for the hidden layer and one for the output layer so you know you can initialize these to be constant you can use some techniques based on the the sample size if you want so now i'm going to initialize v and w randomly right so i will initialize in this case from the same distribution all i need to do is make sure that they're the right shape so i have x train dot shape one that's the number that's d that's the number of things measured about each sample plus one for the bias column and then the output of this has to be the same number of hidden units right so the output shape of this should be hidden units and then i add one to that and then the output of the output size is the this outer dimension of w so set the number of epochs in this case i'll do 100 000 i'll collect a couple of things for plotting training and testing error so now here's the user of the real operation so i will perform the forward pass and the training data remember i've already applied add ones to x train so that's done for me multiply that by v take the tan edge of that apply the add ones function to the output that gives me z1 and then y equals z1 times w and so that is basically what we are doing up here okay next thing is the i'll complete the error right so this is going to be t train s minus y so these are the training targets and then the prediction so now the backwards pass these are just the two functions that i created before so the only thing that's really different here is i'm using x train s instead of just like x1 so you have to make sure that you're using the the right the right data usually if you're putting in if you've assigned multiple variables to different splits of the data and you use the wrong one it'll probably just throw some shape error that should be pretty easy to spot all right so now after this this allows me to do the forward pass in a single line so if we break this down for the sure to predict the the test i can just take the add ones function apply that over the output of the linear operation here so if you work outwards this is x times v plus with the ones take the tanh add ones again multiply that by by w and now this allows me to to compute the the error relative to the the testing data all right so now then what i can do is i can collect collect the error traces for plotting and then all this this is just a matplot lib functions all right so let me run this and we can actually see this network working in real time so here we can see the root mean squared error on the y-axis plotted versus the training epochs on the x-axis and this will run for about a hundred thousand training epochs and so you can see that the the training error is much lower but we also see some significant progress in the testing error nonetheless the testing error kind of appears to bottom out at around maybe 0.25 whereas the the training error is much lower so this this network should be able to fit to this data decently well we can look and see what the predictions are right so here we have training samples so this is the i'll see plot the actual and predicted given the the training data the testing data and the model for every x right so if i run this again we can actually watch this this second one how maybe not i guess this does that i thought this was going to like animate in real time i guess it didn't say to do that so what we see here is now this is going to be the the blue line is going to be the training okay i guess it is moving a little bit probably faster than that oh well so what we see here now i guess the point i'm trying to make here is blue line is the is the the training data the green line is the fit to the training data this is the model so we can see that the blue line and the green line are pretty close right so the green is the predicted values of the blue line is the actual values and the orange line is the testing data which overall is still pretty good like it's a decent fit but it's not quite as good so we can see how this this higher testing error is being reflected in the in the output scene okay final thing is what are the different what are the different units actually predicting so they will just look at the output units or sorry the hidden units and so for x there's like 20 lines here you can only really see a few of them because most of them are basically these lines clustered near y equals zero but you can see how like for some of these units for different values of x they're outputting different values so these hidden units if we look and just see sort of how many of these are not just clustered here at y equals zero you know one two three four five six seven eight maybe there's maybe uh eight units that are probably doing most of the work whereas the bulk of the units are either always outputting is a very small value and then the sum like this one here whatever it's optimized to is basically a right around zero it's changing its output from very positive to very negative right this is going to be after the application of the tanh function because that is going to bound us between negative one and one all right so that's the end of intro to neural networks questions i'll go quickly through i'll start adam at least before we we before we dismiss all right any questions about neural operations yeah i was wondering how do we decide the right kind of blocks to how do you decide the right plot for yeah i mean it depends on what you're trying to visualize right so for example if you're plotting training and testing loss or error you know this is something that you'll see commonly so you'll see training time and then the the error or the loss function on the y-axis this allows you to show that your network actually is converging and where and how how well it's able to be optimized so it really you know there are so many things that you could measure about a neural network and its output so it's really dependent upon what it is trying to show i'll have some examples of say plotting hidden unit outputs in multiple dimensions later i think in notebook maybe seven so i guess there's no there's no real like rules for this in that it's dependent upon the data and it's also dependent on what you're trying to show with the data right because depending on how you visualize the data it may kind of tell a different story that makes your point or a different point better or worse so i think the most i'll say right now is like during this class you will have multiple opportunities to see different types of plots and you can see which ones maybe are intuitive to you and which ones are not and then in like when in your final project you'll have the opportunity to kind of experiment with how you want to visualize the data if it's a classification problem versus a regression problem versus something else all right any other questions yeah yes yeah um so i think i mean you'll definitely know if you're wrong if you see it not converging there is there are some things weird things can happen especially as your networks grow larger in that and your input sizes grow larger and that you may see your network doesn't converge for like a long time and then actually like i think i have a maybe i have an example let me see if i okay maybe maybe we'll discuss this and i'll do adam tomorrow or or uh tuesday so like here's here's some research that i'm doing um and basically we're like trying to predict you know some uh some outputs from uh an experiment from data that we gathered in the lab and um with the loss plot one thing that we see we obviously see things like this so for example if i'm looking at i'm plotting four things here right so we have um a training set a validation set and for each one i'm plotting accuracy and the loss so this is a classification problem we'll talk about loss functions as opposed to error functions later but just take this to be you know classification error and then accuracy right so the accuracy is actually sample accuracy which means that even though i have this nice smooth curve as the loss goes down which is what i want to see there's a long time where that that is not actually reflected in the classification accuracy because it's basically it's a not a regression problem it's basically is this sample being predicted correctly or not and so because of that we see these kind of jagged leaps where it goes up a lot and then in fact the out the validation accuracy goes down again and then it sort of converges better and better in these in these stepwise um increments right so it's like it's getting i don't know 70 percent or what is it like uh 85 percent of the samples here and it's really not getting any more than 85 percent of the samples and then suddenly it starts getting 88 percent of the samples and then eventually it gets up to like 97 or something like that so you can plot you know different metrics and the different packages will allow you to do that pretty easily so you can plot like accuracy loss even you know other metrics like f1 precision that we talked about earlier so again you know depending on the nature of your task if it's a regression function you probably want to see a lot of these nice curves and you should see them both in you know in like well i guess probably only going to be using error for that so you should see kind of the error curve start to to decline and it should be pretty much consistent with a couple of exceptions that we'll go into later where if it's classification you're going to want to look at like measures like accuracy or some of these more information theoretic precision recall type measures so i guess one thing you can do um will use pytorch and you may be might use tensorflow on your projects but there's like a lot of um built-in metrics that you can use and so most of these packages basically allow you to create a validation metric in your uh in your training just with like the change of a string and then you can plot all these things and see like which ones are actually useful information to present okay all right other questions yeah how to decide how many hidden layers are included in the network great question uh short answer is no one really knows um long answer is there's a number of techniques you can use um so uh one of the network one of the like notebooks we're going to be doing is like how to find good parameters um so you can do things like grid search basically specify a bunch of different options you want to try and try all of them and see like according to say your error metric your accuracy metric which one is best there are some rules or some i would say rules of thumb i guess that you can consider um based on the sizes of your input so if you have n by d inputs the more d's you have more dimensions generally the larger network you're going to need um so effectively what's going on here is i look at the the architecture of this network that i created is basically four hidden layers that are 128 units 64 units 64 units and 32 units okay um i ultimately i arrived at these empirically and then i tried different things and saw what worked better but why am i why did i choose 128 for example as opposed to 64 in that input layer well it's because the raw dimensionality of the input was something like 780 so if i take 780 dimensions and project it down to say 64 dimensions i'm losing a lot of information so effectively what we're doing it every hidden layer the network size is the the layer size of the dimensionality of the output which means that you're projecting whatever comes into that layer into that dimensionality so if i have 20 hidden units i'm going to be projecting whatever comes into that into 20 dimensions so what if your input is less than 20 dimensions well it'll project it with the addition of noise because there's no other way to do it right it's gonna not it's basically going to not optimize some weights because it has no information available to optimize them what happens if i put in way more than 20 things it's going to have to project that down to 20 dimensions and so i could lose information that could be useful so in this case um i'm trying to effectively classify three classes using 780 dimensional inputs right so big information bottleneck but i don't want to go too fast so projecting in this case down from 780 to 128 sort of turned out to be the happy medium between you know 64 and 256 people usually use nice multiples of two for computational properties sometimes you might just use decimal numbers so you know it's not unheard of to see you know 20 hidden units 10 hidden units 100 hidden units whatever um and sometimes people will find that some weird number just works really great like 347 which is that a prime number that might be a prime number and like it just seemed to work better than 346 or 348 um case in point i guess if you're you're heard of the burt model you may have it's like it's a major nlp model so basically you've heard of chat gbt i assume okay so gbt is a sort of one family of big nlp models and they use what's called the decoder layer of the transformer meaning they're basically good for generation burt is sort of the is a bidirectional encoding of representations from transformers and the logo was always burt from sesame street and that's that only uses the encoder layer of the transformers basically meaning that it's taking raw input turning it into a demand an n dimensional representation that uh what that does is um the burt model is basically taking you know words turning them into 768 dimensions but they use it you they do it using stacked encoders and so that is you have one feed forward network another feed forward network another feed forward network and so on how many encoders do they use how do you decide how many encoders do you as well burt uses 12 why 12 well they tried a bunch of other stuff and 12 work best so there there are you know there's probably good reasons why 12 works better than say 11 or 13 but it's not entirely clear why 12 works better than say 16 it's probably a happy medium between robustness of the representation and compute time so all that is a long way of saying everybody has their favorite techniques there's some really smart people who have probably found some evidence-based ways to explore this space sometimes it requires an enormous amount of resources to do this exploration so some folks just do trial and error or grid search or you know what have you yeah all righty um what else all right let me um let me start the atom notebook i guess um i doubt we're gonna have time to go through that in uh so of course it might take me 15 minutes to find my uh find my folder um all right where does this work there is okay uh so all right gradient descent with adam so um i guess just in brief uh in the in the last 15 minutes um so who is adam uh adam is about a person adam is as a function um so there are many ways to descend a gradient right what we've talked about so far is basically looking trying to find the direction of steepest descent and taking little steps in that direction well this seems pretty inefficient right maybe i could take a bigger step but as you've observed one way to take a bigger step is to have a large learning rate right the learning rate is eventually the step down the gradient uh but if your step is too big you or maybe you may find yourself stepping back and forth over that optimum you don't want that but let's think about um if i'm standing on the edge of a canyon i'm trying to find my way to the bottom if i know that i'm at the very lip right i could probably take a big step and then like i'm not going to overshoot the the minimum so that's fine so maybe i can be smarter about how big a step i'm taking or basically scale the step that i'm taking using uh using some metric so um there are other ways of finding error gradients that will lead to fewer steps before we get to optimal weights so um this thing one of them is called adam and there are various adam variants that are in use um so this uh uh this one is sort of the original one from uh 2014 i think um so adam stands for adaptive movement estimation so you can kind of see where we're going with this if i'm really far from the gradient from the minimum i can justify moving faster if i should be getting closer maybe i should be slowing down right uh so there are a couple of um you know sort of more in-depth gentle introductions you can read is the additional paper here by king man bha and then jason brownlee has this this nice kind of gentle introduction to atom optimization but basically uh for general purpose gradient descent algorithms you want to collect all the weights into a neural network into one vector so this way you can actually use arbitrary gradient descent algorithms for an optimization problem as long as i know what what hyperparameters i need to apply where so uh let's say we assume these weight matrices v and w so to collect all of these we can run this pack function so now what i'll do is i'll take v and w flatten them both and then just stick them together so it just leaves the h stack function so let's just test this before going any further so what i can do is i'll create some numbers these are just arbitrary numbers just to represent hidden layer weights and then some to represent output layer weights so if i print them these are obviously not good weights for any real reason they're just illustrative so if i have v which is you know a five by two and then w which is a three by six if i flatten all of them and again you'll observe that like these these matrices would not uh would not multiply you have to make sure that the outputs are the right shape so i need to flatten them this is going to give me an array of zero through nine and then an array of 23 or 37 and if i run the pack function we can see that the output is what i expect i basically just have a single array that contains all those numbers okay so now imagine that we sent this weight vector off to some gradient descent optimizer and then it returns some new weight values i need to unpack those into the right shape for v and w so i'll create an unpack function that is good to do more complicated than the pack function because it reshapes w back into the constituent matrices so of course for that i need to specify what shape those are and then this will create you know create that into the number of rows number of columns for each one and then reshape basically split the full the flattened the flattened packed vector at where according to those shapes the the two different weight matrices should be and then reshape them appropriately so if i define that and then i pack v and w and then i run unpack this will get me back my my original one all right so um how is v defined right that is when we run a cell that invokes v what happens so first thing what i can do is set what i do is here is i'll set w zero is equal to two thousand and then if i look at v you will see that that first element is now set to two thousand so what happened i actually didn't recalculate w so why did the value change so if i do if i create this v2 which is basically a a an instance of v then if i run if i show v2 and w i still see this two thousand here okay great because i just effectively cloned v now let me set w zero equal to one thousand so wait a minute v2 didn't change right why not because the unpack method is going to create these output matrices that preserve the same places in memory as the vector that was used to create them so if i change w you change v so this can be useful for efficient usage of memory to make sure you're not overwriting something you don't need to overwrite so if i print w right this is that packed vector i can see one thousand there so v2 didn't change because it was effectively making a deep copy and but if i change w and then i print the packed vector we see the same contents here now so i need to update w in place in order to do this so if i just do you know in place multiplication that that'll work but if i do w equals w times 0.01 that will not right so now w has a 100 in the first position and similarly now so does v right so this is basically accessing the same point in memory another way to update arrays update values without creating new memory is to basically just do a slice over the entire over the entire array so what i'm doing here is now just saying for every element in w take w times 100 and so now if i print w this will give me 10,000 in the first position and you know well 100 times everything else and then v and w you will see that now the v and w have all been multiplied by 100 okay so all of that that's just how you create your format your weight matrices so that it is appropriate for doing this kind of general optimization using using gradient descent so all right in the last eight minutes real briefly intro to adam so adam is short for adaptive movement estimation it's just spelt adam like the name it's not an acronym it is pretty straightforward to implement it is computationally efficient little memory requirements provide that you are creating your matrices in the appropriate way or so it's not just creating deep copies everywhere it's invariant to diagonal rescale of the gradients and it's well suited to problems that are large in either in the data or in the parameters and so it's it's generally quite efficient as we'll see presumably on tuesday we can get adam-based optimization to converge a whole lot faster than sgd okay it is also appropriate for non-stationary objectives and for problems with very noisy or very sparse gradients and the hyper parameters have an intuitive interpretation and typically don't require a lot of tuning so sgd maintains the single learning rate for all weight updates and this doesn't change during training so remember the learning rate is the step adam combines the benefits of these two of two extensions to sgd one is a to grad for adaptive gradient which this will maintain a learning rate for every parameter and this improves on performance with sparse gradients and then rms proper root mean square propagation which also maintains per parameter learning rates and these are based on the average of recent magnitudes so that is how quickly a weight is changing and that means that the algorithm does work like these online or non-stationary problems so adam provides the benefits of both using these things called the first moment and the second moment so if any of you have taken physics this may be familiar to you first moment is the average of recent magnitudes of of the gradients for the weight in question so that's just the mean of recent very recent values and then the second moment is just the square of that so this is just the uncentered variance so formulas that say if i have i'm going to take like the past four would look something like this so this is again related to the concept of the moment in physics so these are expressions involving the product of a distance and a physical quantity so basically this accounts for how the the mass of the of the object is actually arranged so the first moment of mass is the center of mass and the second moment of mass is the rotational inertia so just think of this in terms of if my weights were quantities in space right if those were masses then the center the first moment would reasonably be the center of mass right they're all distributed kind of unevenly and like a potato it wouldn't necessarily be the center of of material but you know rather center of mass and then the second moment is going to be its its variance so you think of the first moment is probability distribution as the mean and the second moment has its variance so you can have raw variance or centered variance and for adam the second moment is wrong so what adam does in the last few minutes is it basically calculates an exponential moving average of the gradient and the square gradient controlled by these two parameters beta one and beta two and these are decay rates so that is if you think about if i'm on the lip of the grand canyon i might run down the trail at first right because it's really steep and then i'll slow down as i get to the bottom so how how much do i slow down as i approach the bottom or as i think i'm approaching the bottom would be controlled by these two parameters okay and so these are just the decay rates of these moving averages and so exponential decay will decry it will describe the amount of reducing an amount by a percentage over time and so the time here is training epochs so the first moment calculation will look something like this so m which is some some value for the moment equals beta one times m plus one minus beta one times the error so here what i'm going to do is i'm just going to look and see there's this controlling parameter how much do i need to reduce my momentum or my movement so all right i will end there for today and then on tuesday we'll pick up with the adam implementation all right thanks everybody i'll see you next week