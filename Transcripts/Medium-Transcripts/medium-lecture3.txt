 All right, let's go ahead and start. It's 2pm. Okay, welcome back. Can you all hear me in zoom. All right. People still connecting to audio. Zoom folks is the audio. And I will assume it's good for the rest of you. All right. So, I think only announcement. Sarah you're doing a tutorial tomorrow. Okay. Can you just recap the tutorial on what and where. And what will you cover. Great. Yeah. So, if you are not familiar with how to do any of those things, I really encourage you to attend the first assignment is going to come out. When we're doing that. So first assignment is due to be rolled out on Thursday. So, make sure that you are familiar with everything that you're operationally going to need to know just to get the Jupyter notebook up and running. So, if you're not familiar with how to do any of those things, I really encourage you to attend the first assignment is due to be rolled out on Thursday. So, make sure that you are familiar with everything that you're operationally going to need to know just to get the Jupyter notebook up and running. We won't be using GPU for an assignment, I think, until a three. Nonetheless, this is you're going to need to know it. Or you need to be able to use it if you want to run any of the notebooks from like eight, nine, ten, etc. So, just make sure that you're at least comfortable with all those procedures. We're picked up last week. So let me share screen. All right, so. All right, so where we left off. Hide. All right, so we, we kind of motivated the problem of linear regression on this is probably something that you're all familiar with basically read this point we're still trying to fit a curve to a set of points. Right. And so if we have a set of observables, so we can take those to be the ground truth. And we have a set of inputs that correspond to those observables in the use case to the outline those basically, I have these, these springs. And I'm trying to effectively, you know, figure out what the spring length is that's going to allow the this this rod here to basically rest at equilibrium. Right. And so we want to minimize the potential energy and a set of springs and one way we can do that is basically if you have the spring lengths stored on as weights we're trying to solve for that, where the observables are the energy stored in any particular spring. And this can be applied to any linear problem. Effectively what I'm trying to do is I'm trying to find the rate of change, and then minimize the rate of change in those inputs. And so I'm trying to find the coefficients correspond to this input that's going to minimize the derivative or the gradient. Just a recap of terminology. What is a gradient slope, but in multiple dimensions right it's basically the high dimensional derivative. And so this is what we're trying to find if I have a bunch of inputs, I'm basically trying to minimize the gradient with respect to every dimension represented by those inputs. So, you know, we talked about you know just using kind of the least squares install functions on you know in NumPy that will I do that with some with relatively small inputs, but often will have a bunch of samples right and this can be very time intensive to solve. And so we don't want to have to do these huge matrix operations you want to minimize matrices are very useful of course, and can minimize the time complexity of these types of operations but still trying to do the operations over these huge matrices are still time complexity is still going to explode. So, so we can do is you can use this incremental form, where basically we're trying to find some sequential algorithm. You use the fact that the derivative of the song is the sum of derivative so now we can express this derivative as that gradient. That's just a matrix of derivative so just like everything else, where your inputs can be a matrix and outputs are usually going to be a column matrix. Those who see you can have multiple columns. The derivatives of course can also be represented as matrix. So this offset on triangle pronounce Adele represents the gradient so we have some function, g of experiment rise by w this is just the linear function remember this can be written is basically the transpose of x times T. And they're very if I'm doing this for every combination of weights and inputs is just be written as a song. So now we have this error, so this error function, he is expressed on as with the arguments of the inputs. So, effectively what I'm trying to minimize is the difference between T Taurus or X times W and T. Right so if T is my ground truth, X times W is my prediction, the correct model is going to be one that minimizes the difference between prediction the ground truth. And that's just expressed by this formula here. Right so inside the summation on every element of T the targets, minus the output of function g for input, X of n. This is just going to be the squared error and try to minimize the squared error. So now we're just back in familiarly square territory. So of course I take the error gradient. So now this is going to be the great with respect to W the weights of that error function. Of course I'm just going to apply that same gradient to the other side of the equation as well. And so then ultimately if I take the gradient. It simplifies to the thing at the bottom by very pretty straightforward calculus operations. I bring the exponent two down in front and multiply by the base. And then eventually we end up with the formula here. So now, instead of summing over all of the samples, if I just take the equivalent weight, then I can update it for the gradient for that sample. So that is five is one input sample. And then I have some weights that are just at this point arbitrator and then the input times those weights is going to be some distance from the ground truth. Right. And if it's the weights are wildly unoptimized, it's going to be very distant. If they're very closely optimized, it should be pretty close. And so I'm going to take that that error and then I can optimize the weights that correspond to that input sample for an optimize them with the error for that that sample. So the gradient for some sample and can be considered to be basically a noisy sample of the true gradient. So that is there's some true gradient that represents the gradient over all of the samples. And for a single input sample, this is going to be a sample of that entire gradient that is just subject to some perturbation or noise. And so I can take a small step in the direction of the negative gradient, try to bring the current guess for that way closer to the actual truth. So on the for some iteration K, I'm going to have this new value for some weight for some weight W and then on the next iteration, I should have a value for that weight that's closer to the ground truth. And this is called stochastic approximation. So in this case, we have W case K plus one. So this is going to be the value of W at iteration K plus one is going to be the previous value for that weight minus the gradient of the error function. Right. So this is written here. And then for this for this algorithm to converge, we have some constant here row. I want this to decrease the reiteration, not too fast and not too slow. So this is the least mean squares algorithm is derived by these folks with your own half. This is often referred to as SGD or stochastic gradient descent. So now here's an issue. If I have two output variables, let's say that I'm trying to predict two things about a car from other other parameters. Let's say I have a bunch of information, and I'm trying to predict what its miles per gallon and its horsepower is, then this value T sub n is no longer going to be scalar. So now into to predict two variables, I now need two linear models so I could do this by changing W, my weight matrix from a single column to two columns. And so now the first column will contain weights used to predict one value and the second column will contain weights used to predict a different value. So now effectively, what I'm looking at is if I have my inputs X, this is a matrix that for every sample contains the number of things I measure about that sample. So let's say I have a thousand cars. This would be a thousand rows in that matrix. And if I measure five things about them, there would be five values for each row. And you can assign some meaning to those values. And in the case of linear approximation, those values are pretty pretty interpretable. And then I have some weights that I'm trying to solve for that will multiply by those inputs that will predict a number of other things that I'm trying to predict. If I'm just trying to predict one thing about each sample, I'm just going to have one column of outputs. I'm trying to predict two things about each. I'm going to have two columns of outputs. And so then if I have, let's say, a thousand rows and then five inputs for each one, and then I have two things that I'm trying to predict, I'm trying to solve for weights that will take those five inputs and predict the two outputs. And so that means that it should have weights that are associated with every output that I'm trying to predict. So I'm trying to predict a thousand things. I should have a thousand different weights. So the linear model in this case would look the same, right, because I have weights that are just a matrix W. And as long as those matrices are the right shapes, they'll multiply together and I'll get the expected number of outputs. And so that's just one of the advantages of using matrix math is that if I just take that input vector and then they take the dot product of each of the two columns or n columns of W, then those resulting values will be the predictions of the items that I'm looking for. And now I just have to optimize those weights to predict both things at the same time. Now, you think this is going to take longer, shorter, the same time as predicting the weights to predict one value? Who thinks it's going to take the same time? Longer? It will take longer to converge to the same level of the same level of error. And that's because if we have two things like if MPG and horsepower are not very closely correlated in those, the two things I'm trying to predict, then I'm trying to optimize those weights at the same time. So it will take a little bit longer. But the formula is pretty much the same. So what do we do to the update formula in order to make this in order to make this happen? So we have to modify W to be the right shape. And then also for every sample, for every input, we have to specify the two target values. So this T sub n here, this is also no longer scalar. So now this is two values in a vector. So now I have to note this is bold T sub n. So now instead of a single value, I'll have some number of output samples I'm trying to predict. And that's just going to that will be an arbitrary number just based on whatever it is you're actually trying to predict. And so now to update the weights, you have to multiply each error by every input component. And this sounds like you would take a double loop. So in the last equation, we use matrix math and NumPy. And we did this, this operation can be done using broadcasting. We'll see the code shortly. If I use NumPy broadcasting, then that allows me to remove the loop over all the components in X and in X and W. So now I use broadcasting again, then I can remove a loop over the target output. Right. So now, yes. And here is referring to particular sample. So if we have usually what the number of samples would be denoted as big N. So if I say I have 1000 samples, that's rows in my matrix. And so I say big N equals one, and then sub n is referring to an arbitrary individual sample. Any other questions. Okay, so right now just operationally, if I'm trying to effectively scale up to an arbitrary number of inputs and outputs, this naturally means we're gonna have to scale up to number of weights. I want to avoid doing things like having for loops. There's a number of reasons for that we'll discuss in a moment. And so I can use the functionality provided by NumPy broadcasting to effectively remove those for loops. So if I use it to say remove the loop over the target components in T, as long as your matrices are the right shape, then the resulting matrix will be the correct shape for W. And so here, if you follow the convention that the vectors are column vectors, then the new weight update at iteration k plus one will be the previous weight at iteration k. And then plus some scalar value times those inputs, x of n. And then what is this last term here represent? This is the gradient for the error, right, how far is, how wrong am I so that you can think of it this way. Your model is always going to make a prediction. And you want to measure how wrong your prediction is. And the amount of wrongness will tell you how much I need to update my weights. Right. So if I'm really wrong, then making a very, very small update in my weights is maybe not going to get me very close to the actual value. So, but if I'm very, very close, I don't want to update the weights by too much, or I could sort of skip over that local minimum or the global minimum and just end up, you know, at some other, some optimal location. Right. Okay. So if row here is a scalar, then the input would be d plus one by one. So this is going to be d dimensions. That is how many things I'm measuring about my sample plus one because, does anyone remember from last time? What's the, what's the one here referred to? Well, it has that effect. That's not really why we do it. Yeah. Yes, that's, that's, it's the bias. Haven't really talked about the term yet. I'll talk about that in a moment. But remember, we have, we're basically taking weight times input plus weight times input plus weight times input. So we have w zero plus X of zero plus w one times X one plus w two times X two until we get to W and times X n. It makes things a lot easier. If I assume that there's going to be some place that I have to basically shift my shift, shift my curve. Right. So it may not necessarily intercept the y axis at zero. If we're talking about say just a two dimensional curve. And so it basically the math works out much better if I assume that that X of zero value is one. And so then I can multiply by some weight associated weight value. And that allows me to do the entire operation as a matrix because it's basically a sum over every weight times every input. So one is like weight zero. Yeah, well, one is like the constant. One is the constant. This will get multiplied. This is the feature that will get multiplied by weight zero. And so effectively, we'll talk about this in a minute but effectively this is a dummy feature that contributes no real information, but can be useful in optimizing the weights. So your inputs should be of size D plus one. So the number of dimensions per sample plus this constant one. And so then T sub n will be K by one for K being the number of things I want to predict the number of outputs. And so the transpose of that will be one by K. And so then if this X, T, W is also one by K, then I can, I can effectively subtract those and I'll get meaningful information. Right. And so if I string these together in the calculation, this will give me D plus one by one times one by K. So these two inner values, this should cancel out. And so this should give me a D plus one by K matrix. And that's the shape that we want that weight matrix to be. Questions? Concerns? So in Python, if you look at the implementation, you can see that effectively, this is the same as this part here. Right. So I assume everybody knows Python syntax. So I take some value for W, I'm going to update it plus equals row. That's our value here. And then times X one. So the X one is going to be my inputs with this column of ones that I append to every sample. And I'm going to take, you know, basically one of these samples, transpose it, and then multiply that by T for that that particular sample, and then the predicted value, whatever the output of my, my function should be. So the non-matrix way of doing this would look like this. So if I have the number of outputs would be my target shape. I'll take the second element of that element, number one, and then number of inputs will be X one. Take the shape of that. And then for every, every element of an outputs, then for every element of an inputs, I will then update the weight W sub ik for basically the weight that corresponds to for that input for that, for that output, plus the update function. So more lines of code generally lead to more potential for bugs. And that's something that you want to avoid. So we prefer to do this the matrix way. And so that way you're either doing everything right or doing everything wrong. If you're doing everything wrong, it will become obvious and you can fix your operation. So hopefully this has motivated, you know, a couple of things. One, why we use matrices for these types of operations. Two, the different components that go into computing an error update. And three, the intuition behind trying to minimize the rate of change in your gradient. So hopefully at least have some, some, some idea of, well, that all those things are important and why they matter. Any questions before I go on to the example? These notebooks will be here on. So this one, if you click there, get you to it. Other questions. Yes. So one that is one technique that you can use. So row here will correspond to something called a learning rate. And this can be a constant or it can be changeable. And so it depends on your use case basically you can start with a very high learning rate and decrease it as time goes on, or you can assume that I'm just going to specify a constant learning rate. So it, you can do that if the use case is appropriate, you don't necessarily require to. Okay. All right. So, an example of SGD in action. So let's actually see this actually executed over some data the data is not necessarily going to be meaningful, but we'll see exactly how the, the update works. We will also do a little animation so you can kind of see the line that we're trying to fit to this data actually be shifted and moved and rotated in real time. So this is basically an affine transformation. So effectively I take a line, and I can rotate it I can stretch it I can move it up and down. But the things that are collinear and the input should be collinear and the output. So there's going to be a limited number of things you can actually do with linear regression, but it's always a good first step to try. So, we'll just make some random data. In this case I'm going to have 100 samples of random values between zero and 10. And then I'll assign the target to be some function, the output of this function here where epsilon is just a bit of noise sample from normal distribution. So that can be done here so here my hundred samples, I will take my inputs and create random values from uniform distribution between zero and 10. And then I'll just take this into an end samples by one matrix. And then I will apply this function to create T. So basically, two minus point one x plus point five. The quantity x minus six squared plus epsilon denoted here by just this sample from a normal distribution. What is NP dot random not normal. This derives random samples from a normal Gaussian distribution. So this default mean, what is the default mean of zero default standard deviation of one in the above example we're using standard deviation of point one, because we don't need that much noise. So I do this. And this doesn't look very good. Right. Just a little little pie plot thing. Be careful exactly how you're plotting your data. So by default, it will connect everything with a line. So I want to make sure that the inputs are generated randomly between zero and 10 they're not generated in order. So it's going to basically connect these points in that random order so instead I will just plot them as points using the period. So here, here's my input data. Right, and it's just some random samples between zero and 10. And then I apply that function to generate the outputs and we get this this sort of curve that looks kind of like the Nike swoosh reversed. Do you think we can fit a linear model to this data. Who thinks yes. Who thinks no. I mean, it's kind of a trick question you can. It's not going to be a great model but you can do it. So let's let's let's actually go about that. So the first thing we're going to do is we're going to take that input matrix. So remember this was created up here as x. And I'm going to include this initial column of a constant one. So now I will take my ex insert one at the front, and we'll call it x one. Where do I put the that concept column of ones. Actually you will see that vary across implementations and in fact I do it differently in my two classes in this class I inserted at the front in LP, the code is written such that we inserted at the back. It doesn't really matter as long as you know where that what constant column of ones is, so that you're, you're updating your bias weights in the right place. For this class we will be fairly consistent, and we will be inserting that constant column of ones at the front. So, your data always consists of your input value will be the sample which is x or x one of the bias, and the output values which are the targets T. So let's make sure that we have the right number of inputs and targets. This is the correct 100 by two and 100 by one. That should be. So we have our targets that should be 100 outputs that have them arranged in a column. And then here I have my hundred inputs, which are just single numbers, except now I've added this constant column of ones. So now, 100 by two. Okay, so I'm learning rate, so that's that row that we saw earlier so I'm going to specify it to be some small number. So in this case I'll do point 001. And then I need to make sure that the, you know, I get the number of samples. So this is just going to be the number of rows and my input. And so I can just save that out as into a variable that I can reuse. So, I'll initialize the weights to zeros. And so here I will train for however many epochs in this case I'll do 1000 so basically an epoch where someone's pronounced an epic. I've observed this to vary between mostly UK and American English, I believe I'm actually saying it the UK way maybe. Anyway, that's a basic number of, in this case a number of passes through the data set. So, when you get to more complicated models we have things like batch size. And so there's a difference between like step and an epoch. But effectively, when we people talk about this just consider passes through the entire data set so when you have like a huge data set say a big language model that you're training on. You may hear like oh yeah we trained chat GPT for 40 epochs something like 40 epochs doesn't sound like a lot but remember how much data that's being trained over. So first of all it takes forever. And also, that sheer amount of data is contributing so much information, every pass through it that you only need for you box or whatever to converge. So, this is when we talked about talking about neural nets this is one of those hyper parameters things that you can vary that you have direct control over in the process of training your model. So, let's step through this code so if I train for 1000 epochs, I'm going to make a prediction that prediction is why, right. So why is now going to be one sample. So, let's say I'm doing n for range and sample so I'm going to get the end sample, multiply it by the weights, w. So, that should give me some predicted value for this input sample, according to whatever these weights currently are. So, now I have the target. And so this t should correspond to this input. So this should be the ground truth target of whatever these inputs should are intended to predict. I'm going to take that and subtract why the prediction that I made. That's the error. Right. How wrong am I, this is the difference between predicted value and the target value. And so then I'm going to update the weights by a fraction of the negative derivative of that square error with respect to the weights. So this is the learning rate that's the row. And so now here, this is going to be the input transpose times the error value. So, and then when I'm done I will print my weights. So, try that. And we end up with these two weights of 3.125 and negative point 264. So now this should give me effectively a weight that corresponds to the input feature. And the second weight corresponds to what? Sorry, other way around. This way corresponds to the input feature, and this first way here corresponds to what? The bias. Right. So, sorry, momentarily forgot where I put the column of ones. So now that bias is this is this basically this is the y intercept. Right. So the bias is what do I assume about my model if I have no other information. So basically if my input contributed no information. What's the best starting point that would minimize my distance from the actual data. That's the bias bias in a technical sense this will be how we're using it in the class, although at the end we will talk about bias kind of in the colloquial sense. So the way we can think about it is this bias is, you know, we think of it as a prejudice, it sort of is, if it's like what do you, what conclusion you're going to leap to about something if you have no other information. Right, it's you you prejudge something that's your prejudice. So I gave this example of if I, if my going something as I see someone wearing a backwards baseball hat I assume that he's a jerk, but I don't know anything about him. But I see someone walking down the street and I just looks like a real loser. And I gave this example in my first NLP class I looked in front of me and there was a guy wearing a backwards baseball cap. Sorry, I've since taken him on as a research student I have observed he hasn't worn a back to a baseball cap since not going to read too much into that. I got a great paper out so I'm But basically this is like, and I don't actually think that about people who are backwards baseball caps I'm just an example that I happened to notice there was someone in front of me. But basically that's you that's your, that would be like a prejudice or something that you would assume. And then once you get to know the person or the sample right you actually know like these, this is, these are the other ways that I need to be. I need to be calibrating when I'm when I'm deciding things about about this phenomenon that I have encountered in the most abstract sense. But at this point of bias is basically, if I know the information my model of all my other features are zeros, for example, what's my best starting point. And so that's the bias and that corresponds to eventually there's a dummy feature this one that we train that weight against. Yes. Great question. So there is, there's a whole lot of research into how we do this hyper parameter optimization for neural networks. Effectively, a lot of people will just be using trial and error. And so in this class that's mostly what you're going to be doing. There are some techniques you can use like say grid search you can try out a bunch of different values of different, you know, say different training lengths and see which one of these is giving me the least error. And then maybe I can try and narrow down exactly what that sweet spot is. But it's actually, especially when we come to deeper neural networks, there's like just a whole lot of research and how can I optimize all the different hyper parameters that I'm trying to deal with because it's not just epochs here. He will hear it is just epochs but it's not just epochs in broader use cases to have things like the batch size, the number of samples that you pass through at each time. The learning rate, you know, so for example, the, the trade off between training number of epochs and the learning rate right that can be directly proportional in fact or in some of the inversely proportional. So if I take a smaller learning rate, I might train for longer and get a better result. Or if I were to take a larger learning rate I could maybe get away with training for less. So, there's no like this definitive answer, but it's an area of experimentation. Yeah. You will need to loop them manually if to do grid search. At least there's one assignment where you have to experiment with hyper parameters. And so for that, you're basically given code that does it for you, you just have to fill in like what numbers you want to try. For like your project and stuff yeah you can import whatever libraries would help you. I'm not going to try and make you write all the code by hand for that. But for for certain assignments. Effectively you're given starter code and you cannot modify outside of certain places. So, that's it. All right, so we train this model. And this is effectively doing y equals mx plus B in two dimensions at this point. And so now I'm going to see how well this linear model fits the data, so I can just do this by plotting the models predictions on top of the actual data. And this is the, this is our prediction so the blue dots are data, the red dots are prediction. And so here you can see this x one, that mall w, that's that prediction value again. So, what do you think. Not. All great I guess. Let's actually see what happens as we're doing the optimization over those thousand epochs so I can actually write this code that will basically run an animation so you can see where that line is as it's processing every sample. So in this case what I will do is I'll initialize all the weights to zero. And then I'm going to collect the weights. After every update to plot them. So this isn't part of training, this is just part of visualization. And then I'll create a bunch of x values, and then for every set every pass through all the samples. I will update my weights and then we all plot the line for those input samples across the actual inputs, so you can see the prediction. So, let's go. And so now you can see the black dot that's the last sample that was just trained on the line is the current state of the model. And then you can see also how those values of W zero and W one are changing over time. Right. So, you know, you can, you're free to adapt this code to do animations, and we'll do we'll have some examples of these in other notebooks, but effectively we can just run that again. And we can see how the line just starts like kind of pretty much wildly opposite the general direction of the data, and then eventually we can see, you know, it's being that that wider set is moving up toward that three point something value. And then it, and then we can see that the, the slope of the line is also decreasing. And so you can see that those values are getting close to these two values here. Right. So the the approximate y intercept is just shy of three, and then the slope of the line is like slightly negative. Okay, that makes sense I hope. Okay. And so now we can see also those those values that I'm sort of, I'm going to qualitatively evaluating based on just looking at this line are being plotted here so again, W zero ends up just short of 3.0, and then W one is in this case it's just a little bit below 0.0 or negative point one. Okay, so all this is to say that matrix multiplication is basically just solving systems of equations. Right, so I have a bunch of inputs, and I have some output corresponding to them. And I have a bunch of these different samples and I'm trying to optimize for the values that solve that large system of equations. So to give a simple example we can solve a pretty simple system of equations here. So if I have 4x minus 3y equals 17 and then x plus 4y equals nine, I'm trying to solve for the value of both x and y and I assume that you have done this, probably in like high school algebra class. So one way we can do this, the way that you may have learned is just through substitution, so I can solve for x at first. And I'll say okay if I saw for x using the bottom equation, I ended up with x equals nine minus four y. Okay, and so now I can take this value that I solved for, I solved for y or x in terms of y, and then I can take that value and substitute it back in for the value of x in the top equation. So now I have four times the quantity nine minus four y minus 3y equals 17. That's the top equation. So now if I expand this out I end up with 36 minus 16y minus 3y equals 36 minus 19y which is equal to 17. So if 36 minus 19y equals 17, then I subtract 36 from both sides, I have 19y equals negative 19, y equals negative one. Now I can take this value for y, substitute it back into any one of my equations to solve for x, and it turns out that x equals five. So this way allows me to solve the system, and I end up with two values for x and y of five and one. But we can also do this with matrices. So, the way this works is effectively the coefficients here in front of the two values I can just plot as the inputs, right, and then the values on the right hand side of the equal side, those are the targets. So I basically have some sample four and some sample negative three, and then I have some sample one and some sample four, right, so these two constitute one input, these two constitute another input, and then the corresponding outputs of 17 and nine. And so, if I solve it this way, so let's say I have my inputs x, and I'm trying to solve for the values in these coefficients here x and y, I can do this by taking the transpose of x and multiplying it by t, and this should give me something close to the expected value. So let me make sure I've run everything. And if I do the inverse function here, I end up with five and one. So, pretty neat way of solving systems of equations using matrices, we and we can demonstrate that we're getting the right values, comparing to another method that we're already familiar with. We can also use least squares. So this we're trying to least square solution. Remember we, this function returns a few different values so W residuals the rank of the matrix and s. If we just look at W, those are the ways we're trying to solve for it also gives me five and one. So, a couple of questions, you know what our residuals. So, from the doc string, basically if the rank of a is less than n or m is less than or equal to and this is going to be empty erase that's what we get here. And so now if I print the shape, the rank of matrix x and then the shape of x and t, and then compare them, we can see that a is not less than n but m is less than or equal to n and so that's why the residuals are empty. What are residuals. Okay, so here is the definition in a nutshell of errors versus residuals. So the error is going to be the deviation of the observed value from some unobservable true value of a quantity. Whereas the residual is going to be the difference between the observed value and the estimated value of a quantity. So, in this simple linear example. These don't really apply on that as we get exact values and we know what our true values are, and they're also the same. But the prediction step is basically x transpose times t to solve for w. So if t contains an exact values, or the values that correspond to x don't linearly predict t, then the best you can do is some form of approximation. So we have residuals in larger neural networks and also working with more naturalistic data sometimes a residual is better than an error, because it allows you to optimize for the approximation. All right, so in the last part, we're going to play with some real data. And so basically, if you want a hint about how to do assignment one, you're going to want to refer back to this section, because we're going to be doing some very similar things just the different data. So, first, we're going to use this automobile data set from this UC Irvine machine learning database repository. So, there are two things, auto data or auto mpg.data and auto mpg.names. So let me download those. So let's look at the data first. So this is the first step that you're going to want to do before beginning any experiment is to actually understand how your data is set up. And so every, every data set you download is going to be represented slightly differently you need to understand that how the data is represented and how it's organized before you can really make any progress. So, let's take a look at the contents of auto dash mpg.names. So, you will find that there are 398 samples, and each of them has these eight numerical attributes and a string. So the names those attributes are going to be the mpg, it's going to be continuous value number of cylinders which should be a multi valued discrete displacement and horsepower and weight and acceleration are all continuous values. So, the number is going to be a multi valued discrete right just just years origin is going to be a number corresponding to some, in this case country, and then the car name is a string. So this just relies to look it up. So first thing you want to do is import it into Python and look at it so we're going to use the pandas package that you all are should be familiar with. So, generally, in this course, import numpy import high plot import pandas and in later assignments import torch should get you pretty much everything you need, with the exception of like you know sis and OS and some other system level Python packages. But generally those four should cover everything that you need. Where, where, where the difference you will be notified of that. So let's look at some of the lines and figure out how to read it in. So, just a note in this, in this notebook there are two cells. One for unique systems and one for Windows systems command is slightly different so depending on if you're running the notebook, depending on which system you use you're going to run one or other of these of yourselves. Since you're using a Mac will use the UNIX version. So here's our data. So we're looking at say the first 40 samples. Let's take a look. Let's remember what those values stand for. So, 18 miles per gallon eight cylinders displacement of 307 horsepower 130 acceleration of 3504 model year of 12 or. So, sorry, the weight. Okay, yeah, yeah, wait a 30 seems like a lot of acceleration, weight of 3504 it's a very fast car. Acceleration of 12 model year 70 in this case, 19 x x. So 1970. And then one in this case corresponds to I believe the options are us Germany or Japan. And then, so one here corresponds to the US, and this is a Chevy Malibu. So this is organized it's not necessarily the, the most friendly organization, but you can do some things to make it more readable. Also you'll see that there are some NA values here. Right. So, in this case, there are some cars in this data set that for example we don't have the MPG value for. Right, so we're gonna have to handle that, and there may be any values in elsewhere in other columns. So, for example, I think it's maybe, yeah so one is us to is at least Europe, and then three is Japan or Asia, more broadly. So, let's look into a data frame. And here's what we get and this is not friendly at all. Right. So, first of all, a couple of nasty things one it just read in the first column is the header, we don't want that. And then we also read everything in in under the in a single line. Right, so we have to format this a little bit better. So, the pandas out reads CSV docstring will basically tell you all you can do in pandas, or you can read through this pandas tutorial. So, we're gonna just go to format this is the easier to read. So, first I'm going to pass in header none so they don't get that first row as the header, and then I'm going to do them there. Set whitespace as the delimiter. So now I get a nice format. So now I can actually get a nice looking data table. And I have my values in the first seven columns and then the name of the car in the eight. And then I also have 406 rows nine columns because they have this one index column here. So let's take a look at just a subsection here. So if you look at rows 30 to 39. I see a couple of things. One, there's some any nans here. So this is going to mess things up so I need to get rid of them. So here, I can just do this by setting any values equals question mark. So I love this again. Let me look at, I can't see any change here but I did know that there were some nans in rows 30 to 39. So let me look at these again. So now let me do this drop in a, and so now I have 396 rows or 392 rows. So it got rid of about 10 rows or so that had unfriendly values. So now let me look at that same sample. And I still have that NA. Well, something didn't quite go right here. Any ideas. So the NA was removed in a specific place, but not in the data frame. Yes. It didn't happen in place. So I did that and then returned that but it didn't modify. Right, so I did, I said, I did df.dropna, but I didn't, I didn't actually resave this into df so I'm basically doing df.iloc and so it didn't do that in place so the drop in a function is not by default in place. And so now if I do df.isna.sum, this will tell me, you know, how many NA values do I have in each column. Right, so there are eight in column zero and six in column three. So now if I don't do it in place if I do df equals df.dropna and I look at that same subset. Okay, now it looks nice and clean. So now if I run df.isna.sum, these are all zeros. So this is what you want. Right. This is one way to make sure that you have no NANDs in your, in your data. Okay. So if you run into difficulties with pandas, I recommend just reading the tutorial. Some things to note if you're not familiar with pandas, but you are familiar with NumPy. So it's not that easy that rows and columns are handled in NumPy versus pandas are different. And so it can be kind of frustrating and I personally like whenever we do a paper and I'm working on stuff. If it involves panda they usually spend like an hour trying to figure out like what I'm doing wrong with pandas. So just fair point you know if you start working with this, do allow time to figure out what the errors are and make sure that you are processing your data correctly, especially if the data is a large set that you can individually examine every row of. Any questions. Yeah. NumPy, pandas, pyplot, and torch. So, and you think we should import those for everything or we should import one of those third step routes? You will always use NumPy for this class. In the in the code you're given usually the standard imports that you need. But just if you're, this is mostly for the people who would like to import like your favorite third party package that like no one else has ever heard of. I'm just telling you, those four will get you everything you need to do. There's no need to get fancy. And, and even torch like we're probably not going to we're not going to use that until a lot of assignment three I think. Yes. So you can just do this, if you look at the the read CSV doc strings will tell you like what, what everything does. So basically, Oh god, it's lost up in here. So, NA values. So additional strings to recognize as nan. So like if there's if there's a question mark in the data set. It might just be like someone mistyped something that they don't have the value. So basically I will just I'll turn that into a nan, and then I can remove it. Okay. Other questions. All right, so the first step to doing any kind of data processing is examining the data, the next step is going to be to visualize it. So one thing we can do is we can just plot the value of every attribute in a separate graph. And so I'll make an array of columns, column names to label the y axes. So instead of doing zero through eight. So now if I set the column names, I can actually see what every column corresponds to I don't have to keep referring back to that list above. So this makes things again, easier to present easier to interpret so don't neglect these pre processing steps because it will save you a lot of time, it takes more time up front, saves you a whole lot more time at the end. Okay, so now if I just do df.plot. Well, that's not terribly helpful is it was a couple of reasons why one, one big one. Yeah, right weight is in pounds so it's like it's between you know 2000 to 5000 pounds these are cars. So of course I'm following these raw values, but I'm looking at weight 3500 versus year 70. I'm not going to be able to tell which one was made in 1970 versus 1971 I can't even really tell you know what the displacement values are. So, I want to separate these out. So if I take a look at everything except the car names I can just look at, you know, the, basically see the different ranges of the different values, and already I can observe even though there's some missing values here because there are nine columns. I have things that range from 70 to 82 and then also things that range from like in the hundreds to the 300s. So, if I look at the type of my value they're all float 64. Okay, I can work with that. So now I can plot every data column separately, and use. So I'll just use this code here, so I can plot all of my different samples kind of nicely side by side using sub plots. And so I'll plot the sample number on the x axis, and whichever parameter value is on the y axis. So, take a look at these charts. And tell me if you notice anything interesting about these about these samples. What sticks out to you about this what relationships you see between the samples, and the different parameters. Yeah. They seem to be already ordered by years we have this like step function here. Anything else. Does all for young get better over time, I think so yeah because like it's ordered by year and we can see that as we can use this the sample numbers of proxy for time. You can see that MPG seems to be getting better over time. What else do we see. Yeah. Horsepower tends to be decreasing on the maybe a slight correlation. Yeah, so there's a couple of things you might be able to reserve. The first observation that you have to make is that the sample number is ordered by year. Otherwise, if you didn't have this this one in the bottom left, you don't know what order you're in. Right. And so, now that I can see this, I can draw some conclusions based on what I know about cars we know that auto technology has gotten better over time and so a car that was made in a later year is probably on average going to have a better miles per gallon than one that was made early. So, anything anything else that seemed interesting about these. Yeah. So, Well, we don't really know I mean we want to look at we need to look at the data kind of an aggregate so just from looking at the individual graphs. The first inputs we can make is that they're ordered by time and that can tell that can give us some other intuition about like what things are correlated with time but we don't see things like how does horsepower correlate with displacement or miles per gallon. Yes, in the corner. Yeah, displacement is decreasing over time so like some of these things seem to be correlated with time, but we don't know are they really correlated with each other. Right. Is it that cars are getting heavier or what's any correlation with weight. Is it that cars getting lighter over time and is that correlated with, is it really the weight of the car that makes the horsepower go down or the displacement go down or something. Right. As opposed to the year. So plotting displacement as a function of year may not be all that meaningful when really the dependent variable is something else. So let's try to predict one attribute, namely miles per gallon from the other attributes. So, first we're going to make a 392 by one column vectors that's going to be the target values containing all of those MPG values, and then a three 92 by seven matrix to hold all the other values. So I have these eight samples and trying to predict the value in this graph from the other ones. And so that this can tell me whether MPG is correlated with any of these other things we observed is correlated by year. So what we can do with this knowledge we can see whether our model is making some of the same intuitive judgments that we are. And if it is, then it stands to reason that it's other predictions can probably be believed. Okay. So, let me get the target values this is going to be stored in T. So I'll just print all of those. So these, this is the MPG data for every car in my data set. So I have the two variables. And so this is the, these are all those other seven values. Let me just check my shapes to make sure that they are what I expect so I expect 392 samples. I have seven inputs associated with every sample now and a single target value. Alright, so now let me make sure that I have the names associated with the, the right values so I want MPG to be my target name, and all the others to be my, my x names. So now let me see if a linear model makes some sense. I can do this by plotting the target value MPG versus each of the input values. Alright, so now take a look at this. So this is miles per gallon in terms of the other variables. What do you notice here. Sorry, say again. Right yeah so there's a correlation between weight and miles per gallon. So, right so the lighter cars here have higher MPG. What else do you see. Yeah. Yeah, so the cars with greatest placement have low miles per gallon, which might suggest there is some correlation between weight and displacement. Right. What else do you see. Same with horsepower so we see basically similarly shaped curves. When we look at the weight displacement and horsepower relationships with miles per gallon. So these are the, those are some of the continuous values. Any correlations between some of the other ones and miles per gallon. Yeah, so, well, there should be this. Yeah, here. Yeah, here. So is there, is there, is it an inverse relationship or a positive relationship. Yeah. Yeah, so I do not know. Some weird things happened in 1981 so I heard this guy called Ronald Reagan right. And I would have to look at my history to see if there were like any major deregulations that happened in 1981 the automotive industry. So, it is possible in fact that maybe miles beyond did get worse from 1980 and 1981. So yeah there's literally just recording me just now. So, yeah. And then also a couple a couple other things to note here. So, there's a discreet value we only have a three through eight. But there seems to be an inverse relationship between miles per gallon and cylinders. Right. And those of you who know anything about cars that makes sense. Also, yeah so origin also. So, the American cars, European cars and Japanese cars. And definitely in the time span that this data was gathered. Japanese cars had a reputation for being a lot more fuel efficient and American cars were like pretty lousy. So there is a correlation between the, the origin at least, according to this coding, and the miles per gallon but just keep in mind. So, there's a sort of a arbitrary number that was assigned to each these categories if it had been, if Europe was one America was two and Japan was three what we see would be the sort of V shape. Right, it would not be easy to fight to fit a linear relationship to that. So, in certain cases with these like multinomial classification labels, the way you organize your data because very important this one simple change could throw off the entire linear model. Let us, yes. Yeah, so you could I mean, the first of all, with multinomial inputs, a linear model is always not is like not good anyway. So, it's not always true that the way this data is set up there is a linear relationship that this could be a helpful feature. But in most cases this is not. So if you any sort of language work, right, if you, how do you represent word as a number of a one technique would be to have a big one hot vector for the size of my vocabulary. So, for example, if I have a one in this I have a one in that space. But what that means is that every word is orthogonal to every other word, and I have no way of telling if cat and dog are more similar to each other than cat and truck. Right. And so that's the way that you organize your your inputs, and the way that you represent your inputs using more sophisticated techniques can be very important. So, in the last 15 minutes, let me finish this example. So we've observed some linear relationships between some of these parameters, and these seem to make sense, given you know what we know about cars even if we don't know very much. So, now that this seems like this. So now that we've done these relationships that could be useful. Let's build a linear model so first let's tack on this column of constant ones to the left side of my inputs. So now, this will take care of that coefficient multiplication with W zero. And so you just do this using NP inserts and be entered to basically the array, where you want to put the the new value, the value that you want to put it on and then the number of inputs that you want to be computing over. So here I'm just going to transform x into x one, using that command. So now I have a 392 by eight array. If I look at say a couple of samples the first three samples. It's now represented like this. And so it's in exponent notation here but you can see that the first value is a one now for everything. So now we can add to the x names to the constant column. We call this the bias weight so we'll add bias to our names. So now, if I were to show this in the data frame, my first column should be bias and it should be all ones. That's not very useful, because we know that's the bias, but this will come in handy later when we're trying to interpret the weights in our train model. We could try to fit the model to all the data and see how accurately we predict the miles per gallon for each sample. But that means this model is going to do really well on this data but if we show it other data, there's no guarantee that it's at all going to fit to that data, it could be, you know, wildly off, or it could fit perfectly we just don't know. So a much better way to avoid this kind of overfitting as we call it is to basically hold out some samples from the training so I'm going to train on a subset of the data, and then demonstrate that the model is working by evaluating it on new data that hasn't seen. So, this will work here, because we are reasonably assured that any data we remove will more or less resemble the data it was trained on, but we want to be kind of careful in how we partition that test set from that train set. So, one way this could go wrong. What if I just held out all the samples from 1982. Right, or what if there was some weird anomaly in 1981 because Reagan deregulated something. What if I held on my 81 and 82 data and it trained on 7380 and suddenly it's not a good fit for that 81 and 82 data. So, we have to be kind of careful about how we select that so how do we partition these joints, these subsets. So a common practice is to randomly select some portion as the test set, and then keep the rest of the training set. So a typical partition would be 8020. But you know you can you see you'll see different distributions 7030 9010 even 5050 sometimes if the, you know, if the data is particularly sparse or particularly information rich. So we'll stick to 8020. So we'll partition our samples and do our training and testing sets will just deal with the row indices, and then we can randomize those and then take that same selected slice to get those corresponding rows and x and t. So let me calculate the number of samples in the training set. So I've got 392 total. If I take 80% of that and round it it's gonna give me 314, then the remainder 78. So if I use an 8020 train test split. I'll have 314 training samples and 78 testing samples and that will cover all of this, the data that I've got. So now I want to randomly select those 314 rows and take the remaining samples as the training as the testing set. So what I will do is I will just shuffle all the rows. So now I have my rows arranged randomly. And then I will take my end train which is computed previously as 314. And then I'll take that first 314 as the train and the remainder as the test. So now I have, we see we started 4D158. So I take those first 314. These rows are going to be my training data, and these rows are going to be my testing data. Check and see if they're disjoint. Do intersect 1D, this should be empty. Okay, so now I have successfully partitioned my training for my testing. Okay, so now I can take those train indices elements of X1 that will be my X train, similarly for t train, and then you know the same for X test and t test. Check the shapes to make sure that everything looks good. I have 314 training samples, 314 targets, 78 testing inputs, 78 targets. Okay, great. So now I can use my SGD loop previously shown to find good weights. So first thing we're going to do is we'll add a calculation to track the error. So I want to see how quickly the sum of squared errors over all samples decreases. So as I optimize my weights, that sum of squared errors over all samples should be going down. That means that I'm optimizing my models toward that global minimum. More meaningful is actually the square root of the mean of squared errors to RMSE. This will be a common metric for these regression examples. This allows us to have the units of the error in the same units of the target variables, rather than their square. So I'm trying to predict miles per gallon, I want to know how many miles per gallon I am off, not how many miles per gallon, miles squared per gallon I am, because that doesn't really make sense. So this allows me to have an intuitive metric that I can then report my results and say I'm literally this far off on average. So RMSE is going to be taking all the residuals I'm computing over the training data, or all the errors of the testing data. So here we come back to that residual versus errors. So I don't have any ground truth in my from my test data in my training data so I can use the residuals to compute an approximation. Then I compute their quadratic mean where R is an element of the set of residuals or E is going to be an element of all those individual errors. Okay, so now let's run this. So in particular, look at the tiny size learning rate, and we can try running it again. So, if I have a train for in this case, what 50 epochs, we can see that this root mean squared error value is in fact decreasing. And this is what I want to see. So, 9.77 down from 19.1. If I increase the learning rate or decrease or decrease the learning rate. What happens so we start with a higher value, but we end up, or we start with a lower value we end up not quite as optimized right. So we can play around with this learning rate, let me increase it. But if I make it too big, then we run into problems. So, effectively what is happening here if learning rate is too big is, I'm, there's some global minimum, I'm trying to approach, and it sort of keeps skipping back, back and forth across it. And so I will never reach that. So learning rate is going to be a very important hyper parameter. We can also train for longer by train for hundred epochs instead. So, we can see that now I'm getting a RMSE of about 8.2. So let's see what happens with my linear model, which is now just these weight matrices, and I'll use it to predict W for the first four samples, or predict miles beyond for the first four samples. So, this gives me some, some values. Remember these are randomized so let me predict, compare them to the actual MPG values. So I'll take a two column matrix, or I can use a for loop to print them. So now it's predicting a value of nine for a true value of 14, a value of 19 for true value of 17 and so on. So it seems to be off but it's hard to tell like if it's consistently high or consistently low. So, you can play around with the values of learning rate and number of epochs, to find the values that result in lowest RMSE. Let me print these four samples. So, this is just a pretty print version of this matrix above. Okay, so now let's try all the test data and plot the results we can see over the entire test set, how good my model is. So, there we go. Okay, so this is, you know, choose one of these, I would say this is not great. It is consistently low. But I also want to know how numerically how wrong I am so let me calculate the RMSE. Our predictions are about eight miles per gallon off on average. So, a couple of things we can do to fix this. One thing is to standardize the variables. So, we've discovered that the learning rate has to be really really small to prevent these updates from resulting in Nan. And this because this is because this larger learning rate when I multiply by these inputs x. This will basically send me back off the far side of that gradient curve. And so, is there a general way to deal with this problem. So let's take a look at the different ranges of our values. So I plot the min max of everything, we can see that I have, you know, ignore the bias but things from like three to eight but also things from 1600 to over 5000. So since each input values multiplied by its own weight the magnitude is those weights are going to be very dependent on those range of those inputs. And so, the step size and gradient descent is going to be very dependent on the range of input values as well. So to minimize this will standardize our variables this means that according to the min max of weights. I just, I want to know like how close am I to the minimum maximum values rather than what's the absolute value, and that means that the min max of weight can be rated from like negative one to one or zero to one, and so can the min max of cylinders or year or anything else. So we need to do this. So basically what we'll do is we will adjust the range of all those input variables we have a mean of zero and a standard deviation of one overall to training samples. And so those values that are most dispersed from means that the highest standard deviation of the set. We don't want to do this with the, with the bias, because they're all ones, you can't compute a standard deviation over a set of constant values. So, you want to make sure when you're doing when you're doing the homework like standardize your values before you append or prepend that column of ones. And so now also to do this correctly when you're partitioning data into training and test sets. You need to also only calculate those means and standard deviations using the train set, so that you're standardizing the test set to the same range. You might have something that is outside the min max of the train set and the test set, but at least that that value that you standardize it to be meaningful if you're using the same means standard deviations that you calculate using the train set. So then you store the means and standard deviation training data and then use them again. So we calculate the means calculate standard deviations. So I apply those to the train set. And then now I can see that I can, I now have standardized values. So, these should be a lot friendlier for my SGD operation means of the same shape. And then I can also perform standardization using those calculated means on the on the test set. So now, let me try this again and note the much larger learning rate here. So now I can see that I have standardized values my root mean squared error is now in 50 epochs down to about 3.3 as opposed to nine point something before. So now I can make my predictions over my test set. And these look like they're a lot closer to those true values. So let's try it again with the test data and plot the results. And this seems to be much better fit. So now we have standardized variables are much less sensitive to different values of the learning rate. Finally, what's most important what's the most important feature for predicting this with a linear model we can actually see this with a neural net is much more difficult, but with linear model we can actually see which weights are correlated or inversely correlated with the outputs. So which of these attributes we use are most important for predicting MPG, maybe you can remove some if they're not useful. So by looking at the magnitude of the weights. We can see which ones are positively or negatively correlated with the output. So, for example, the bias is the bias that has no real correlation. So if you look at the or this is the min max. So you look at the ranges, we can see no change in the bias. The, the standardized variables range from like negative 1.5 to 1.5. Let's look at the weights. So these are the weights that are associated with everything. And we can print them according to those different values they're associated with. So, I'll give them three minutes left I'll tell you what you observe about these values. So the bias is 23, which is probably pretty close to kind of the average miles per gallon of this data. And so if I know other information, 23 seems like a pretty good guess. So, for example, we observe that MPG increases with time and in fact, year is highly positively correlated with MPG. We also saw that it's a negatively correlated with weight. And so we see a negative weight associated with the weight input. Right. And if I had a ton of different variables might be easier to sort them by their magnitudes, so I can do that. And then I can plot them, according to which parameter is the most important. So, yes. I'm sorry, say again. No, this is because this is to, this is to sort them in just descending order of magnitude. And so then I replot them with the signs here. Right. And so now I can see if I that the weight is very important, but it's got a negative value so it's very important but it's the inverse correlation. So, year is also pretty important, but it's not quite as positively correlated with MPG as weight is negatively correlated. Okay. And so you can look at this data and see what you might expect to correlate with predicting MPG positive weights indicate that this positive correlated negative weights indicate that's inversely correlated. Okay, so I will do the last bit on Thursday before we get into all the newer features, because we have no time left. But thank you and I will see you in a couple of days.