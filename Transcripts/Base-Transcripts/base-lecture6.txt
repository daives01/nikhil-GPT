 I'm sorry, several years in short. Sorry. I'm sorry. You're doing good. Okay. I want to go over. Go on. Okay. No. No. No. No. No. No. No. No. No. No. No. No. No. No. No. No. No. No. No. No. No. No. No. No. No. No. No. Okay. Let's get started. Sorry. I'm running late. Is late bringing your. Faculty candidate back from lunch. Okay. All right. So today I'm going to finish up the introduction to neural networks. I'm going to go back to the next notebook and then time permitting. I'll start the next one, which I think is Adam. Optimizer, if I remember correctly. So what I'll do, I'll just recap kind of gradient descent, very left off last time. And then continue to the end with demonstration. And the code. So assignment one is due a week from today for most of you. So I hope you all have made progress. I had some people come to office hours. So clearly some of you are working on it. So I just recommend that. Everybody take advantage of office hours if you need any help. Cause things are only going to get more complicated from here. So if there are any other questions before I get started. Let me share the screen to zoom. All right. No questions. But. The material or general class procedures. All right. So let's get going then. There it is. All right. So just recall how we train my gradient descent. It's pretty much the same neural networks as training in linear operations. In that we are taking the error between some prediction, why, and some target T. And then we square it. And then we square it. And then we square it. And then you sum that squared error for all of our samples. So the only trick here is that we may have some n number of samples for each sample. We want to predict some k number of outputs. Right. So now you're having a many to many correspondence. And so for every sample for every output, you need to compute the equivalent error between your prediction of that output for that sample to the target value. So just to clarify a point, the targets. This is just a question that came up in office hours. The targets are the things. That's known, right? Known data that you're trying to optimize the model to predict. So target T. Why is the output of a function. So if we assume that there is some function. F of X parameterized by W X is your input. That function outputs why your task is then to solve for W. The trick with neural networks is that there may be a nonlinear function. And your goal is to optimize the weights for a nonlinear function. And we do that by basically performing linear operations. And then taking some nonlinear function and taking the output linear operation as the input to nonlinear function. The nonlinear function is an activation function. The one we're working with currently is 10 H. There are others that I will go to go into in within a few lectures. But for the moment, we can assume that the 10 H function is the nonlinear function of choice. And it has some nice properties such as being linear near zero and less linear as the was the inputs go to more extreme values. So the trick because the error is not a linear function of the parameters. We have to set the derivative. We cannot set the derivative equal to zero and solve for them. But you can do gradient set in the same way. Right. So the only thing is you just have to update the equivalent weights for every function. So the only thing that you can do is just to update the equivalent weights for every input to the said weight matrix, be that your W for everything that that weight matrix is intended to output. So as we saw the update the delta rule for V, the hidden layer weights is pretty straightforward. So we break down what happens here with the DEDV. And that's fairly familiar. So for example, this is the two outputs. If you look at one output here. The DEDV is simply the partial derivative of the squared error, right, with respect to V. We then can use the chain rule to break down what everything in this term actually means in terms of other values in our, in our equation. So just recall that Z is, at this point, can the output of the hidden layer. There's a scalar value that's not intended to be inherently meaningful. But when the network is optimized, the output of this hidden layer should be useful information for the computation in the subsequent layer. So the first thing that we can do is just to make sure that the number of the parameters in this case for a two layer neural network, the output layer. The, what is Z is actually the, is actually H of a, where a is the scalar value becomes out of the linear operation. We perform a non linear operation in this case, 10 H over it. So therefore, we're going to use the partial derivative of 10 or the derivative of 10 H to complete the partial derivative, which is going to be one minus 10 H squared. So we have the weights, we have the, the partial, the derivative of the activation function, we have the input. Now we add another output. The only real difference is that we now have to sum the squared errors for each output. So this is just a recap of what we did last time. So what we end up with is that the delta rule for the hidden layer, where there are two outputs of this hidden layer. We need to sum that, that error for each output. And in this case, if we were only trying to optimize the weights for a single output node. So the function remains the same. So we have this error term, the, which is the input to that, that layer, and then a constant. So now the delta rules involving the, or the rules involving the deltas. Look like this, we have the learning rate for the output layer, the error term, the input. This can be written, you know, delta sub one zero or oh. So then for the hidden layer, the error term is going to be the, the sum, the sum of the errors for each of the individual outputs, times those respective weights. Okay, so that was just a recap of what we talked about Tuesday. Any questions after that refresher. All right. So the full version of back propagation is going to look something like this so take. Just look at a single, a single weight here let's take the sub D one, which I think this is usually zero here is this one here looks like a type of. So what we're looking at, just how we update this single weight given some set of outputs that depend on the output of this node. Right, this should look familiar, compared to the one above here, the only difference is we're now dealing with an arbitrary number of outputs. So what we do here is this error term is going to be output Y one, minus the equivalent target, and then output Y two minus T two and output Y. Y K minus T K and this should be, you should be K is there not to. I didn't make this figure I'll try and see if I can Photoshop it to be correct. So what we do then is these things will need to be summed. And then we will take so if you look at the function here effectively we're doing here is now this generalizes to whatever number of outputs we actually have so it's T one minus Y one times W one plus T two minus Y two times W two, and so on and so on until we get to T K minus Y K times W can. Right. So we only have to use the derivative of the activation function once because we're simply looking at how to update one way in one node. So here this this H is going to be activation function that produces Z. And so all of these then will need to be summed multiplied by one minus the activation function or the activation service of the activation function squared, times the input to this node. So what I need to do here that is different with multiple nodes is going to be doing this at scale for every single one of these. So as you can imagine this starts to grow somewhat out of control if I were to try to do it, you know, element wise using these update rules. So we're going to do then is we're simply going to apply matrix multiplication and matrix operations do this. So here we have the update rule for an individual weight, the sub JM. I'm going to take the current value of that minus the learning rate times the direct the error to respect to that weight. Same thing for the output layer weights and we saw how these terms here will break down into the, the full formula depending on whether I'm looking at a hidden layer weight, whose update will depends on what happens in the output layer, or I'm simply going to do that. So the reason that we're going to do this is because we're going to do this in the input layer weight, where the only real thing that I have to calculate is the error in that output term. Right. So the reason that neural networks get more complicated is really entirely because of these hidden layers. So we have if instead of this, if this yellow, these yellow nodes weren't here, and they're going straight from input to output, it would be the same as linear function. I'm simply just trying to optimize the weights here. Because the assumption is that there's no non linearity, this is a aggressor. There's no non linearity being applied here. So there's no non linear function. Does it really do I need to take in order to be okay. But one thing you what this means then is that one neat trick you can do is that you can actually create neural networks that you can use to just do like red regression. And you can, if you set up the code correctly, you can use it the exact same way and basically just say I want to have no hidden layers in this, and it'll perform the same as a linear model, which means that a linear model is a good baseline and also when we get to certain assignments, you can set up your neural network in that way to compare the neural network to effectively linear model with no significant changes to the computer. And then the significant changes to the code except for specifying some of those hyper parameters about the layers. So, we took these original update rules. We saw the operations that lead us to these expressions for doing gradient descent. So right here we hit the here is the error the element wise error term times the relevant weight. And here now it's for simplicity sake before we ignored the addition of the bias column, just to show how the math worked. But now we can add it back, right, in order to make the matrix operations work correctly so why are we doing this. If we're just looking at a single how to update a single way. It doesn't matter whether that weight is sort of a meaningful way to a bias weight. The update is the same. And I want to make these into matrix operations. Remember the math works out much more cleanly if I have this bias column, so that I can assume that w zero times x zero is simply w zero times one. Right, because that first column x zero for every sample is one and so we can turn this into basically your standard and dimensional linear function with some sort of Y intercept. So, hence being the Z tilde and the X tilde, if you remember from last time reason it's sort of notation to signify some weight matrix that comes with the addition of a bias column. So, so if we look at these, let's work on, you know, driving this result using the, the output layer weights. So here, this is kind of our standard formula for computing the, the total squared error for all sample for the output. So here what I will do then is I will simply take the derivative of both sides. This allows me to bring this negative to down in front. So now I'm simply summing over for all n for all K, the error terms and then multiply that by the derivative of the of the the output with respect to the weight. So, what is Y sub n K prime? Well, this is equal to for all m, which remember that's the output of our hidden layer. Further, so that's the weights are in our, in our layer. So for all m I'm going to take weight. m prime K prime times Z and m prime. And so now this works out eventually, kind of skipping through the math here, but eventually they take the derivative of both sides here I can then take the derivative of the thing that we just saw here. Right, so we were driving this. This is the how it can be written so I can put that into the partial derivative function there. And then eventually this will kind of cancel out to this part here. So now we have basically a constant times one over n times one over K times the sum for all n remember that's all samples times the sum for all n of the target and sub K or sort of target T sub n K minus Y sub n K. So that is the target value for that sample for that output minus the predicted value for that sample for that output times the relevant inputs to the output layer. Right, so I apologize for alternating terms input and output Z is going to be that input to the output layer for sample and for output of the hidden layer m. So, and here is just one of those columns in that hidden layer matrix. This is not something that is, again, a meaningful, like scalar value that has any real interpretation. And then it's simply some sort of feature that will inform what T sub n K would be. Okay, so we can think of this as if I had a single layer, just some linear function, where I have kind of random outputs, or stochastic outputs, or arbitrarily derived outputs. This part of the neural network, this hidden layer that output Z will allow me to approximate those values. Now, the intuition there is that those values are somehow useful numerical features for predicting the true output that we're actually interested in. So, I'm going to add some of those ones about that intuition. Okay. So that was just for the output layer. So now the harder one, of course, is going to be optimizing those hidden layer weights, because we are dependent upon how wrong those outputs of the hidden layer weights were when predicting the final output. And then you can think of it as a function over X produces Z and a function over Z produces Y. I'm trying to update, though, I'm trying to get the appropriate values of Z to map from X to Y. But you'll notice that Z does not directly involve Y, even though it does directly involve X. So, I have to use some error in Y to correctly update Z for the appropriate weights for processing X. So therefore I need to know, you know, how many outputs, how wrong are all the outputs that derived from a particular term in Z. So we'll begin with the same, the same formula. So the error formula is the same. And the derivative is going to be the same as above now, knowing that Y sub n K is equal to the formula given previously. So then I can substitute substitute this in for Z. So whoever is he is going to be the output of the hidden layer over some function of X. Right. So if I take V, my hidden layer weights times X my inputs, and then I apply some function H to it, this is going to be equivalent to Z. So now we can rewrite this. And so now if I'm looking at basically what is, I'm trying to calculate what D Z DV is I can take all this whole monster here, and, and stick it in where I'm trying to calculate Z. Okay. So now I'll just, because this is really gnarly and hard to read, I will just let H of V X equal B equal to A. Yes. The D this one here. This is going to be the number of things I measure about X. So we'll talk about X as being an N by D matrix, meaning that every X is like a number is some sample number N. And then there's something about that I'm that I'm measuring D and I have D things. Okay. So let's, um, a equal equal H of big V times B, big X. And so then I can just, I'll use a in place of this, this normally equation there. So now I can rewrite this as below. So then after some simplification, I end up with the following equation so negative two times one over N times one over K times the sum for all N times the sum for all K of again the error term here. And then times the sum for all M that is all outputs of the hidden layer of W sub M prime K prime times effectively d Z, because we wrote Z is this D Z da where A is the input to Z times X. Okay. So that's now work backwards. Remember what all these things refer to X is the inputs. A is going to be some weights times X. Right. So that's the course both in the numerator and the denominator of this derivative. The trick is that in the numerator applying some activation function non linear function H to this. The told is there because that output has to have this column of ones appended to it so that it can be an argument to another linear, another linear operation in the next layer. That next layer is parameterized by weights W. Right. And so every W is going to take in N, like we can call them inputs. Right. This is just inputs of the hidden layer, not the same as the raw inputs to the network. But there are M things that go into W. And for each of those M things we want to produce K things. Okay. So, and M by K matrix. So that's this part. The first part here is effectively what you should be familiar with now error term average overall samples and all outputs. So to summarize error function that you should be familiar with just a squared error. And then the derivative of that error with respect to each weights, depending is going to differ depending on which layer that weight is in. So we can have arbitrarily large networks where all the hidden layers have update functions that are some form of this, this, or this one here at the bottom here I'm kind of bouncing over. And then the output function is going to just be a version of this for this to update the output weights. Right. That was back propagation. That is, how do we update those individual weights based on prediction error. But how do we get that prediction in the first place. This is going to be the forward pass so when you're writing a neural network, basically have the forward function, which is I'm going to use my network in its current state. And if I'm in training, I'm going to assume that current state is not optimized and that's going to give me some error that I can use to opt better optimize those weights using the backward pass so the forward pass. This is effectively right. Remember what this is. This is going to be made big matrix V times big matrix X. And this is just broken down in terms of the individual elements. Then I apply each some activation function over this gives me Z. Right. So each individual element of Z Z for sample N, and then quote hidden output M will be defined by this. And then finally I'm going to take all of that at a column of at a one on front of if necessary. And then for each element in that updated matrix, I'm going to multiply that by the equivalent weight, and then take the sum over that for all M. That is all things that go into the up the up with the. And the backwards pass is given by the equations that we drive previously. Okay. So that was all the mathematics, which took us probably in total an hour to get through between Tuesday and today. So you can go through this and this is I believe the most math heavy notebook in terms of like individual equations that I have written out. But if you are interested in how all this comes together, you can review this, but you don't have to actually worry about this so much for doing the assignments, which I think is going to be a relief to most people. So, let's actually go through the process of turning the mathematical equations into functional Python code. The first thing we're going to do is right we've been looking at these individual scalar operations I'm operating over some individual input sample for some individual measurement about that sample right it's going to be x sub n d. I also have let's say z sub n m, which is going to be some function over some individual x time some weight V, right. This is going to produce some value. And m, which is going to be for every in every input sample of all and I want to produce m measurable scalar is about it. Right. So these are just unit list numbers effectively. And then finally I'm going to take that whole thing for each one of those apply some activation function to it the 10 h function. And then for each of those outputs. I'm going to pass it into another set of weights that's going to give me the key things I actually care about. And then I use the error to optimize both weights in the end w. And of course, what I said in lecture three is basically don't use for loops because that they're slow. And it just introduces a lot more opportunity for error. So we're going to take advantage of matrix multiplication. So the first thing we're going to do is convert these individual scalar operations into matrix matrix expression so if you have the version of how we define z sub n m as as this. So we're going to get rid of this, this, the sum operation here by combining things into rows and vectors or rows and columns. So we have, you know, h for the sum arbitrary arbitrary column, or arbitrary row, times x for some arbitrary column. So, so now as long as these things match up, then I can start to rewrite my equation so z sub n m will basically be I'm going to take, I don't care about the row. I'm just going to take all of the m in whichever row it is times all of the n rows in whichever column it is. Right, this allows me to actually perform a single matrix operation to get one term of the output matrix. So I'm just going to use the community of property swap these two things around here. And so now for every, every row and every column, I can just collapse this into one big matrix. So, X toda is going to be my inputs with the bias, and then V toda is just going to be my, my hidden layer weights, as long as these things are the right shape. So I'm going to multiply, because all I have to do is make sure that these two inner terms are the same right so the star here is going to be some variable. And as long as these two have the same number of items, I can perform the whole thing as a single matrix operation. So now I do that. If I just perform this non linear function or that's just that's just going to operate element wise, right so I'll take the 10 nature now every element of this resulting matrix, and that will give me easy. And then the same thing basically applies applies there. So I just want to get rid of the sun sign and so all I need to do is make sure that I can rewrite my operation so that I have some input that has the same number of columns as the other thing has the same number of roads. And so if I can manage that, then I can collapse both Z and W into big matrices to. And so now I have Z told times W and that's going to give me why. So this part is should be pretty straightforward. I'm just looking to make sure that for every individual element. I have a matrix of the appropriate shape that can be multiplied to something else. And the backwards pass for V. Well, it is more complicated. So we just have to do some, some more manipulations of the of the individual numbers in order to get the, in order to get the matrices to be in the right shape. So here's the individual operation. I'm trying to get rid of these some signs and get rid of the the sum over K by basically taking the column K to be some arbitrary number. So this will allow me to do that was rewrite those the stars here. You don't think any new division. Oh, sorry, what was that. It wasn't me. It's like I've never heard that sound like Peter before. So it's a little worry. Oh, press here to power off the projector now press your teeth. Projector must have been on time on for a long time. Okay. We will hope that it doesn't die before classes over. If it does, we had to spend another 10 neural networks. Okay, so backwards pass. So about to try to do is I'm trying to get first I'm trying to get rid of the some signs I can get rid of the, the, the sum over K by turning this into just some arbitrary column. You know, the thing I need to do there is I need to make sure to transpose the weight matrix here. So I'm because I don't have any community property that I can just use to swap these two things to make sure that the dimensions align instead, because I'm going to take this to be a column matrix minus the column matrix times a column matrix. The result of this is going to be a column matrix. And so then I will, or sorry, my bad. This is a row matrix minus a row matrix times a row matrix. So the result of this will be a row matrix. So in order to turn this into a column matrix, I just have to transpose it. In NumPy, you do not actually have to do this for individual rows, remember, because if I have a one dimensional array, I can just multiply them together. And then using the map mall operator, it will give me a single number. So NumPy will basically course the shape for you. But you're almost never going to have single row or column matrices and dealing with neural networks. So you can assume this is always going to be the case. So the next thing I want to get rid of now is the sum over N. So what do I do there? So this remains the same as before. And so now I need to do something with the ends to turn them into arbitrary rows. Right. So if I rewrite these as stars, I just have to make sure that I'm doing this, basically for all for all N for each individual and in that row. Similarly, because I again don't really have a nice, what I want to do is I want to make sure that the inner dimensions of this thing aligns with this thing. Right. This is not really easy. I have to compute all of this in order to figure out whether the dimensions are right. But I can already tell that I'm going to have I've got N items that have M individual corresponding columns. And then I have multiple that by something that also has N rows for J columns. So in order to get basically the two N size dimensions on the inner. All I'm going to do is just transpose this whole thing. Right. So the shapes of this line up such that I end up with N by M. And so if I transpose it, then I'm going to have an end by M, which is going to multiply nicely. So I'm almost there, except I have this problem in that the right side has subscripts written in terms of MJ or M and some other, some other elements, whereas the left side is J. So I have to make sure to line these up because I can't take V sub J M and then, and then add something that is in terms of something sub MJ. And then I will want the dimensions are going to line up and I'll be adding or subtracting like the wrong element from the in the update matrix from the wrong element in the thing to be updated. Okay, so then what I will do here is so I have this is the update function, according to what I had computed previously. So what I will do is first I'm going to transpose it. Okay. Now this allows me to swap the individual dimensions. And then what I can do is I can treat for V for every row J, every column M, then I will be able to take the learning rate times one over N times one over K. So for all inputs and all all outputs, times the transpose input times the whole error function times the transpose weights, element wise multiplied by the derivative of the activation function. So, the end result now is now I've got things all lined up. I've got, I can treat these arbitrary members elements of the, of the matrix, just in as as individuals. So if I can handle them all the same I can collapse everything into a big matrix. So given this I can take so V is going to be some new hidden layer weights. And for that I'll take the previous hidden layer weights, plus the learning learning rate times one over N times one over K times the transpose input times the error times the output times one over one minus z in this case the derivative of the of 10 H. So, this w with the carrot is going to be w without the constant input row. So this is just going to be sort of raw w or w to double is w with the with the bias. And so now the backwards pass for w works out rather similarly. So the first thing I'm going to get rid of is the sum. This is pretty easy because I only have one something rid of so we can basically do it the same way. Again, all I need to do is transpose the resulting array that results from taking the error term for every row, and then multiply that by z by z Again, my subscripts are a little bit in birded. So the right side has nk or so the left side is mk, but the right side has as k and m. So then what I will do is I'll take, I'll take these two terms and just switch them using the community of property. And so now this allows me to turn these into row arbitrary rows arbitrary columns, and therefore I can collapse now everything in this into a big matrix. So, w is going to be old w plus learning rate times whenever n times whenever k times the transpose input to the hidden layer so this is now playing the same role as X told did in in the above. Right, so these two are kind of playing equivalent roles here. And then this is just the raw error. My T all my T's minus all my Y. And so now the shapes of these should work out correctly. And so now all together in math. Right, what is Z, Z is some function H applied over bias X times V. And then I apply a pen to prepend a bias to my my Z multiply that by w I get. And then the update for V is going to have to incorporate a couple of other things right not only the inputs and the error, but also the also the weights things that are to be updated in the subsequent layer. And then the derivative of the activation function the nonlinear function being applied. And then w is kind of the same just simplified. Basically the only thing different, this is, this can be considered the w update can be considered a special case of the update where the activation function. The activation function is just a linear pastor so X equals X. What's the derivative of Y equals X it's one so this is just the same as multiplying by the derivative of Y equals X, which is one. And there are no weights. There are no subsequent weights to be updated. So I don't need to add, I don't need to multiply by anything here. Okay. So that was the mathematics now how do we do this in Python so your code is going to look something like this, right, this is not necessarily going to be exactly what you're going to do in assignment to, but this is generally the shape of the code. So first of all, I'm going to take an input X and a target T. What I want to do is I want to do this forward pass. Right, that's these two things are the first two things up here is a Z and Y. So what I'm going to do for that is I will just add ones to X. So this is this add ones function. Can be assumed to be some function that's just going to put a constant column of ones on the front of your input matrix. Okay. So I'll just call that X one allows me to keep things straight. So then I will multiply X one and V. This is going to give me what I was previously referring to as a. So I'm going to use my non linear function. This is going to give me Z here. Right. So, Z equals H of X V is that's what's happening in these first two lines. I have to add a column of ones on the front of Z. So I'll apply that same add ones function. And then I take this Z one multiply it by W. This gives me my output. So now. For the backtop step, I'm going to do gradient descent on the derivative of the squared error with respect to each weight to update V and W. So first thing. I'm going to reuse T minus Y in a bunch of places. So I'll just calculate that as the error. And so now if you look at these two columns here, or these two rows here. You should be able to see that they're basically just reproducing in Python what we did here. So what is V, it is the previous value of the plus some learning rate times. X one X one transpose times the error times the W transpose and then element wise multiplied by the by the derivative of the 10 H function. And then W is going to be the same thing. So why am I not really using one over and one over K. Well, I know the sizes of an or K. So just just a constant. I don't really need to worry about that. All right, questions. All right. So the above equation is going to this is going to be like a single gradient descent step. So we're going to be using all of our training data and X and T to calculate the gradient of E with respect to the weights. So we don't want to use the for loop. So we're going to actually use instead of writing the for we're going to be using the full gradient. So here's an example. This is just dummy data. So this data doesn't signify anything. What I'm going to do is I want to create a non linear function on that I can fit a neural network to this. So if you recall from like assignment three, if this loads. So we had like we did some exercises where we had this function that was at best only vague, the best vaguely linear. This is a long notebook. This one here. Right. So we created some function that this is really a non linear function. Right. Because I was I created a some some dummy data and then applied a polynomial over it. So we know that that's likely to be a non linear function. And so now my goal is instead of just fitting a line to that, which is a pretty lousy fit. I want to try and fit a non linear function to it using a neural network. So for example, here's a function that has clearly some non linearities in it with the use of sign. And I'm going to try and fit a neural network to this using a using non linear functions. So I will apply some noise to make things a little bit more interesting. So this epsilon is going to be a random variable drawn from the standard normal distribution between with a range of negative 10 and 10. Okay, so let's see what it looks like. So let me do my imports. So first I'll make some training data. And I'll create some helper functions. So this is I'm just going to create some training data that is where the inputs are evenly spaced across some some domain. And then I'll take the dysfunction apply that to that to that to that data to create this non linear function. And I'll do the same thing with some testing data where I have just different inputs that are random that are sampled differently. So these are generating using the lin space function. The X test is basically, I take the train data and add a little bit of noise to it. And then I'm going to try to figure out the way that the testing data is going to be completely out of distribution. But enough that it like it's close, but it hasn't been seen before. That's just the idea here. And so that is, even though this is dealing with random random inputs here. This is what you should expect for pretty much any type of machine learning problem if you wanted to behave well. That is the training, the training data and the testing data should be more or less resemblance. Right. If I'm trying to use my network fitted to weather to classify miles per gallon. And the same is true for for neural networks as well. Okay, so now I'm going to add this helper function term running every cell. So I had this helper function at ones. And so this is just doing what we did previously in notebook three, just in a convenient wrapper function. So I'll standardize standardization in this case is the same as we did for for the near regression. So I'll compute means and standard deviations over the training data, and then I will standardize both the training data and the testing data using those computed means and standards. Take this. Now I apply the add ones function to both my training and my testing data. I'll do this right now so that when I get to the evaluation phase. My testing data is the shape that I might never expect. So generally good practices just to make sure that you have your data all set up in advance. Before you before you're going to use it. And then just make sure that you're not accidentally inputting the testing data into your training function or something. Okay, so previously we did our weight initialization in in assignment one and in lecture three, using just initializing them all to zeros. So here with the neural network we're going to actually initialize the weights to random values. So if all the weights are initialized to zero, all those hidden units will earn identical weight updates. And if we have only like one hidden units. Okay. And so basically you cannot reliably get your network to fit when you are initializing your rates to zeros with most never burn touches. You could also, you could do assignment three using random initialization of weights. It's just that. So a couple of things that happened one, your code may not pass the automated greater because we have no expected values assuming that you initialize using zero, but also, even if you even if that weren't a factor. Different initialization will take longer or different times to converge, because you don't know exactly what the initialized weights are. And so you don't know how many grading updates steps you need to get to the same level of root mean squared error. So with neural networks. This is a pitfall in that if you have different way of initializations you may get different results. Usually, if the data is such that the network and the network architecture is such that it can converge. You don't end up with a radical difference in many cases. But generally it's good practice reproducibility to you things like set a constant random seed to make sure that you're initializing effectively to deterministic values. Okay, so now let's set the parameters of our, of our neural network. The first thing I want to specify is how big is this hidden layer. Right, so I have N samples and I have D things that I want to measure about this, and I have K things that I want to predict. But somewhere in there there's a transformation by some dimensionality M right now basically have to decide the size of them. So, I'll use 20. The, the, the number of the numbers that you choose has certain implications for the results of your training based on the nature of the data. And normally people arrive at the appropriate number of hidden layers hidden units by some sort of empirical evaluation or trial and error or grid search. There are more sophisticated techniques that you can use that are somewhat outside the scope of this class, but there are some tool kits that will do things like hyperparameter search for you. All right, for the moment, we'll just say okay we'll use 20 hidden hidden units. I'm going to specify two learning rates one for the one for the hidden layer and one for the output layer. So, you know, you can visualize these to be constant. You can use some techniques based on the sample size. So now we're going to initialize V and W randomly. Right, so I will initialize in this case from the same distribution. All I need to do is make sure that they're the right shape so I have X train that shape one that's the number that's D. That's a number of things measured about each sample plus one for the bias column. And then the output of this has to be the same number of hidden units. Right, so the output shape of this should be hidden units. And then I have had one to that and then the output of the output size is the this outer dimension of W. So, set the number of epoxy this case on 200,000. I'll collect a couple of things for plotting training and testing error. So now here's the, here's sort of the real operation. So I will perform the forward pass and remember I've already applied add ones to X train so that's done for me. Multiply that by the take the 10 age of that. Apply the add ones function to the output, that gives me Z one, and then Y equals Z one. And so that is basically what we are doing up here. Next thing. Is the, I'll compete the error. Right, so this is going to be T train S minus Y. So these are the training targets and then the prediction. So now the backwards pass. These are just the two functions that I created before. So the only thing that's really different here is I'm using X train S instead of just like X one. So you have to make sure that you're using the right. Usually if you're putting in if you assigned multiple variables to different splits of the data and use the wrong one, it'll probably just throw some shape error. That should be pretty easy to spot. All right, so now. After this, this allows me to do the forward passing a single line. So if we break this down. To the, to predict the test. I can take just take the add ones function, apply that over the output of the linear operation here. So if you work outwards. This is X times V. Plus with the ones. Take the 10 age add ones again, multiply that by by W. And now this allows me to. To compute the error relative to the testing data. All right, so now then what I can do is I can collect collect the error traces for plotting and then all this, this is just a matplot lip functions. All right, so now we've run this and we can actually see this network working in real time. So here we can see the root means where the error on the Y axis plotted versus the training epochs on the X axis. And this will run for about a hundred thousand training epochs. And so you can see that the training. Error is much lower, but we also see some significant progress in the testing error. And nonetheless, the testing error kind of appears to bottom out at around maybe point to five, whereas the training error is much lower. So this, this network should be able to fit this data decently well. We can look and see what the predictions are. Right. So here we have training samples. So this is the, I'll see plot the actual and predicted given the training data, the testing data and the model for every X. Right. So if I run this again, we actually watch this, this second one. Oh, maybe not. I guess this does that. I thought this was going to like animate in real time. I guess it didn't said to do that. So what we see here is now this is going to be the blue line is going to be the training. Okay, guess it is moving a little bit faster than that. So what we see here now, I guess the point I'm trying to make here is blue line is the training data. The green line is the fit to the training data. This is the model. So you can see that the blue line and the green line are pretty close. Right. So the green is the predicted values of the blue line is the actual values and the orange line is the testing data, which overall is still pretty good like as a decent fit. But it's not quite as good. So we can see how this, this higher testing error is being reflected in the in the outputs unit. Final thing is what are the different, what are the different units actually predicting so the will just look at the output units. Sorry, the hidden units. And so for X, there's like 20 lines here. You can only really see a few of them because most of them are basically these lines clustered near Y equals zero. But you can see how like for some of these units for different values of X, they're outputting different values. So these hidden units. If we look in just see sort of how many of these are not just clustered here at Y equals zero, you know, one, two, three, four, five, six, seven, eight, maybe. There's maybe eight units that are probably doing most of the work, whereas the bulk of the units are either always outputting is a very small value. And then the sum like this one here, whatever it's optimized to is basically a right around zero. It's changing its output from very positive to very negative. This is going to be after the application of the 10 H function. Because that is going to bound us between negative one and one. All right. So that's the end of intro to neural networks questions. I'll go quickly through, well, start Adam at least. Before we, before we dismiss. Right. Any questions about neural operations. Yeah. How do you decide the right plot for yeah I mean, it depends on what you're trying to visualize. Right. So, for example, if you're plotting training and testing loss or error. You know, this is something that you'll see commonly. So you'll see training time. And then the error or the loss function on the Y axis. This allows you to show that your network actually is converging and where and how well it's able to be optimized. So it really, you know, there's so many things that you could measure about a neural network and its output. So it's really dependent upon what it is trying to show. I'll have some examples of say plotting hidden unit outputs in multiple dimensions later. I think in the book, maybe seven. So I guess there's no. There's no real like rules for this in that it's dependent upon the data. And it's also dependent on what you're trying to show with the data. Right. Because depending on how you visualize the data, it may kind of tell a different story that makes your point or different point better or worse. So I think the most I'll say right now is like during this class, you will have multiple opportunities to see different types of plots. And you can see which ones maybe are intuitive to you and which ones are not. And then in like when in your final project, you'll have the opportunity to kind of. The experiment with how you want to visualize the data if it's a classification problem versus regression problem versus something else. All right. Any other questions? Yeah. Yes. Yeah. So, I mean, you'll definitely know if you're wrong. If you see it not converging. There is there are some things that weird things can happen, especially as your networks were larger in that and your input sizes were larger in that you may see your network doesn't converge for like a long time. And then actually like I think I have a maybe I have an example. Let me see if I. Okay, maybe we'll discuss this and I'll do Adam tomorrow or Tuesday. So like I'm here's here's some research that I'm doing and basically we're like trying to predict, you know, some, some outputs from an experiment from data that we gathered in the lab and work with the lost plot. One thing that we see we see things like this. So, for example, if I'm looking at plotting four things here right so we have a training set a validation set for each one I'm plotting accuracy and the loss. So this is a classification problem. We'll talk about loss functions opposed to error functions later, but just take this to be, you know, classification error, and then accuracy. Right, so the accuracy is actually sample accuracy, which means that even though I have this nice smooth curve as the loss goes down, which is what I want to see. There's a long time where that is not actually reflected in the classification accuracy because basically it's a not a regression problem it's basically is this sample being predicted correctly or not. And because of that, we see these kind of jagged leaps where it goes up a lot and then in fact the out the validation actually goes down again. And then it sort of converges better and better in these in these stepwise increments, right so it's like, it's getting I don't know 70% of the, like, 85% of the samples here and it's really not getting any more than 85% of the samples and then suddenly it starts getting like 97 or something like that. So you can plot, you know, different metrics and the different packages will allow you to do that pretty easily. So you can plot like accuracy loss, even, you know, other metrics like F one precision that we talked about earlier. So again, you know, depending on the nature of your task, the regression function you probably want to see a lot of these nice curves and you should see them both in, you know, in like, well, I guess probably only going to be using error for that you should see kind of the error curve start to decline. And it should be pretty much consistent with a couple of exceptions that we'll go into later, where is it this classification. You're going to want to look at like measures like accuracy or some of these more information theoretic precision recall type measures. So, I guess one thing you can do will use PyTorch and you may be might use TensorFlow on your projects but there's like a lot of built in metrics that you can use. So, most of these packages basically lie to create a validation metric in your, in your training, just with like the change of a string. And then you can plot all these things and see like which ones are actually useful information to present. Yeah. All right, other questions. Yeah. How do you decide how many hidden layers include the network. Great question. Short answer is no one really knows. Long answer is there's a number of techniques you can use. So, one of the network, one of the like notebooks we're going to be doing is like how to find the parameters. So you can do things like research basically specify a bunch of different options want to try and try all of them and see like, according to say your error metric or accuracy metric which one is best. There are some rules or some rules of thumb I guess that you can consider. Based on the sizes of your input. So if you have n by d inputs. The more D's you have four dimensions, generally the larger network you're going to need. So effectively what's going on here is I look at the architecture of this network that I created. One is basically four hidden layers that are 128 units, 64 units 64 units and 32 units. Okay. I ultimately I arrived at these empirically and then I tried different things and saw what worked better. But why am I, why did I choose 128, for example, as opposed to 64 and that input layer. Well, it's because the raw dimensionality the input was something like 708. So if I take 780 dimensions and projected down to say 64 dimensions, I'm losing a lot of information. So, eventually what we're doing it every hidden layer, the network sizes, or the layer sizes dimensionality of the output, which means that you're projecting whatever comes into that layer into that dimensionality. So if I have 20 hidden units. I'm going to be projecting whatever comes into that into 20 dimensions. So what if your input is less than 20 dimensions. Well, it'll project it with the addition of noise. Because there's no other way to do it. Right. It's going to not it's going to basically going to optimize some weights because it has no information available to optimize them. What happens if I put in way more than 20 things going to have to project that down to 20 dimensions. And so I could lose information that could be useful. So in this case, I'm trying to effectively classify three classes using 780 dimensional inputs. Right. So big information bottleneck, but I don't want to go too fast. So projecting in this case down from 780 to 128 sort of turned out to be the happy medium between you know, 64 and 256 people usually use nice multiples of two for computational properties. Sometimes you might just use decimal numbers so you know it's not unheard of to see, you know, 20 hidden units 10 hidden units 100 hidden units, whatever. And sometimes people will find that some weird number just works pretty great like 347, which is that a prime number that might be a prime number and like, it just seemed to work better than 346 or 348. Case in point, I guess. You heard of the Burt model. I may have it's like this, it's a major NLP model. So basically, you've heard of chat GPT I assume. Okay. So GPT is a sort of one family of big NLP models and they use what's called the decoder layer of the transformer, meaning they're basically good for generation. Burt is sort of the is a bidirectional encoding of representations from transformers. And the logo was always birt from sesame street. And that's that only uses the encoder layer of the transformers basically meaning that it's taking raw input turning it into a dimension, an end dimensional representation. That. That is really not what I was saying. What that does is the Burt model is basically taking, you know, words turning them into 768 dimensions. And so they do it using stacked encoders. And so that is you have one feed forward network, another feed forward network and other feed forward network and so on. How many encoders do they use how do you decide how many encoders to use well. Burt uses 12. Why 12. Well, they try to bunch other stuff and 12 work best. So there, there are, you know, there's probably good reasons why 12 works better than the day 11 or 13. And it's not entirely clear why 12 works better than say 16. It's probably a happy medium between robustness of the representation and compute time. So, all that is a long way of saying everybody has their favorite techniques. There's some really smart people who have probably found some evidence based ways to explore the space. Sometimes it requires an enormous amount of resources to do this exploration. So some folks just do trial and error or research or, you know, what have you. What else. All right, let me, let me start the Adam notebook, I guess. I doubt we're going to have time to go through that in. Of course, it might take me 15 minutes to find my, find my folder. All right, there is this work. There is. So, all right, gradient descent with Adam. So, I guess just in brief in the last 15 minutes. So who's Adam. Adam is about a person. Adam is a function. So there are many ways to descend the gradient. Right. Well, we've talked about so far is basically looking. Find a find the direction of steepness descent and taking little steps in that direction. Well, that seems pretty inefficient. Right. Maybe I could take a bigger step, but. As you've observed one way to take a bigger step is to have a large learning rate. Right. The learning rate is eventually the step down the gradient. But if your step is too big, you are maybe you may find yourself stepping back and forth over that optimum. You don't want that. But let's think about if I'm standing on the edge of a canyon and trying to find my way to the bottom. If I know that I'm at the very lip, right, I could probably take a big step. And then like I'm not going to overshoot the minimum. So that's fine. So maybe I can be smarter about how big a step I'm taking or basically scale the step that I'm taking using using some metric. So there are other ways of finding error gradients that will lead to fewer steps before we get to optimal weights. So this thing, one of them is called Adam and there are various Adam variants that are in use. So this, this one is sort of the original one from 2014 I think. So Adam stands for adaptive movement estimation. So you can kind of see where we're going with this. If I'm really far from the gradient or from the minimum. I can justify moving faster. So I'm going to be getting closer. Maybe I should be slowing down. Right. So there are a couple of sort of more in depth, the gentle introductions you can read as the additional paper here by team on bar. And then Jason Brownlee has this, this nice kind of gentle introduction to Adam optimization. But basically for general purpose gradient descent algorithms, want to collect all the weights into a neural network into one vector. So this way you can actually use arbitrary gradient descent algorithms for an optimization problem. As long as I know what what hyper parameters I need to apply where. So let's say we've assumed these weight matrices V and W. So to collect all of these, we can run this pack function. So now what I'll do is I'll take V and W flatten them both and then stick them together. So just use the H stack function. So let's just test this before going any further. So what I can do is I'll create some numbers. These are just arbitrary numbers just to represent hidden layer weights. And then some represent output layer weights. So if I print them, these are obviously not good weights. For any real reason, they're just illustrative. So if I have V, which is, you know, a five by two and then W, which is a three by six. So if I flatten all of them. And again, you'll observe that like these, these matrices would not, would not multiply, you have to make sure that the outputs are the right shape. So I need to flatten them. This is just going to give me an array of zero or nine and then array of 2337. And if I run the pack function, we can see that the output is what I expect. I basically just have a single array that contains all those numbers. So now imagine that we sent this weight vector off to some gradient descent optimizer. And then it returns some new weight values. I need to unpack those into the right shape for V and W. So I'll create an unpack function that is good to do more complicated than the pack function, because it reshapes W back into the constituent matrices. So of course, for that, I need to specify what shape those are. And then this will create, you know, create that into the number of rows, number of columns for each one, and then reshape basically split the full the flatten, the flattened pack vector at where, according to the shapes, the two different weight values, the one that I want to see should be, and then reshape them appropriately. So if I define that and then I pack V and W and then I run unpack, this will get me back my, my original one. All right, so how is V defined, right, that is when we run a cell that invokes V what happens. And what I can do is set, what I do is here is I'll set W zero is equal to 2000. And then if I look at V, you will see that that first element is now set to 2000. So what happened, I actually didn't recalculate W so why did the value change. So, if I do, if I create this V two, which is basically a, an instance of V, then if I run, if I show V two and W, I still see this 2000 here. Okay, great because I just affected the clone V. Now let me set W zero equal to 1000. So wait a minute. So, I'm going to change. Why not. Because the unpack method is going to create these output matrices that preserve the same places in memory as the vector those use to create them so if I change W you change V. So this can be useful for efficient usage of memory to make sure you're not overwriting something you don't need to overwrite. So this is that packed vector I can see 1000 there. So V two didn't change, because it was effectively making a deep copy. And but if I change W and then I print the packed vector, we see the same contents here. Now. So I need to update W in place in order to do this. So if I just do, you know, in place multiplication, that that will work. But if I do W equals W times point, one that will not. Right. So now W has a 100 in the first position. And similarly, now so does the right. So this is basically accessing the same point in memory. Another way to update arrays update values without creating new memory is to basically just do a slice over the entire over the entire array. So what I'm doing here is now to saying for every element in W take W times 100. So now if I put W, this will give me 10,000 in the first position and you know, well 100 times everything else. And then the new, you will see that now the, the new, have all been multiplied by by 100. Okay, so all of that. And that's just how you create your format your weight matrices so that it is appropriate for doing this kind of general optimization using using gradient descent. So, all right, in the last eight minutes, real briefly, intro to Adam. So Adam is short for adaptive movement estimation. It's just spelled Adam like the name. It's not an acronym. And it is pretty straightforward to implement. It is computationally efficient. Little memory requirements provided that you are creating your matrices in the appropriate way. So it's not just creating deep copies everywhere. It's invariant to diagonal rescale of the gradients. And it's well suited to problems that are large in either in the data or in the parameters. And so it's, it's generally quite efficient as we'll see presumably on Tuesday, we can get Adam based optimization to converge a whole lot faster than SGD. Okay. It is also appropriate for non stationary objectives and for problems with very noisy or very sparse gradients. And the hyper parameters have an intuitive interpretation and typically don't require a lot of tuning. SGD maintains a single learning rate for all weight updates. And this doesn't change during training. So remember the learning rate is the step. Adam combines the benefits of these two of two extensions to SGD one is a grad for adaptive gradient, which this will maintain a learning rate for every parameter. And this improves on performance with sparse gradients, and then our mess proper root means where propagation, which also maintains program to learning rates. And these are based on the average of recent magnitudes. So that is how quickly a weight is changing. And that means that the algorithm does look like is online or non stationary problems. So Adam provides the benefits of both using these things, call the first moment and the second moment. If any of you have taken physics, this may be familiar to you. First moment is the average of recent magnitudes of the gradients for the weight in question. So that's just the mean of recent very recent values. And the second moment is just the square of that. So this is just the uncentered variance. So formulas to say if I have, I'm going to take like the past four would look something like this. So this is again related to the concept of the moment in physics. So there are expressions involving the product of a distance and a fiscal quantity. So basically this accounts for how the mass of the object is actually arranged so the first moment of mass is the center of mass and the second moment of mass is the rotational inertia. So just think of this in terms of if my weights were quantities in space. Right. If those are masses, then the center of the first moment would reasonably be the center of mass. So if you're going to distribute kind of unevenly and like a potato, it wouldn't necessarily be the center of material, but rather centered mass. And then the second moment is going to be its its variance. So you think of the first moment is probability distribution as the mean and second moment has its variance. So you can have raw variance or centered variance. So what Adam does in the last few minutes is it basically calculates an exponential moving average of the gradient and the square gradient control by these two parameters beta one and beta two. And these are decay rates. So that is, if you think about, if I'm on the lip of the grand Canyon, I might run down the trail at first, right, because it's really steep. And then I'll slow down as I get to the bottom. So how, how much do I slow down as I approach the bottom. Or as I think I'm approaching the bottom would be controlled by these two parameters. Okay. And so these are just the decay rates of these moving averages. And so exponential decay will describe the amount of reducing an amount by percentage over time. And so the time here is training epochs. So the first moment calculation will look something like this. So M, which is some, some value for the moment equals beta one times M plus one minus beta one times the error. So here what I'm going to do is I'm just going to look and see this controlling parameter. How much do I need to reduce my momentum or my movement. So, all right, I will end there for today. And then on Tuesday, we'll pick up with the Adam implementation. All right, thanks everybody. I'll see you next week.