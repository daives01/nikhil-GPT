 Okay. All right. Okay. All right. Let's go ahead and start. So I am not as on today as I usually am probably feeling pretty tired. Huh? I feel I mean, I feel physically fine. I just like have not been sleeping a whole lot recently. So I'm like, uh, we water bottles that. I feel like I'm not the one. I'm just like, I feel like I'm just like. I feel like a lot of people are like, yeah, yeah, I'm just like. It's like, Every time it comes, it's like a different water bottle right there. Like someone keeps leaving a different person keeps leaving their water bottle. Okay. If you forget stuff in this room, like. I'm back and get it because I'm not picking up at you. Okay. So, um, all right. So I hope you all saw the announcement. I unfortunately, I got a little bit, but I will have to leave before the, the 430 got a pet family emergency. I think I have to attend to so, um, but I think, you know, people have started PA or assignment two. Um, it's not due for a while. So, you know, hopefully you have time to kind of figure out what's going on. I hope things will be batch normal by Thursday. And so I guess, um, that was only an announcement for today. Um, other than that. Anybody have questions today might be kind of short. I'm just going to do autograph basically. All right. No questions. Okay. So let me, um, I get my material up. So in church green. Okay. And then we make sure they can still connect to the, um, right. I need to, yes. I, I brought my GP laptop and then I forgot to charger at home and it was down like 13% battery life. So. Have to back off to putting things on the lab machine. Oh, wait. I'm going to answer the wrong password. No, what are you doing? Of course. All right. What if I disconnect. There we go. Okay. But it's again. All right. Yes. Okay. Um, so before we start this, I'm going to do a quick tutorial that I realized actually missing from this notebook on computation graphs. And so, um, I'm not sure if you're aware of some of the terminology that we're, that we're using. So basically. We all kind of have this notion of what the schema of a neural network looks like. Right. We have a, basically a bunch of, you know, circles. And they're in rows and you have edges between all the circles in consecutive rows. So neural network is basically it's, it can be represented as graph. Right. So as we all know graphs have like the neural network schematic representation nodes and edges. The trick is in a neural network. Each of those has basically a representation that is realized mathematically either as a value or a function. So we can say that. So if we have an expression X, we can have to just graph it like the following. Right. So you can actually have a graph representation of any expression. And so the question is just what do I represent as nodes and edges and how do I connect them together. So if I have some expression X is just going to be represented as a node with an X in it. The edges represent function arguments. So for example, if I have some function where that's F of you, where you is the cardinal word that the function is like the cardinality of you. And what I can do is I can any argument that is connected via an edge to this other node will basically represent the input to that function. Right. So, for example, if I have another function F of you be that is you transpose times V. Then I can take some other values X and Y. So if this if this node represents the function, then the edges that go from these nodes representing the expressions into this other node representing the operation over them will then take whichever values I specify here and use them as arguments to this function. Okay. So, um, a node with an incoming edge is basically just a function of the parent node. So what does that mean for a neural network. One of the parents were the children. So in this case, you can just have the children be the, the nodes and subsequent layers. Right. So now if we think of that lattice style representation. The children are going to be connected by edges to their parents in the preceding layer, which is in a fully connected network would be all of the nodes in the preceding layer. And then there's going to be some function that is applied to them. Right. We've already seen what those functions are right is basically an activation function over a weighted song. That's the operation that that occurs in our network. So now, what this means that we can then represent these things is these neat computational structures that allow us to kind of get away from the firm scratch building that you're doing in NumPy into something that has more efficiency that we'll see. We do this by allowing a node to compute things. So, of course, this makes sense because the node is now a union in the hidden layer. Right. There is an operation that's going to be that's going to go on in that in that layer in that node. So, a note can compute two things, right, can compute its own values that would be the sum the weighted sum that comes out of that node using whatever input. So, I'm going to add that into that node. And then it can also compute its derivative with respect to each input. So, why is it important that we can compute both of these things given what you now know about neural networks why is it important that we can compute that a node can compute its own value using its inputs. Any thoughts. So new here. Sorry, I can't pick on it. Yes. So it can be, it can be used in subsequent computation. Right. So if I have a, if I have a node that is connected to some other nodes in a subsequent layer. Right. I don't need to know what the arguments were in the previous layer. All I need to do is take the output of this node and then use it as an argument to subsequent. Right. So this means that I can eventually just do kind of a dynamic programming style operation right where I can take the output of some computation that just use it in a subsequent computation. And then of course, why is it important to be able to calculate the partial derivative of these values with respect to each input. What we use the partial derivative for. Yeah. So, I can't create weights. I heard something back propagation right. So the weight update that is the back propagation. We need to know the derivative of things that have happened in subsequent layers right so be being able to allow these nodes to compute both of these things now allows me to do both the forward pass and the backward pass. So, for example, in these examples the nodes there will compute you know, for now you X and then X transpose times Y and then in the left graph. This, this will compute D FDU may increase the font size. So D FDU and then the right graph will know how to compute D FDU and D FDV. Right, because that those are the arguments. Okay. So now the graphs, the entire graph represent functions. And these functions could be expressed. You know, these functions could be say, null array functions. They have no arguments. So, for example, this thing, right, this is an expression also known as a null array function. There are no inputs to this. It just is its own value. And then unary right if there's one incoming edge, this would be a function. This would be a binary function up to basically just an arbitrary value of an end. So, you know, the, a single node in a neural network. represents an NRE function for the size of the previous layer. Right. I've got N nodes in the previous layer. There are going to be N inputs to every node in a subsequent layer, assuming a fully connected network with none. We're not talking about like residuals or convolutions or anything just yet, but just assuming a standard feed forward fully connected network. This is what you can expect. So basically just all the way up to some value of N. So now we can express arbitrary functions as graphs. So let's say I have some expression x transpose times a, where might we encounter like this for an arbitrary value of a, what I bought a represent in this case. An image or just or just generically, right, any input, but generically, let's say in the interior of your neural network, what might it represent. Let's say I've got a three layer neural network and I'm looking at like some function of a in that second layer. Right. Second hidden layer. It's basically just going to be the output of the previous layer. Right. So this can be a would be, you know, H of x times V as came out of the previous layer. Right. So this really can be anything. So what we can do here is that if I have some input x. It has some function applied over it. In this case, the function is just the transpose. And then that output can be used to as inputs to another function. So here we see, for example, I have an input x. This might be a raw input and I have some input A that might be another input or it could be a feature map or something from from a previous layer computation. And then I can perform operations over them. Now here, interestingly, what I can do is I can represent sort of arbitrary graphs that might have loops. They don't, these don't necessarily need to be directed or a sick week. So for example, I can have an expression that is x transpose times a times x, right. I don't need to define x twice. I simply needed to find the edge that tells me where x needs to go what it what x is an input to. So for example, I could take the previous one, right. We've already established that x transpose times a can be represented by this. So anytime I see that, I can just take that same graph, right, just clone it, pop it in there. And so then I have another multiplication by x. I just got to figure out where I put x, right. I already have x. I can reference the same x. This simply just needs to be a function that's going to take the output of x transpose times a and multiply it by x. And so I can represent it like this graph. And so another way you can do this is you can also represent the same expression right expand transpose times a times x with a simpler graph. Right. So I could have a function of u and m. That is actually the whole this expression, all I need to do is pop in those values that represent u and m. Right. So as long as I define the function that is being executed in the node. Right. There are many different ways that I could represent the same expression. So that means that is to say the competition graphs are not necessarily unique for a given function. So, if we take a cop cop more complicated one so x t times a x plus b t times x plus c. It may look something like this. Right. So the first part is already given here. Right. We've already saw we've already seen that. And then there's going to be another node is basically the sum of these three, three expressions. And then all I need to do is provide the inputs there. Right. So I've already got the output of x t times a x. I need to provide some, some graph that's going to give me a b t x, and then something that's see. Right. So I've already got x again reference that same x again a third time here when computing b transpose times x and see is just an expression. And so now all of these get fed into this node that is just a summation function, and it will give me that output. Right. So that is to say, what we can do with these things is now allows us to build complex operations from simple building parts. This is interesting for neural network purposes because we can write neural networks as computation graphs. Right. So the nodes are the quote neurons and the edges are the quote synapses. We don't really talk about synapses in computational neural network and just I don't think I've had this event yet in this class. So here we go. The term neural network like whoever came up with that is just an absolute genius at marketing, because like if I if this class were called introduction to non linear optimization or something. So here's you probably wouldn't be here. But machine learning and neural networks are just like incredible terms of art that just draw people to the field because it's like seems like something mystical is going on. So these neurons are sort of loosely inspired by cognitive architectures in that there is an input. You know, in the brain's like electrical signal, it's transformed and then the transformed input goes elsewhere and becomes an input to something else so these British doing functions right the transformation is some sort of non linearity. Times over some some weighted some and we're just simply trying to figure out like what those right values are. So in the sense that it's neural like neural like machine learning. Doesn't really bear any known resemblance to actual learning, except perhaps coincidentally there are cases in the brain where we see processes that seem to be like supervised learning like reinforcement learning or like unsupervised learning. There's a whole lot of things that the brain does that we don't have neat machine learning metaphor. So, there's, there's somebody to go, but the term neural networks seems to be here to stay. All right, given that we can write neural networks is computation graphs. We can also write loss functions as computation graphs. So that is you can write loss functions within the innermost SGD operation. And also, you may have observed their plug and play. Right. So if I have this expression, where I've already kind of determined some computation graph for say the first term of the sum. I can just clone that in whatever form and then just drop it in. Right. And then all I have to do is if I need to reference a term that is referenced in this in this sub graph. I can't. It's really no big deal. And then finally, you know, we can, so we can basically construct this graph and just like use it in someone else's program, which is basically if you have used TensorFlow and PyTorch, that's what you're doing. You'll specify what you want your layers to look like. It's going to create a computation graph for them that allows you to do all these operations. And there's a whole bunch of like C plus plus or whatever that happens under the hood that you never have to touch. And therefore, this allows us to make efficient gradient computations because we're going to write the entire thing in say Python, the underlying C plus plus or C or, you know, assembly code or whatever that is so much faster is doing all of that for you. And so you get a significant speed up with these packages. All right, so. Finally, if we have some operation right H is going to be some nonlinear functional called the 10 H over W X plus B or my weighted sum. And then why my output would be some other weights V times H plus a, a would be like another that other bias. This can be represented are too layer. No, no, no, we can represent it something like this. So I've got my weights and I've got my input. And then I've got a bias. This is explicitly representing the bias as its own term, but as shown, we can just consider this to be another. And so now we add these. We take the 10 H function, this gives me my output. That goes in as the missing input that it's looking for for this other other function. And here are some other weights, the, and then I multiply them. And then I add some bias and there might be some other nonlinear function here that I want to apply. So plug and play neural networks courtesy of computation graphs. Very simple, allow us to do to do certain things so you know, like I mentioned, artificial neurons kind of loosely mimic some functions of biological neurons. But they have the advantage of being able to find patterns and this is from an LP class, I say language data, but generally just like data. In the large, we don't have to do manual feature selection, like we don't have to try and figure out which power I need to raise some term to in order to fit my linear function. But they can take quite a bit of time to set up correctly as you may be observing. And also the way that you represent the input data is very important. Everything's still got to be numeric. And what we want is we want to capture something about this is kind of again, NLP specific, but we just want to find a way to capture important features without trying to extract the manually, to at least to the extent that we are, we do not have to. Okay. So why all that about computation graphs, because this goes into the topic of the main lecture, and we're actually still a day ahead, which is good. And I anticipate this will be able to finish this with no trouble today. So today I'm going to talk about PyTorch, particularly the autograd capability, and then also the, says, and module and I think I'm sure we cover that here in the next one. But either way, we'll talk about autograd and hopefully you'll see kind of how the construction of the computation graph allows us to use these features of PyTorch, you know, with sort of a single line of code rather than having to write say a dozen as you may have had to do for for a second or two. All right, so, first of all, who here is used PyTorch for. Okay. All right, so we will get, you will get some practice in this in this class. So starting here and then in homework three, and then subsequently you'll get the ability to kind of play on the PyTorch see how it works differently from say the NumPy version, or similarly, and then also see how we can get a significant speed benefit. So, why use PyTorch? Well, obviously, you probably wear some of the benefits right it's faster as I alluded to, it's more efficient as I also alluded to, it provides support for GPUs, speeds up everything as you saw in like that first lecture, significant amount and we'll see that again. And then also the code is usually easier to write, right? So if you see how I'm calculating the output of my prediction, what I'm going to do is I'm going to take, you know, why is if I'm using the form from the code in the assignment. Why negative one is that last element of the outputs for each layer right as you so if you look at the code, you'll notice that it's kind of accumulating the outputs for each layer. So like the last output that I got, which would be the output from my previous layer times the weights, whatever it is, add the bias, and then apply my 10 h and my non linear function to and that gives me why. Okay, so maybe a little bit hard to keep straight in PyTorch. You basically just define the hidden layer, and that becomes the function, right, as we saw in the computation graph. So, I'm going to specify what the input to that function is, and we'll do the computation for me. So the code is more opaque. And if you're like trying to figure out if you're trying to like infer what machine learning operations are from reading PyTorch code is not going to be very easy, but having done some already, you know, it's going on in those hidden layers. Right now you see why equals hidden layer of why you should have at least have some intuitive understanding of kind of what that's doing. So, the, the core of PyTorch and also other packages like TensorFlow is this thing called a tensor. As we alluded to in lecture one, you know, tensors and NumPy arrays are both end dimensional arrays, but they are not equivalent. Right. So, you know, it's a lot more than you can see. And I'm going to go back to the next one. And then I'm going to go back to the next one. So, we're going to go back to the next one. And then the next one is the last one is the last one. So, we're going to put a little bit of data on there. The lab machine. The scroll is all fast. So tensors are a much more generalized form. So remember that a tensor technically is basically a transformation. And the numerical array is sort of a form suitable to representing that transformation. So, the tensor being a transformation is a function. So, the torch package contains these classes and functions that are mostly very similar to NumPy. So that is, if you do like V stack and each stack and all the array manipulation you can do in NumPy. You knew a lot of the same stuff in PyTorch. It also provides convenient functions to convert back and forth. You want to minimize the use of these functions because it does take time to convert the NumPy data structure to the torch data structure. So basically set up our data in NumPy converted to tensors. Then you can run PyTorch when you want to do your data analysis convert back to NumPy arrays and you can do things like, you know, make plots and all that stuff. Okay, so let's just view this in action. Right. So I just create some data. This is now just a list. Right. This is just a list of lists. So, you know, I can take a list and turn it into an array using the NumPy.array function. This is going to give me this. So now I have a two dimensional three by three array representing this data. If I look at the type, this is going to tell me okay it's made up of 64 bit floats and it's a NumPy and the array. Now if I create torch.tensor using the data, it's going to give me something very similar. It's going to give me the same function or the sort of the same function equivalent in torch. Right. So instead of creating an array and creating a tensor, but I can, I can do that operation over a list. I can also do that operation over a right, we give me the same thing. So how is how is this represented now this is a torch tensor. And it is this one. And it is composed of 32 bit floats. So a little bit different there at the NumPy version is 64 bit floats the torch version 32 bit floats by default. Of course you can specify with a D type, which kind you actually want to use. So now what I can do is I do torch from NumPy of a, this is going to give me the same numbers. But now it explicitly says that the D type is torch dot float 64 because it was created from 64 bit floats from NumPy. Right. And then running the type and the D type will confirm that. So now I can also do torch as tensor. Right. And this is going to give me pretty much the same thing. So again, same numbers, right. I'm also taking this from a, and this is going to create 64 bit floats. So, and so now basically see and D contain the same information and contain the same data type. Okay. So the next one. So now what I can do is I can take D right this thing that is created and turn it back into a NumPy array. So now this is going to be an array. And if I take the type of this is going to say okay now this is an NDA ray again, and it is a, a float 64 data type. What's the distinction. Right. The distinction is torch dot tensor makes a copy of the data, whereas torch dot from NumPy torch dot as tensor do not copy the data. So remember what happened when we were doing in the first part of the atom notebook. What happens if you do a deep copy versus a shallow copy so if I do if I make a shallow copy. What happens if I change something about the original. If I make a shallow copy and change something about the copy. It does change the original right if I make a deep copy. The two are completely separate there you copy the data to a different place in memory. Let me do whatever I want with this new copy and nothing about the original change. So I ran into this. Yesterday when I was doing some manipulation for doing some, some data and like I changed the class labels for something and all of a sudden all my plots like the colors were wrong. It's like a I got to rerun the model. So be careful. Okay. So here's a again. So now what I can do is if I go. So if I create this tensor from using the from NumPy function right so this is B as a tensor. And now I set that first element to 42 point 42. Okay, here's a. And here is B. So this is that shallow copy and by changing a I have also changed B. So now I'm having basically torture is referencing the same place in memory for the actual data. It's just got sort of a data structure that is of the right type to defeat it into into PyTorch. If I tried to put a into a PyTorch neural network, I would give me some error saying, you know, was expecting tensor but got non py array. But if I put be in it would be fine. Although the numerical data is the same. So now I could do a torch dot tensor, right, which copies the data as noted. And then, oh, God, I was get this wrong. I have the scroll set to a different direction. Okay, so here's B right and then B zero zero is 42 point 42. Now I said a zero zero to 12,345. Okay, there is. And B is still the same. Right. So torture tensor will create a deep copy. Now we can also use the at signs for matrix multiplication as we do in NumPy. So here, let me create some data. Right. And for a and B and I could do C equals a at B and the shape of C is 10 by 20. Why is the shape of C 10 by 20 given what it was calculated from. So it's a 10 by five and a five by 20. Those two inner terms are the same. And so when you multiply, you end up with the two outer terms as your shape. Okay, so. Don't need to do that about randomness. I guess. So now if I do tensor versions. Right. So if I do the dot random function, just kind of the same as the NumPy random uniform. So give me the same thing. Right. But now when I put a CT. shape, it's going to be just torch dot size of the same dimension. So again, I can pull the same values out of this is just represented slightly differently. Okay. So now where we, we get with what we get with autograph is basically the ability to calculate gradients automatically so I'll begin with these two quotes to deal with hyperplanes and a 14 dimensional space visualize a 3D space and say 14 to yourself very loudly. Everyone does it. This is by Jeff Hinton, the father of deep learning. And I do, I think this works. I think my technique is slightly different. When I think of a high dimensional array literally just imagine a really, really long three dimensional array. So our tiny like human meat brains are not good at conceptualizing things in more than three, maybe four dimensions. If you think of time as a fourth dimension. Beyond that. They're just you see these long strings of numbers and like this, this looks two dimensional to me or one dimensional or something. Really what it's saying is that there's the value in every dimension that is orthogonal to all the previous ones. Once you get beyond three. This is not something that you can actually visualize very easily. What you need to, I guess what you need to know is that vectors, even in high dimensions preserve those similarities across the high dimensions so things that are similar to each other numerically or semantically will point in a similar direction in high dimensional space. And that operation is equally true in three dimensions as it is in a thousand dimensions. So, as Abraham Lincoln said this is pretty cool. I actually say this. So in the Cooper Union speech in the section address to the southern people. He actually says this, that is cool. I believe he meant it in the sense of like that is kind of cold or cold hearted. Nonetheless, if anyone tells that Abraham Lincoln didn't say this is cool, you can, you can show them the reference. I can find my notebook anymore. Okay. So anyway, people are like pretty bad at calculus, just in general. In more than three dimensions, it gets even worse. Right. There's so many numbers you have to calculate the derivative for like every, every element of a high dimensional array with respect to all that by holding holding all the other values constant. And so one of the reason that machine learning sometimes feels like magical is just like, oh, so much math going on that. Yes, you could sit down and actually calculate like what's going on inside of a neural network in principle. If you had all the time in the world and the super powerful computer. But doing those operations, you know, by hand, or like line by line would take greater than the lifetime of the universe to actually do. So of course no one actually does it. And so if we take the workout by, by doing by using matrices, and then as we mentioned, we have GPUs that are optimized for vector math and then some matrix multiplication. So we can get this big speed speed up with the, the GPU hardware, but there's still explainable math that's happening at each step. So if you were, if you had the ability to zoom in on a single, you know, iteration, a single gradient update, we will see the operations that we saw happening in lecture five or like updating a single weight is just remember all that's happening at a massive scale. And we think of modern applications, it is just truly mind-boggling. So, that makes it impractical to calculate these gradients for these giant gigantic composite functions, especially in the high dimensional space. So for example, you know, what's the derivative of sign of X. Cosine of X right so we learned that in, in trigonometry. And so you can see like how we can actually calculate this. So they create 100 evenly spaced points from negative two pi to two pi, and then plot the sign. Y equals sign of X and then the derivative would be cosine of X, I can plot these right this is what we would expect. So, now what I can do is I can, I can do this using PyTorch and tensors. So I'll take X, right, those numbers that I created. I'll create a tensor from that array. Here's the tensor. And so then currently I look at this, this argument is a parameter of this tensor requires grad. I'll get to what requires grad in a minute. So it says false. So right now requires it does not require grad or require gradient. Now I can set that value to true, right, just by, you'll see the function version has an extra underscore there. So I set requires grad to true. Now I can see that it will give me this extra little bit of information at the end. So we'll set that set requires grad equal true. And it'll tell me that whenever I print out the tensor. So now by setting requires grad equal to true. I'm forming this computation graph, this backwards graph that is the history of every operation. So when we think about how a node can calculate itself, its own values from its input, and then also its derivative. And those values are going to be dependent upon the children, sorry, the parents, the values of the children, subsequent nodes are going to be dependent upon the values of the parents. We start to create this graph. And so this backwards graph is going to be this history. Right. So if you think about the actual operations being performed. If you start from the input, you perform an operation over you perform a few function over that operation. You then take that value and another operation is performed over and so on and so on. And so each of those operations can also be part of the graph. And so setting requires graph through will allow me to basically automatically calculate every component of that sub graph every every corner of the sub graph within that graph, as I'm performing operations. All right, so this will aid in calculating these composite gradients. So I'll just look at this grad, and currently says non will start assigning values to it soon. So now I can define the sign function. Right. So of course I'm going to define why being sign of x. And so now here's y of t. And so here's the sign you can see the basically starting from a value really close to zero, and we're ending, we're getting closer and closer to one and then eventually we end up with close to zero again. So no doc stream for that one. So the shape of this is 100. So just a tensor that has 100. 100 elements in it. Okay, so now if I look at the backwards so y t dot backward. It's confused the gradient of the current tensor with respect to the graph leaves. Graph is differentiating using the chain rule we've seen that before. This function accumulates gradients in the leaves. So you may need to zero grad attributes that tend to none before calling it will see what happens if you don't zero are your gradient. So backward will basically compute the derivative for every x in y t that has required requires a grad set to true. So y t is basically constructed by in this case performing the sign function. Over some, some other offer some other value in that case x t. So this will basically compute the gradient for every value in that in that array or in that tensor. Okay. So, so now here if I just do a doc backwards over an array of one 100 ones. So this argument will represent the gradient of y sub t with respect to itself. Hence, it's going to be all ones. So now if I look at x t dot grad. Oh, God. No. There it is. So now if I look at x t dot grad, right, I did, I did y t dot backwards with the gradient with respect to itself, not to look at x t dot grad, right, we started one. We go down to zero. We end up back at one. And this is now actually the cosine of x. Right. So I started with just some. Some values. I computed the sign for those values. I took the gradient of the sign. And now that original input that x is now set to cosine. How did that happen? So let's look at how we compute. Y t, right. Y t is generated by taking the sign function over x t. And since y t is created by performing this operation over x t. If I run y t dot backwards, this will keep a record of updating gradients for x t because x t was one of those arguments in the computation graph that was used to create y t. So this only does it if x t requires grad is set to true, which we did earlier. So therefore, you just need to be alert to your in place calculations. Right. So if I'm doing operations over something that uses something else as an argument. If that other if that argument has requires grad set true to it, I may end up calculating the gradients of y with respect to that in the original input. So you got to be careful. Right. You may have it. You may not actually want to do that. So you have to make sure that requires grad is set to true only when you need it to be. So let's visualize some of these operations. So first you can see what's going to happen. I just want to plot x t versus y t. And then it's going to get mad at me. So why did it get mad at me? Why do you think it got mad at me? Sorry. Not the same dimensions. Let's see what happens. What it wanted. So it didn't say anything about the dimensions. So x t and y t should both have 100 elements. The error is can't call non pie and tensor that acquires grad use tensor dot detached on non pie instead. So remember we got those operations to convert between non pie arrays and tensors. Those only will work assuming that basically the tensor is not attached to the computation graph. Okay. And so, if I tried to do that it's basically saying, hey, I'm not done with my computations over this. Don't try to take it away from me. But of course, pie plot being pie plot. So it needs to be an umpire array. I can't turn it back into an umpire array until I detach it from the computation graph. So there's a sneak function dot detached that you can use to basically say, I've got this tensor and I want to do something with like visualizer use it as, you know, an input feature to another operation or something. From the current computation graphs. Remember when that the doc string said that dot backwards accumulates gradients in the leaves. Right. This is one of those leaves. I need to take I need to attach the leaf from the tree that is the graph in order to use it anywhere else. So we will use the detach non pie function and again when you're doing assignment. I want to say three. You may run into this issue. So if you want to attach will return a new tensor, this will be detached from the current graph. And this, this result will not require grad. Right. Of course, if I have something that requires grad and I detach it from the computation graph. There's not much point in having requires grad or what I'm going to use requires grad for if I'm detaching it from the graph is no graph to compute the gradient. And then whenever I want with it and not worry about changing that due to other operations having been performed on the graph. And then the dot numpy will convert the tensor to a number. And now we're back in familiar territory. So now here we go. So here is xt and yt. Right. That is the blue line. So we have xt being the original input. So we need the sign function. And then xt dot detach, right. That'll give me the same x values and xt dot grad is going to give me the derivative of why. Right, because of sort of that computation graph magic that we just discussed. And so now, instead of plotting, you know, two separate functions, sign of x and cosine of x. And then we're going to be doing properties of the same to the same two variables xt and yt to get the values that I need. Okay. So questions. Be a little bit mind bending. All right. So where we at now. So, I'm going to go through. Actually, I have to move faster. Okay. So now let me do yt equals the sign of xt and then I'll run yt dot gradient again. And so now xt dot grad gives me something like this. We started to go down close to zero and then to back it to. I do know that the derivative of sign of x is cosine of x right. That hasn't changed. So what happened. Let me plot it. Now we can see this. Right. So now it's telling me that the blue line is still side of x and the orange line computed by xt dot grad. Now is like cosine of x except it's bounded at two with negative two. So what gives I didn't actually change anything. So the back to the derivative is twice what it should be. And this is because not backwards is going to add the gradient values to the previous values. So I'd already, I'd already calculated one gradient that was effectively cosine of x. Then it is again, but cosine effects are still there. So it's like, okay, I'm just going to take whatever this is and I'm just going to add it to this. So now my gradient is sitting there at two times the cosine of x. So we must explicitly zero out the gradient. If I do this, then the same addition is true. Right. Whenever I can be the gradient is going to add it to whatever whatever is in the gradient. But if the gradient is zeroed out, that's zero. And so what I get is the actual gradient that I want. Okay. So use this dot grad zero function. And this will print out the, the, this will zero out the gradient. So now what I can do here is if I do, you know, for 10 times, I'll just create. I'll take the gradient of the sign function, and I'll print out that first element. Right. So the first, the first term should be one for cosine. Now if I do this, you'll see that I get, you know, one, and then two and then three and then four and then five all the way to 10, because it's every time I run this, it's adding that gradient. So I get that accumulation of values. So we add one to the existing value. If I put the grad zero inside of the for loop. Now it's 111 11111 so I keep getting the right value here. Okay. So always know you need to be zeroing out your ratings. All right. So now having done that, what we're going to do, we're going to run through some examples of training, some simple models using SGD and PyTorch. So here's the NumPy version and then the PyTorch version. So here's the NumPy version. This should look pretty familiar to you. So we see our X's and then my T is just not some nonlinear function square of X. I'm just going to use my SGD implementation similar to what we did in the assignment one. And that gives me this. So here is my T and this function. Why this is like the best linear function that I can fit to this. Right. So still doing just linear operations. Now we do it in torch. So what's different here, but I'm creating these sensors from the NumPy arrays. And then I create my weights as torch.zeroes. I'm not using autograph yet I'm still just doing the calculation manually. So gives me an error expected scalar type long, but found float. So if you look at X, it says it's 64 bit in. So this error is actually a little bit misleading. In fact, it suggests that some float should be an end. So X is already made of it's but W is now made of floats. So rather than make W into in because integers do not make good weights typically will make X into floats. Okay. So let me run a version of this again. All I've done is I've just added dot float here. And now this works just fine. Very similar result. Okay, so why are we actually using torch if it looks identical to our NumPy code. What's the point of this exercise. And just to get you thinking about computation graphs apparently. So where this really shines, let's take advantage of automated gradients. So I've got this computation graph, but reason that I do it, is that I can automate the calculation of gradients. So why am I dealing around here with this for loop when I can do everything much more cleanly. Okay, so here we go. So same up until this point here. Now, instead of the update I'm causing just calling emcee dot backwards right so. So this is my loss function. And so to update the gradient I just call whatever instance of my loss function I've created and just called backwards on that. Okay, because the backwards calculates the gradient so when my, when I was doing dot backwards and why to use the sign function is going to calculate the derivative of the sign function. But I'm always counting the derivative of the loss function. And so I just define what that is and then called backwards on that. And then finally, I also do a with torch, no grad so I can kind of not update the gradient and sort of do a temporary, I don't fully detach anything with the computation graph I just sort of pause the gradient calculations on that, so that I can use that to update the actual weights here. So you can compare that to what we did before in the commented code. And this gives me, again, pretty much the same result. And so a lot of things you can do is you can use predefined optimizers. So here, you know I'm defining, you know what what define optimization function, you know manually. So here I can do this, using some some predefined function. So we're previously I had defined my sg operation. I can actually just pull that out of the library. So this is going to look like this. So now I can basically instantiate my optimizer as an instance of torsa optum.sgd. And then I can classify what weights I'm going to be optimizing and what learning will be. And then after calling lost out backwards, I can just call optimizer step. This is basically this thing to perform one step of way optimization. And so now for every training epoch in 100 I'm going to do one per step and each time I'm going to zero out the gradient. All right, and this also gives me the same result. Rather than define sg your atom or what have you by ourselves we can use this predefined optimizer class. And this torsa optum is this package that implements a bunch of different optimization algorithms. All of them have like, you have to define different parameters for them right you have to find like the, of course, the ways you're going to optimize but also for Adam, you need to define say those beta values and things like that. And at this link you can see a list of all the implemented optimizers that you may want to use. Questions on that so far. The other thing we can do is we can use predefined loss functions. So what was my loss function to this point was I using. So, you know, regression problem. Mean squared error right so I'm trying to minimize the error so here we go. This part this is the definition of the loss function right there. Okay, now I can optimize that. But maybe I don't feel like doing that maybe I forgot the function for me and squared error maybe I'm doing a more complicated function like you know category across entropy loss something like I don't remember how to write this precisely and I don't want to mess it up. So, I can say that, hi torch will give you the loss function. Like before so here, I can define this MSE funk as torch dot nn dot MSE loss. And so now I just calculate the MSE as this function whatever it is, over my targets and my predictions, and then I just call it backwards and they can optimize my weights. I do get a problem. So what is this issue right found D type long would expected expected float. This is similar to the one above. So we see this where we had X made of ins and it wanted floats. This is dropping off the backwards pass inputs are T and why. So we know why is made of floats as it should be. So therefore the problem must be in T. And so now I can add dot float to you and I define it along with X. And so the last thing is the same boom boom boom. Here we go. Okay, I actually will talk about torch dot and module. Okay, and then stands if you haven't guessed already stands for neural net. So basically this allows me to create a lot of the infrastructure that we need for neural net and then define my specifics like how many layers and what types of optimizers and loss functions. So it looks simpler for our linear model but if you try to apply to multi layered models it will. Right, because I have to all I have to do is define, but the specifics of my layer with, you know, a single line of code each. Okay, so number of inputs number of outputs looks similar. And then everything is going to be torch dot and n dot sequential and then I define the layers here so basically this is saying, the only quote layer is just a linear function mapping from input to output. So I have multiple fully connected layers I would define each of those in turn. So now if I just print the model, you'll get this nice print out of what the model looks like. And so you can see what all the layers are. This allows you to like if you forget, say what the input size to a particular layer should be. You can print out the entire model and say okay hey layer four is expecting that things are going to be 256 elements and so that's where my error is because my input somehow is not 200. So I print model dot parameters, I get this, basically this list of the parameters that I've solved for. So in this case they're just they're random right so I've just got some random weight and some random bias weight. So now I can actually use this to try and solve function. This looks similar, except all I've done is I've added an inputs. Right so I've added in samples and inputs. And so now I've also added Y equals model X. So this is just saying my model is a function I defined it however, I'm just going to run that entire model over this input. So this is sort of the higher level version of running like hidden layer of why there's all the hidden layers are all the layers in there. I'm going to run all of them single forward. So if I do that, then this gives me. Once again, I've solved the. I solved the problem. You'll notice if you're paying attention notice that like these are not exactly the same solutions in fact some of them have like the orange line is like a little bit higher. So the slope is slightly less than the biases, probably a little bit higher. So remember these are all estimations right you start you initialize weight randomly and it optimizes based on your error as best as it can. And so you may get slightly different outputs each time it is in fact perfectly possible to write a neural network that has two inputs that are the number numbers two and three with a single unit is activation function is a plus sign and it's going to tell you the answer is 4.9999 This is the thing that happens sometimes. So just be aware that this is all estimation. So by adding a hidden layer or two, then what I can do is I can describe the structure of the network like this. Right. So we see here. So we're going to do the first and end of sequential. So one linear layer that maps from size of n inputs to that first hidden layer size so in this case both in layers or 10. 10 h function, right, define my activation function to what function gets applied after I perform this operation. That output then goes into another linear layer that's going to map it to whatever size and hidden is one is, and then another 10 h function that's going to map it to the linear, the output, whatever, you know, size that is in this case just one. And then everything else is pretty much the same. We run that. So now I'm actually get now instead of a linear function right it's able to optimize kind of the curve of the line. It's not like it understands that there's a squared function here or anything, but it is able to match those values pretty closely. We do get a bit of a weird zigzag here at the end. So maybe Adam will do better. So what I can do here is I can, from my optimizer, I will just define torso often Adam instead of SGD. And then I can change my learning rate appropriately. And then I run that. And there we go. Exactly where it needs to be. So it's the optimized to this almost perfectly. Okay. So now let's actually make use of the GPU. So it's trivial to move data and operations down to the GPU with PyTorch. So all we need to do. Well, first I'll run it without the GPU. So here I'm just going to perform matrix map multiplication for 1000 times over some random numbers. And we'll run this and we'll see that it takes about a second. So pretty fast. This is running on my lab machine. The CPU itself is quite powerful. But we do have this thing on this machine called CUDA. Torch. CUDA. Is available. We'll tell you whether your machine has CUDA or not. Generally good practice to write your code to accommodate either in case you end up on a machine that has no GPU or they can't find CUDA. At least you can still run, even though it will probably be really slow. So now what I can do is I can do. Dot to CUDA. This is going to say take this tensor and move it to the device. This is not done in line. You have to reassign the variable. Right. So, At dot to CUDA is not going to change. It's not actually going to move it. But I do at equals to to CUDA. Then every time I reference at it will get the version is on the GPU. So now we're still running on the CPU. So here we go right C. CTE equals CTE dot to CPU using code on the CPU is not much faster. It's actually no, it's actually slightly slower. Right. Because CUDA is a GPU acceleration library. So what's why am I using it on the CPU? So what I can do here is I can define this function, use GPU. And in this case, I have this code written so I can use the Linux machine or my other laptop, which I would have brought it to connect to the Internet anymore. So now let's compare the speech of the torch dot and then model on more data using the GPU and comparing it to CPU. So first I'll just set use GPU equal to false. And then I'll run this like non linear model, move everything to the GPU. And this is similar as before. Moving to a GPU training to about a second again with GPU. And took 3.15 seconds without it. Okay. So now the torch dot and end at module forward function. We just saw how to implement this using this combination of sequential and then linear and teenage layers. And the forward calculation for the neural network is defined this way. So now we can define a class that extends torch dot and end module and define the forward function explicitly. So here I'll define an end net class that extends this class, and I can define the forward function. That this is going to be very similar to the forward pass function in assignment to. So I start with, you know, I just set my Y equal to my input, and now this allows me for each hidden layer. I just recompute why is the output as the operation over the output of the last layer. And then this will give me the final output. So now I can set, you know, larger network 100 notes each. A large learning rate, and then I can move the data to the GPU and run. And we can see that it takes about one second. So basically the GPU magic makes it such that the larger model you have the greater speed up you're going to get. And then we can see that the differences we see here with the simple models like a factor about three. But then as your models growing grow larger it becomes a factor of 300 3000 and so on. And so you can define your neural networks. And then you can see that the data is the same and the other is the same, and then you can see that the other code remains the same and this allows you to very easily experiment with like different layer sizes and different hyper parameters and things like that. Alright, that I think will be it for today. So sit down. Good luck with the homework. And I have like a few minutes if you want to talk but I'm going to have to leave early today.