 Okay, welcome back. Can you all hear me in zoom? All right. So connecting the audio. Zoom folks is the audio. Okay. I will assume it's good for the rest of you. All right. So I think only announcement. Sarah, you're doing a tutorial tomorrow. Okay. And can you just recap the tutorial on what and where. I have. And what will you cover. So I'll be. Okay. Great. Yeah. So if you are not familiar with how to do any of those things, I really encourage you to attend the first assignment is going to come out. When we're doing that. So first assignment is due to be rolled out. On Thursday. So make sure that you are familiar with everything that you're operationally going to need to know is to get the Jupyter notebook up and running. We won't be using GPU for an assignment. I think it's all a three. Nonetheless, this is you're going to need to know it. We're going to need to know it. We're going to be able to use it if you want to. So we're going to be able to do that. So we're going to be able to do that. So we're going to be able to do that. Nonetheless, this is you're going to need to know it or you need to be able to use it if you want to run any of the notebooks from like eight nine and etc. So just make sure that you're at least comfortable with all those procedures. I think that was the only. Today. So if there are no questions, I will go ahead and resume. We're picked up last week. So let me share screen. All right. So. All right. So where we left off. Hide. All right. So we, we kind of motivated the problem of linear regression on this is probably something that you're all familiar with. Basically, at this point, we're still trying to fit a curve to a set of points. Right. And so if we have a set of observables, so we can take those to be the ground truth. And we have a set of inputs that correspond to those observables in the use case to the outline those basically. I have these, these springs. And I'm trying to effectively. You know, figure out what the spring length is that's going to allow the, this, this rod here to basically rest at equilibrium. Right. And so we want to minimize the potential energy instead of springs in one way. We can do that is basically if you have the spring lengths stored as weights. We're trying to solve for that where the observables are the energy stored in any particular spring. And this can be applied to any linear problem. Effectively, what I'm trying to do is I'm trying to find the rate of change and then minimize the rate of change in those inputs. And so I'm trying to find the coefficients correspond to this inputs that's going to minimize the derivative or the gradient. Just a recap of terminology. What is a gradient? A slope, but in multiple dimensions. Right. It's basically the high dimensional derivative. And so this is what we're trying to find if I have a bunch of inputs. I'm basically trying to minimize the gradient with respect to every dimension represented by those inputs. So, you know, we talked about, you know, just using kind of like the least squares and stall functions on, you know, in NumPy that will like to do that with some with relatively small inputs. But often we'll have a bunch of samples. Right. And this can be very time intensive to solve. And so we don't want to have to do these huge matrix operations. You want to minimize matrices are very useful, of course, and can minimize the time complexity of these types of operations, but still trying to do the operations over these huge matrices are still as time for let's see still going to explode. So, so what we can do is you can use this incremental form where basically we're trying to find some sequential algorithm. You use the fact that the derivative of the song is the sum of derivative. So now we can express this derivative as that gradient. That's just going to be a matrix of derivatives. So just like everything else where your inputs can be a matrix and outputs are usually going to be a column matrix. Those you see you can have multiple columns. The derivatives, of course, can also be represented as matrix. So this opposite on trying all pronounced del represents the gradient. So we have some function G of x parameterized by w. This is just the linear function. Remember, this can be written as basically the transpose of x times t. And they're very if I'm doing this for every combination of weights and inputs. This is just to be written as a son. So now we have this error says error function e is expressed as with the arguments of the inputs, the targets t and the weights w. So effectively what I'm trying to minimize is the difference between t sorry x times w and t. Right. So if t is my ground truth, x times w is my prediction. The correct model is going to be one that minimizes the difference between prediction and the ground truth. And that's just expressed by this formula here. Right. So inside the summation on every element of t the targets, minus the output of function G for input x of n. This is just going to be the squared error and try to minimize the squared error. So now we're just back in familiar with the square territory. So, of course, I take the error gradient. So now this is going to be the gradient with respect to w the weights of that error function. Of course, I'm just going to apply that same gradient to the other side of the equation as well. And so then ultimately, if I take the gradient, it simplifies to the thing at the bottom by very pretty straightforward calculus operations. So I'm going to bring the exponent to down in front and multiply by the base. And then eventually we end up with the formula here. So now, instead of summing over all of the samples. If I just take the equivalent weight, then I can update it for the gradient for that sample. So that is five is one input sample. So I have some weights that are just at this point arbitrator and then the input times those weights is going to be some distance from the ground truth. Right. And if it's the weights are wildly unoptimized. It's going to be very distant if they're very closely optimized it should be pretty close. And so I'm going to take that, that error. And then I can optimize the weights that correspond to that input sample. And then I can optimize them with the error for that sample. So the gradient for some sample and can be considered to be basically a noisy, noisy sample of the true gradient. So that is there's some true gradient that represents the gradient over all of the samples. And for a single input sample, this is going to be a sample of that entire gradient that is just subject to some perturbation or noise. So I can take a small step in the direction of the negative gradient, try to bring the current guess for that weight closer to the actual truth. So, on the for some iteration, K, I'm going to have this new value for some weight for some weight w, and then on the next iteration I should have a value for that weight that's closer to the ground truth. And this is called stochastic approximation. In this case, we have w case, K plus one, so this is going to be the value of w at iteration K plus one is going to be the previous value for that weight, minus the gradient of the error function. Right, so this is written here. And then for this, for this algorithm to converge, we have some constant here row. We want this to decrease the reiteration, not too fast, and not too slow. So this is the least mean square is the algorithm is drive by these folks with Jordan Hoff, this is often referred to as SGD or stochastic gradient descent. So now here's an issue if I have two output variables let's say that I'm trying to predict two things about a car from other other parameters, let's say I have a bunch of information. And I'm trying to predict what it's miles per gallon and its horsepower is, then this value t sub n is no longer going to be scalar. So into to predict two variables, I now need two linear models. So I can do this by changing w my weight matrix from a single column to two columns. And so now the first column will contain weights used to predict one value. And the second column will contain weights used to predict a different value. So now effectively, what I'm looking at is if I have my inputs x, this is a matrix that for every sample, contain the number of things I measure about that sample. And so I have a thousand cars, this would be 1000 rows in that matrix and if I measure five things about them, there will be five values for each row. And you can assign some means those values. And in case of linear approximation, those values are pretty pretty interpretable. And then I have some weights that I'm trying to solve for that will multiply by those inputs, I'll predict a number of other things that I'm trying to predict. So if I'm just trying to predict one thing about each sample. I'm just going to have, you know, one column of outputs from trying to predict two things about each time I'm going to have two columns of outputs. And so then if I have let's say 1000 rows, and then five inputs for each one. And then I have, you know, two things that I'm trying to predict and trying to solve for weights that will take those five inputs and predicted two outputs. And that means that it should have weights that are associated with every output that I'm trying to predict. So I'm trying to predict 1000 things. I should have a 1000 different weights. So, the linear model in this case would look the same, right, because I have weights that are just a matrix W. And as long as those, as long as those matrices are the right shapes, they'll multiply together and I'll get the expected number of outputs. And so that's just one of the, one of the, the advantages using matrix math is that if I just take that input vector and then they take the dot product with each of the two columns or n columns of W, then those resulting values will be the predictions of the items that I'm looking for. And now I just have to optimize those weights to predict both things at the same time. Now, you think this is going to take longer, shorter at the same time as predicting the weights to predict one value. Things are going to take the same time. It will take longer to converge to the same level of the same level error. And that's because if we have two things like, you know, if mpg and horsepower are not very closely correlated and those the two things are going to predict. Then I'm trying to optimize those weights at the same time. Right. So it will take a little bit longer. But the formula is pretty much the same. So what do we do to the update formula in order to make this in order to make this happen so we have to modify W to be the right shape. And then also for every sample for every input we have to predict, we have to specify the two target values. So this T sub n here this is also no longer scalers now this is to two values in a vector. So I have to note this is bold T sub n. So now instead of a single value, I'll have some number of output samples and trying to predict. And that's just going to that will be an arbitrary number just based on whatever it is you're actually trying to predict. And so now to update the weights, you have to multiply each error by every component. And this sounds like you would take a double loop. Last equation, we use matrix math and NumPy, and we did this, this operation can be done using broadcasting will see the code shortly. If I use NumPy broadcasting, then that allows me to remove the loop over all the components in X and in X and W. So now I use broadcasting again, then I can remove a loop over the target output. Right. So now, yes. And here is referring to particular samples so if we have, usually with the number of samples would be denoted as big N. So if I say I have 1000 samples. That's rose in my matrix. And so I say big N equals one, and then sub n is referring to an arbitrary individual sample. Okay. Any other questions. Okay. So right now just operationally, if I'm trying to effectively scale up to an arbitrary number of inputs and outputs. This naturally means we're going to have to scale up to number of weights. I want to avoid doing things like having for loops. And there's a number of reasons for that we'll discuss in a moment. And so I can use the functionality provided by NumPy broadcasting to effectively remove those four loops. So if I use it to say remove the loop over the target components in T. As long as your matrices are the right shape, then the resulting matrix will be the correct shape for W. And so here, if you've all the convention that the vectors are column vectors, then the new weight update at iteration K plus one will be the previous weight at iteration K. And then plus some scalar value times those inputs, except of N. And then what is this last term here represent. This is the gradient or. The error, right how far is the how wrong am I so you can think of it this way. But your model is always going to make a prediction. And you want to measure how wrong your prediction is. And the amount of wrongness will tell you how much I need to update my weights. Right. So, if I'm really wrong, then making a very, very small update in my ways is maybe not going to get me very close to the actual value. So I'm very, very close. I don't want to update the weights by too much or I could sort of skip over that local minimum or that the global minimum and just end up, you know, at some other so on the location. Right. Okay, so if row here is a scalar, then the input would be D plus one by one. So this is going to be D dimensions that is how many things I'm measuring about my sample plus one. So, I was just, does anyone remember from last time. What's the what's the one here refer to. Well, it has that effect. That's not really why we do it. Yeah. Yes, that's, that's the bias. I'm going to talk about the term yet. I'll talk about the minimum. But remember, we have, we're basically taking weight times input plus weight times input plus weight times input. So we have w zero plus x sub zero plus w one times x one plus w times x two until we get to w and times x n. It makes things a lot easier if I assume that there is going to be some place that I have to basically shift my shift shift my curve. Right. So, it may not necessarily intercept the y axis at zero. If we're talking about say I just issued a dimensional curve. And so it basically math works out much better if I assume that that x sub zero value is one. And so then I can multiply by some weight associated weight value, and that allows me to do the entire operation as a matrix because it's basically a sum over every weight times every input. Yeah, well, one is like the constant. One is the constant. This will get multiplied. This is the, this is the feature that will get multiplied by weight zero. And so effectively, we'll talk about this in a minute, but effectively this is a dummy feature that contributes no real information, but can be useful in optimizing the weights. So your inputs should be of size D plus one. So the number of dimensions per sample plus this constant one. And so then, T so the end will be K by one for K being the number of things I want to predict the number of outputs. And so the transpose of that will be one by K. And so then if this x T w is also one by K, then I can, I can effectively subtract those and I'll get meaningful information. And so if I string these together in the calculation, this will give me D plus one by one times one by K. So these two inner values, this should cancel out. And so this should give me a D plus one by K matrix. And that's the shape we want that weight matrix to be. Questions. Concerns. Okay. So in Python, if you look at the implementation, you can see that effectively, this is the same as this part here. Right. So I assume everybody knows Python syntax. So I take some value for double, you're going to update it. So I'm going to take a D plus equals row. That's our value here. And then times x one. So the x one is going to be my inputs with this column of ones that I append every sample. And I'm going to take, you know, basically one of these samples transpose it and then multiply that by T for that, that particular sample, and then the predicted value, whatever the output of my, my function should be. So if you're doing this would look like this. So if I have the number of outputs would be my target shape. I'll take the second element of that element number one. And then number of inputs will be x one. Take the shape of that. And then for every, every element of an outputs, then for every element of an inputs. So I'm going to update the weight w sub ik for basically the way the corresponds to for that input for that for that output, plus the update function. Okay. So more lines of code generally lead to more potential for bugs. And that's something that you want to avoid. So we prefer to do this the matrix way. So that way you're either doing everything right or doing everything wrong or doing everything wrong and will become obvious. And you can fix your operation. So, hopefully this is motivated, you know, a couple of things one, why we use matrices for these types of operations to the different components that go into computing and error update. The intuition behind trying to minimize the rate of change in your gradient. So, hopefully at least have some, some, some idea of that all those things are important and why they matter. Any questions for a go on to the example. Yeah. These notebook. Yeah, these notebooks will be here on. So this one, if you click there. Get you to do it. Yes. That's one that is one technique that you can use. So, row here will correspond to something called a learning rates. And this can be a constant or it can be changeable. And so, it depends on your use case basically you can start with a very high learning rate and decrease it as time goes on, or you can assume that I'm just going to specify a constant learning rate. So, if you can do that if the use case is appropriate, you're on a Soviet acquired to. Okay. All right. So an example of SGD in action. So let's actually see this actually executed over some data. The data is not necessarily going to be meaningful, but we'll see exactly how the update works. We will also do a little animation so you can kind of see the line that we're trying to fit to this data actually be shifted and moved and rotated in real time. So remember this is basically an affine transformation. So effectively I take a line and I can rotate it. I can stretch it. I can move it up and down. But the things that are colon ear and the input should be colon ear and the output. So there's going to be a limited number of things you can actually do with linear regression, but it's always a good first step to try. So what does make some random data. In this case, I'm going to have a hundred samples of random values between zero and 10. And then I'll assign the target to be some function, the output of this function here where epsilon is just a bit of noise sample from a normal distribution. So that can be done here. So here are my hundred samples. I will take my inputs and create random values from uniform distribution between zero and 10. I will create this into an end samples by one matrix. And then I will apply this function to create T. So basically, two minus point one x plus point five. The quantity x minus six squared plus epsilon denoted here by just this sample from a normal distribution. And so we'll have a default mean, we'll just use the default mean is zero default standard deviation of one in the above example we're using standard deviation of point one, because we don't need that much noise. So I do this. And this doesn't look very good. Right. Just a little little pie plot thing. Be careful exactly how you're plotting your data. So by default, it'll connect everything with a line. But remember that the inputs are generated randomly between zero and 10 and on generated in order. So it's going to basically connect these points in that random order. So instead, I will just plot them as points using the period. So here, here's my input data. Right. And it's just some random samples being zero and 10. And then I apply that function to generate the outputs and we get this, this sort of curve that looks kind of like the Nike swoosh reversed. Okay. Do you think we can fit a linear model to this data. Who thinks yes. Things no. I mean, I think we can fit a linear model to this data. Who thinks yes. I mean, it's kind of a trick question you can. It's not going to be a great model, but you can do it. So let's, let's, let's ask to go about that. The first thing we're going to do is we're going to take that input matrix. So remember this was created up here as X. And I'm going to include this initial column of a constant one. So now I will take my X insert a one at the front and we'll call it X one. Where do I put the concept column of ones. Actually, you will see that very across implementations. And in fact, I do it differently in my two classes in this class I inserted at the front. In NLP, the code is written such that we inserted at the back. It doesn't really matter as long as you know where that what constant column of ones is so that you're, you're updating your bias weights in the right place. For this class, we will be fairly consistent and we will be inserting that constant column of ones at the front. So your data always consists of your input value. So this will be the sample which is X or X one at the bias. So we have the input value, which are the targets T. So let's make sure that we have the right number of inputs and targets. This is a little correct. 100 by 200 by 200 by one. That should be. So we have our targets that should be 100 outputs that have them arranged in a column. And then here I have my 100 inputs, which are just single numbers, except now I've added this constant column of ones. So now it's 100 by two. Learning rage. So that's that row that we saw earlier, something specified to be some small number. So in this case, I'll do a point zero zero one. And then I need to make sure that the, you know, I get the number of samples. So this is just going to be the number of rows and my input. And so I can just save that out as into a variable that I can reuse. So I'll initialize the weights to zeros. And so here I will train for however many epochs in this case, I'll do 1000. So basically an epoch where sometimes pronounced an epic. I've observed this to vary between mostly UK and American English. I believe I'm actually saying it the UK way maybe. Anyway, that's a basically number of, in this case, a number of passes through the data set. And so when you get to more complicated models, we have things like batch size. And so there's a difference between like step and an epoch. But effectively, when we people talk about this, just consider passes through the entire data. It says, so when you have like a huge data set, say a big language model that you're training on, you may hear like, Oh yeah, we trained chat GPT for 40 epochs. And you're like 40 epochs doesn't sound like a lot. But remember how much data that's being trained over. First of all, it takes forever. And also that sheer amount of data is contributing so much information every pass through it that you only need 40 epochs or whatever to converge. Okay. So this is when we talked about, we talked about neural nets. This is one of those hyper parameters things that you can vary that you have direct control over in the process of training your model. So, let's step through this code so if I train for 1000 epochs, I'm going to make a prediction that prediction is why, right. So why is now going to be one sample. So, I'm going to say I'm doing n for range and end sample so I'm going to get the end sample multiply it by the weights w. So that should give me some predicted value for this input sample, according to whatever these weights currently are. So, I have the target. And so this T should correspond to this input. So this should be the ground truth target of whatever these inputs should are intended to predict. I'm going to take that and subtract why the prediction that I made. That's the error. Right. How wrong am I, there's a difference between the predicted value and the target value. And so then I'm going to update the weights by a fraction of the negative derivative of that square error with respect to the weights. And so that's this learning rate that's the row. So now here, this is going to be the input transpose times the error value. So, and then when I'm done, I will print my weights. So, try that. And we end up with these two weights of 3.125 and negative 0.264. So now this should give me effectively a weight that corresponds to the input feature. And the second weight, corresponds to what. Sorry, other way around. This way corresponds to the input feature. And this first weight here corresponds to what the bias. Right. So, sorry, for momentarily forgotten where I put the column of ones. So now that bias is this is this basically this is the Y intercept. Right. So the bias is what do I assume about my model if I have no other information. So basically, if my input contributed no information, what's the best starting point that would minimize my distance from the actual data. That's the bias bias in a technical sense. This will be how we're using it in the class. And then we will talk about bias kind of in the colloquial sense. The way you can think about it is this bias is, you know, we think of it as a prejudice. It's sort of is if it's like, what do you, what conclusion you're going to leave to about something if you have no other information. Right. It's you you prejudge something. That's your prejudice. I gave this example of if I, if my going something as I see someone wearing a backwards baseball hat, I assume that he's a jerk. I'm not going to read too much into that. We got a great paper out. So I'm just. But basically, this is like, and I don't actually think that about people who are backwards baseball caps. I'm just an example that I have not. I'm not going to read too much into that. We got a great paper out. So I'm. But basically, this is like, and I don't actually think that about people who are backwards baseball caps. I'm just an example that I have noticed there was someone in front of me. But the basically that's your, that's your, that would be like a prejudice or something that you would assume. And then once you get to know the person or the sample, right, you actually know like these, these are the other ways that I need to be. I need to be calibrating when I'm when I'm deciding things about about this phenomenon that I have encountered in the most abstract sense. But at this point of bias is basically, if I know the information, my model of all my other features are zeros, for example, what's my best starting point. And so that's the bias. And that corresponds to, eventually there's a dummy feature this one that we train that weight against. Yes. Great question. So there is, there's a whole lot of research into how we do this hyper parameter optimization for neural networks. And effectively, a lot of people will just be using trial and error. And so in this class, that's mostly what you're going to be doing. There are some techniques you can use like say a grid search, you can try out a bunch of different values of different, you know, say different training lengths and see which one of these is giving me the least error. And then maybe I can try and narrow it down exactly what that sweet spot is. It's actually, especially when you come to deeper neural networks, there's like just a whole lot of research and how can I optimize all the different hyper parameters that I'm trying and then trying to deal with because it's not just epochs here. Well, here it is just epochs, but it's not just epochs in broader use cases to have things like the batch size, the number of samples that you pass through at each time. The learning rate, you know, so for example, the. The tradeoff between training number of epochs and the learning rate, right, that can be directly proportional in fact or it's an interesting proportional. So if I take a smaller learning rate, I might train for longer and get a better result. Or if I were to take a larger learning rate, I could maybe get away with training for less. So there's no like this definitive answer, but it's a area of experimentation. Yeah. You will need to loop them manually to do grid search. At least there's one assignment where you have to experiment with hyper parameters. And so for that, you're basically given code that does it for you. You just have to fill in like what numbers you want to try. For like your project and stuff, yeah, you can import whatever libraries would help you. I'm not going to try and make you write all the code by hand for that. But for certain assignments. Effectively, you're given starter code and you cannot modify outside of certain places. Other questions. All right, so we train this model. And this is effectively doing why equals and plus B in two dimensions at this point. And so now I'm going to see how well this linear model fits the data. So I can just do this by plotting the models predictions on top of the actual data. And this is. This is our prediction. So the blue dots are data. The red dots are prediction. And so here you can see this X one, Matt, Mo W. That's that prediction value again. So what do you think? Not. It's all great, I guess. Let's actually see what happens as we're doing the optimization over the thousand epochs. So I can actually write this code that will basically run an animation so you can see where that line is as it's processing every sample. So in this case, what I will do is initialize all the weights to zero. And then I'm going to collect the weights after every update to plot them. This is just part of training. This is just part of visualization. And then I'll create a bunch of X values. And then for every. Every pastor, all the samples, I will update my weights and then we all plot the line for those input samples across the actual inputs. So you can see the prediction. So let's go. And so now you can see the black dot. That's the last sample that was just trained on the line is the current state of the model. And then you can see also how those values of W zero and W one are changing over time. So, you know, you can, you're free to adapt this code to do animations and we'll do we'll have some examples of these. You know, there are notebooks, but effectively we can just run that again. And we can see how the line just starts like kind of pretty much wildly opposite the general direction of the data. And then eventually we can see, you know, it's being that that wire intercept is moving up toward that three point something value. And then it, and then we can see that the slope of the line is also decreasing. And so you can see that those values are getting close to these two values here. Right. So the approximate Y intercept is just shy of three. And then the slope of the line is like slightly negative. Right. So that makes sense. I hope. Well, pretty quick. Okay. And so now we can see also those those values that I'm sort of, I'm going to qualitatively evaluating. Based on just looking at this line are being plotted here. So again, w zero. Ends up just short of 3.0. And then w one is in this case, it's just a little bit below zero points zero or negative point one five. Okay. So all this is to say that matrix multiplication is basically just solving systems of equations. Right. So I have a bunch of inputs and I have some output corresponding to them. And I have a bunch of these different samples and I'm trying to optimize for the values that solve that large system of equations. So do you have a simple example, we can solve a pretty simple system of equations here. So if I have 4x minus 3y will 17 and then x plus 4y equals 9. I'm trying to solve for the value of both x and y and I assume that you have done this, probably in like high school algebra class. So one way we can do this, the way that you may have learned is just through substitution. So I can solve for x at first. And I'll say, okay, if I solve for x using the bottom equation, I end up with x equals 9 minus 4y. Okay. And so now I can take this value that I solved for our software y or x in terms of y. And then I can take that value and substitute back in for the value of x and the top equations now I have four times the quantity nine minus four y minus 3y equals 17 as the top equation. So if I expand this out I end up with 36 minus 16 y minus 3y equals 36 minus 19 y which is equal to 17. So if 36 minus 19 y equals 17, then I subtract 36 from both sides I have 19 y equals negative 19 y equals negative one, now I can take this value for y substituted back into any one of my equations to solve for x, and it turns out that x equals five. So this way allows me to solve the system, and I end up with two values for x and y of five and one. But we can also do this with matrices so the way this works is effectively the coefficients here in front of the two values I can just plot as the inputs. And then the values on the right hand side of the equal side those are the targets. So I basically have some sample for, and some sample negative three, and then I have some sample one and some sample four. Right so these two constitute one input, these two constitute another input, and then the corresponding outputs of 17 and nine. If I saw it this way, so let's say I have my input x, and I'm trying to solve the values in these of these these coefficients here x and y. I can do this by taking the transpose of x and multiplying it by T, and this should give me something close to the expected value. So let me make sure I've run everything. And if I do the inverse function here, I end up with five and one. So pretty neat way of solving systems of equations using matrices, we, and we can demonstrate that we're getting the right values comparing to another method that we were already familiar with. We can also use the least squares. So this will return least square solution. Remember we, this function returns a few different values so w residuals the rank of the matrix and s. If we just look at double use those the ways we're trying to solve for it also gives me five and one. Okay. Couple of questions, you know, what are residuals. So from the doc string, basically, if the rank of a is less than n or, and is less than equal to n this is going to be empty array so that's what we get here. So there are no residuals. And so now if I print the shape, the rank of matrix x and then the shape of x and T, and then compare them, we can see that a is not less than n, but n is less than or equal to n. And so that's why the residuals are empty. What are residuals. Okay, so here is the definition in a nutshell of errors versus residuals. So the error is going to be the deviation of the observed value from some unobservable true value of a quantity. Whereas the residual is going to be the difference between the observed value and the estimated value of a quantity. So in this simple linear example. These don't really apply that is we get exact values and we know what our true values are, and they're also the same. But the prediction step is basically x transpose times T to solve for w. So if T contains an exact values, or the values that correspond to accidentally predict T, then the best you can do is some form of approximation. So we have residuals in larger neural networks and also working with more naturalistic data sometimes a residual is better than an error, because it allows you to optimize for the approximation. So in the last part, we're going to play with some real data. And so basically, if you want a hint about how to do assignment one, you're going to want to refer back to this section, because we're doing doing some very similar things just the different data. So, first, we're going to use this automobile data set from this UC Irvine machine learning database repository. So there are two things, auto data or auto dot auto mpg dot data and auto mpg dot names. So let me download those. So now look at the data first so this is the first step that you're going to want to do before beginning any experiment. Is actually understand how your data is set up. And so every, every data set that you download is going to represent it slightly differently you need to understand that how the data is represented and how it's organized before you can really make any progress so let's take a look at the contents of auto dash mpg dot names. So you will find that there are 398 samples, and each of them has these eight numerical attributes and a string. So the names those attributes are going to be the mpg. It's going to be continuous value number cylinders, which should be a multi valued discrete displacement and horsepower and weight and acceleration and all continuous values. So the number is going to be a multi valued discrete right just to just on years. Origin is going to be a number corresponding to some in this case country. And then the car name is a string. So this just relies to look it up. So first thing you want to do is import it into Python and look at it so we're going to use the pandas package that you all are. Should be familiar with generally in this course. High import, high plot import pandas and in later assignments import torch should get you pretty much everything you need with the exception of like you know cis and OS and the some other system mobile Python packages. But generally those four should cover everything that you need on where where the difference you will be notified of that. So let's look at some of the lines and figure out how to read it in. So I'll just note in this in this notebook. There are two cells. One for Unix systems and one for Windows systems is going to man is slightly different so depending on if you're running the notebook, depending on which system you use you're going to run one or other of these of these cells, since you're using a Mac or you the Unix version. So if you look at say the first 40 samples. Let's take a look at this remember what those values stand for. So 18 miles per gallon eight cylinders displacement of 307 horsepower 130 acceleration of 3504. Model year of 12. This is or. Sorry, sorry, sorry, wait, wait, wait, wait, wait, wait a 30. That seems like a lot of acceleration. Wait of 3504. It's a very fast car. Acceleration of 12 model year 70 in this case, 19 x x. So 1970. And then one in this case corresponds to like the options are us Germany or Japan. And then so one here corresponds to us. And this is a Chevy Malibu. So that's how the data is organized. It's not necessarily the most friendly organization, but you can do some things to make it more readable. Also, you'll see that there are some N a values here. Right. So in this case, there are some cars in this data set that, for example, we don't have the mpg value for. Right. So we have to handle that. And there may be any values in elsewhere in other columns. So for example, I think it's maybe, yeah, so one is us to is at least Europe. And then three is is Japan or Asia more broadly. So let's load this into a data frame. And here's what we get, and this is not friendly at all. Right. So, first of all, a couple of nasty things. One, it just read in the first column is the header. And then it also read everything in, in, in a single line. Right. So we have to format this a little bit better. So the pandas are read CSV doc string will basically tell you all you can do in pandas, or you can read through this pandas tutorial. But we're going to just get a format this. It's a little bit easier to read. So first I'm going to pass in header none so they don't get that first row as the header. And then I'm going to do limiter set white space as a delimiter. So now I get a nice format. So now I can actually get a nice looking data table. And I have my values in the first seven columns and then the name of the car in the eighth. You can see I also have 406 rows nine columns because they have this one index column here. So let's take a look at just a subsection here. So if you look at rose 30 to 39. I see a couple of things. One, there's some n a nans here. So this is going to mess things up so I need to get rid of them. So here, I can just do this by setting any values equals question mark. So now if I load this again. Let me look at I can't see any change here but I did know that there were some nans in rose 3339. So let me look at these again. So now let me do this drop in a and so now I have 396 rows or 392 rows. So you got rid of about 10 rows or so that had unfriendly values. So now let me look at that same sample. And I still have that n a well, something didn't quite go right here. I mean, any ideas. The any was removed in a specific place, but not in the data frame. Yes. So I did I did df dot drop and a, but I didn't I didn't actually receive this into df. So I'm basically doing df dot I walk. And so it didn't do that in place. So the drop and a function is not by default in place. And so now if I do df dot is n a dot sum, this will tell me, you know, how many n a values do I have in each column. Right. So there are eight and column zero and six and column three. So now if I don't do it in place if I do df equals df dot drop and a, and I look at that same subset. Okay, now it looks nice and clean. And so now if I run df dot is n a dot sum. These are all zeros. So this is what you want. Right. This is one way to make sure that you have no nans in your in your data. So if you run into difficulties with pandas, I recommend a screens tutorial. Some things to note if you're not familiar with pandas, but you are familiar with NumPy. The way that rows and columns are handled in NumPy versus pandas are different. And so it can be kind of frustrating and I personally like whenever we do a paper and I'm working on stuff. If it involves Panda, they use these spend like an hour trying to figure out like what I'm doing wrong with pandas. So just fair point, you know, if you start working with this, do allow time to figure out what the errors are and make sure that you are processing your data correctly, especially if the data is a large set that you can individually examine every row. Okay, any questions. Yeah. NumPy pandas pie plot. And torch. So, and you think we should import those for everything or we should pay for one of those. You will always use NumPy for this class in the in the code you're given usually the standard imports that you need. This is mostly for the people who would like to import like your favorite third party package that like no one else has ever heard of. I'm just telling you, those four will get you everything you need to do is no need to get fancy. And it's and even torch like we're probably not going to use that until a lot of assignments three I think. Yes. So, you can just do this. If you look at the, the read CSV doc strings will tell you like what all, what everything does. So basically. No, God, it's lost up near. And a values. So additional strings to recognize as nan. So, like, if there's if there's a question mark in the data set. It might just be like someone mistype something that they don't have the value. So basically I will just turn that into a nan and then I can remove it. Okay. Okay. Other questions. All right, so the first step to doing any kind of data processing is examining the data. The next step is going to be to visualize it. So one thing we can do is we can plot the value of every attribute in a separate graph. And so I'll make an array of columns, column names to label the Y axes. So instead of doing zero through eight. So I actually want to label these with some meaningful values so I'll set the names of those different. Other different parameters and PG cylinders, etc. So now if I said, D F dot columns equals names and I print the data frame again. So now I can actually see what every column corresponds to I don't to keep referring back to that list above. So this makes things again, easier to present, easier to interpret so don't neglect these pre processing steps because it will save you a lot of time. So I'll do it one more time up front, says you a whole lot more time at the end. Okay, so now if I just do D F dot plot. Well, that's not terribly helpful is it was a couple of reasons why one, one big one. I hear whispers. Right weight is in pounds. So it's like it's between you know 2000 to 5000 pounds. These are cars. So of course I'm following these raw values. But I'm looking at weight 3500 versus year 70. Right. I'm not going to be able to tell which one is made in 1970 versus 1971. I can't even really tell, you know, what the displacement values are. So I want to separate these out. So if I take a look at everything except the car names, I can just look at, you know, the day, basically see the different ranges of the different values. And already I can absorb even though there's some missing values here because there are nine columns. I have things that range from 70 to 82 and then also things that range from like in the hundreds to the 300s. So if I look at the type of my value, they're all folks 64. Okay, I can work with that. So now I can plot every data column separately. And use this code here. It's not can plot all of my different samples kind of nicely side by side using subplots. And so I'll plot the sample number on the x axis and whichever parameter value is on the y axis. So take a look at these charts. And tell me, if you notice anything interesting about these about these samples. What sticks out to you about this what relationships you see between the samples and the different parameters. Yeah. It seemed to be already ordered by years we have this like step function here. Anything else. There's all for young get better over time. I think so yeah because like it's ordered by year and we can see that if we can use this the sample numbers a proxy for time. You can see that. Yeah, of course, of course, power tends to be decreasing. That may be a slight correlation. Yeah, so there's a couple of things you might be able to observe. The first observation that you have to make is that the sample number is ordered by year. Otherwise, if you didn't have this, this one in the bottom left, you don't know what order is written. Right. And so now that I can see this, I can draw conclusions based on what I know about cars we know that. Automotive technology has gotten better over time and so a car that was made in a later year is probably an average going to have a better miles per gallon than one that was made early. So, anything else that seemed interesting about these. Yeah. You're basically. You're basically. Like. To make it more. Well, we don't really know. I mean, we, we want to look at, we need to look at the data kind of an aggregate. So, just from looking at the individual graphs. And then the first inputs we can make is that they're ordered by time and that can tell that can give us some other intuition about like what things are correlated with time, but we don't see things like, how does horsepower correlate with displacement or miles per gallon. Yes. In the corner. Displayed displacement is decreasing over time. So, like, some of these things seem to be correlated with time, but we don't know. Are they really correlated with each other. Right. Is it that cars are getting heavier or, what's this any correlation with weight. Yeah. Our car cars getting lighter over time and is that correlated with, is it really the weight of the car that makes the horsepower go down or the displacement go down or something. Right. So, as opposed to the year. So plotting displacement as a function of year may not be all that meaningful and really the dependent variable is something else. Okay. So let's try to predict one attribute, namely miles per gallon from the other attributes. So, first, we're going to make a 392 by one column vectors that's going to be the target values containing all of those mpg values, and then a 392 by seven matrix to hold all the other values. So I have these eight samples and trying to predict the value in this graph from the other ones. And so that this can tell me whether mpg is correlated with any of these other things we observed as correlated by year. One thing we can do with this knowledge, we can see whether our model is making some of the same intuitive judgments that we are. And if it is, then it stands to reason that its other predictions can probably be believed. Okay. So, let me get the target values. This is going to be stored in T. So I'll just print all of those. So these, this is the mpg data for every car in my data set. And now give me the input variables. And so this is the, these are all those other seven values. Let me just check my shapes to make sure that they are what I expect. So I expect 392 samples. I have seven inputs associated with every sample now in a single target value. All right, so now let me make sure that I have the names associated with the, the right values. So I want mpg to be my target name, and all the others to be my my x names. So now let me see if a linear model makes some sense. I can do this by plotting the target value mpg versus each of the input values. All right, so now take a look at this. So this is miles per gallon in terms of the other variables. What do you notice here. So, again, right. Yeah, so there's a correlation between weight and miles per gallon. So, right. So the lighter cars here have higher mpg. What else do you see. Yeah. Yeah, so the cars is greatest placement have lower miles per gallon, which might suggest there is some correlation between weight and displacement. Right. What else do you see. Same with horsepower so we see basically similarly shaped curves. When we look at the weight displacement and horsepower relationships with miles per gallon. So these are the, those are some of the continuous values. Any correlations between some of the other ones and miles per gallon. Yeah, so, well, there should be this. Yeah, here. So is there, is there is it a inverse relationship or a positive relation. Yeah. Yeah, so I do not know. Some weird things happen in 1981. So I heard this guy called Reagan. Right. I would have to look at my history to see if there were like any major deregulations that happened in 1981. The all go to industry. So it is possible in fact that maybe miles beyond did get worse from 1980 in 1981. So yeah, there's literally just degrading me just now. So yeah. And then also a couple of other things to note here. Cylinders right cylinders are discrete value. We only have three through eight. But there seems to be an inverse relationship between miles per gallon and cylinders. And those of you who know anything about cars that makes sense. Also. Yeah, and so origin also. So the American cars, European cars and Japanese cars. And definitely in the time span of this data was gathered. Japanese cars had a reputation for being a lot more fuel efficient and American cars were like pretty lousy. So there is a correlation between the, the origin of these according to this coding. And the miles per gallon, but just keep in mind. This is an arbitrary number that was assigned to eat these categories. If it had been, if Europe was one America was two and Japan was three, what we see would be the sort of each. Right, it would not be easy to fit into linear relationship to that. So in certain cases with these like multinomial classification labels, the way you organize your data becomes very important. This one simple change could throw off the entire linear model. Okay, so let us. Yes. Yeah, so you could. I mean, the first of all. With multinomial inputs, a linear model is always not is like not good anyway. So it just so happens that the way this data is set up, there is a linear relationship that this could be a helpful feature. But in most cases, this is not. So if you any sort of language work, right, if you, how do you represent word as a number of a one technique would be to have a big one hot vector for the size of my vocabulary. And if a word exists, I have a one in that space. But what that means is that every word is orthogonal to every other word. And I have no way of telling if cat and dog are more similar to each other than cat and truck. Right. And so that's the way that you organize your inputs and the way that you represent your inputs using more sophisticated things can be very important. All right, so in the last 15 minutes, let me finish this example. So we've observed some linear relationships between some of these parameters. And these seem to make sense given, you know, what we know about cars, even if we don't know very much. So now that this seems like this. These relationships that could be useful. Let's build a linear model. So first let's tack on this column of constant ones to the left side of my inputs. So now this will take care of that coefficient multiplication with w zero. And so you just do this using NP insert to NP inserts to basically the array, where you want to put the new value, the value that you want to put it on and then access. So the access that you want to be computing over. So here I'm just going to transform X into X one using that command. So now I have a 392 by eight. Array. If I look at say, there are a couple of samples, the first three samples. It's now represented like this. And so it's in exponent notation here, but you can see that the first value is a one now for everything. So now let's add a name to the X names for the constant column. We call this the bias weight so we'll add bias to our names. So now if I were to show this in the data frame. My first column should be bias and it should be all ones. That's not very useful. Because we know that's the bias, but this will come in handy later when we're trying to interpret the weights in our train model. So we can try to fit the model to all the data and see how accurately we predict the models per gallon for each sample. But that means this model is going to do really well on this data. But if we show it other data, there's no guarantee that it's at all going to fit to that data. It could be, you know, wildly off. Or it could fit perfectly. We just don't know. So a much better way to avoid this kind of overfitting as we call it is to basically hold out some samples from the training. So we're going to train on a subset of the data and then demonstrate that the model is working by evaluating it on new data that it hasn't seen. So this will work here. Because we are reasonably assured that any data we remove will more or less resemble the data it was trained on. But we want to be kind of careful in how we partition that test set from that train set. So one way this could go wrong. What if I just held out all the samples from 1982. Right. Or what if there was some weird anomaly in 1981 is Reagan deregulated something. What if I held up my 81 and 82 data and it trained on 73 80 and suddenly it's not a good fit for that 81 and 82 data. So we have to be kind of careful about how we select that so how do we partition these joints these these subsets. So common practice is to randomly select some portion as the test set and then keep the rest of the training set. So a typical partition would be 80 20. But you know you can you see you'll see different distributions 70 30 90 10 even 50 50 sometimes if the data is particularly sparse or particularly information rich. And but for the most part, you know, we'll we'll stick to 80 20. So we'll partition our samples into training and testing sets will just deal with the row indices. And then we can randomize those and then take that same selected slice to get those corresponding rows and X and T. So let me calculate them numbers samples in the training set. So, and I've got 392 total. If I take 80% of that and round it it's going to give me 314 and then the remainder 78. So if I use an 80 20 train test split. I'll have 314 training samples and 78 testing samples and that'll cover all of this, the data that I've got. So now I want to randomly select those 314 rows and take the remaining samples as the training as the testing set. So what I will do is I will just shuffle all the rows. So now I have my rows arranged randomly. And then I will take my end train which is computed previously as 314. And then I'll take that first 314 as the train and the remainder as the test. Now I have, we see we started 41 58. So I take those first 314 these rows are going to be my training data. And these rows are going to be my testing data. Check and see if they're disjoint to intersect 1 D. This should be empty. Okay, so now I have successfully partitioned my training for my testing. Okay, so now I can take those train indices elements of X1 that will be my X train similarly for T train. And then, you know, the same for X test and T test. Check the shapes to make sure that everything looks good. I have 314 training samples 314 targets 78 testing inputs 78 targets. Okay, great. So now I can use my SGD loop previously shown to find good weights. So first thing we're going to do is we'll add a calculation to track the error. So I want to see how quickly this sum of squared errors overall samples decreases. So as I optimize my weights that sum of squared errors overall samples should be going down. That means I'm optimizing my models toward that global minimum. So more meaningful is actually the square root of the mean of squared errors to RMSC. So this will be a common metric for these regression examples. This allows us to have the units of the error in the same units as the target variables, rather than their square. So if I'm trying to predict miles per gallon. I want to know how many miles per gallon I am off not how many miles per gallon miles squared per gallon I am because that doesn't really make sense. So this allows me to have an intuitive metric that I can then report my results and say I'm I am literally this far off on average. So RMSC is going to be taking all the residuals I'm computing over the training data or all the errors of finding the testing data. So here come back to that residual versus errors. So I don't have any ground truth in my from my test data in my training data so I can use the residuals to compute an approximation. Where are an element of the set of residuals or he is going to be an element of all those individual errors. Okay, so now let's run this. So in particular, let's look at the tiny size learning rate and we can try running it again. So if I have if I train for in this case, what 50 epochs, we can see that this root means greater error value is in fact decreasing. And this is what I want to see. Right. So 9.77 down from 19.1. If I increase the learning rate or decrease or decrease the learning rate. What happens. So we start with a higher value, but we end up over start with a lower value. We end up not quite as optimized. Right. So we can play around with this learning rate. Let me increase it. But if I make it too big, then we run the problems. So effectively what is happening here is learning rate is too big is I'm there's some global minimum. I'm trying to approach. And it sort of keeps skipping back back and forth across it. And so I will never reach that. So learning rate is going to be a very important hyper parameter. We could also train for longer by train for 100 epochs instead. We can see that now I'm getting a RMSC of about 8.2. So let's see what happens with my linear model, which is now just these weight matrices. And I'll use it to predict W for the first four samples or predict miles free onto the first four samples. So this gives me some some values. Remember, these are randomized. So let me predict, compare them to the actual MPG values. So I'll take a two column matrix, or I can use a four loop to print them. So now it's predicting a value of nine for a true value of 14, a value of 19 for true value of 17 and so on. So it seems to be off, but it's hard to tell if it's consistently high or consistently low. So you can play around with the values of learning rate and number of epochs on define the values that result in lowest RMSE. Let me print these four samples. So this is a pretty print version of this matrix above. So now let's try all the tested and plot the results. We can see over the entire test set how good my model is. So there we go. Okay, so this is, you know, choose one of these. I would say this is not great. It is consistently low, but I also want to know how numerically how wrong I am. So let me calculate the RMSE. Our predictions are about eight miles per gallon off on average. A couple of things we can do to fix this. One thing is to standardize the variables. So we've discovered the learning rate has to be really, really small to prevent these updates from resulting in man. And this because this is because this larger learning rate when I multiply by these inputs x. This will basically send me back up the far side of that gradient curve. And so is there a general way to deal with this problem. So let's take a look at the different ranges of our values. So I plot the min max and everything. We can see that I have, you know, ignore the bias, but things from like three to eight, but also things from 1600 to over 5000. So since each input value is multiplied by its own weight, the magnitude is of those weights are going to be very dependent on those range of those inputs. And so, the step size and gradient descent is going to be very dependent on the range of input values as well. So we can minimize this will standardize our variables. This means that according to the min max of weight. I just, I want to know like how close am I to the minimum maximum values rather than what's the absolute value. And that means that the min max of weight can be rated from like negative one to one or zero to one. And so can the min max of cylinders or, or year or anything else. So we need to do this. So basically what we'll do is we will adjust the range of all those input variables. We have a mean is zero and a standard deviation of one. Overall, this training samples. And so those values that are most dispersed from means that the highest standard deviation of the set. We don't want to do this with the with the bias, because they're all ones. You can't compute a standard deviation over a set of constant values. You want to make sure when you're doing when you're doing the homework like standardize your values before you append or prepend the column of ones. And so now also to do this correctly when you're purchasing data into training and test sets. You need to also only calculate those means and deviations using the train set. So that you're standardizing the test set to the same range. Right. You might have something that is outside the min max of the train set and the test set. So at least that that value that you standardized it to be meaningful if you're using the same means standard deviations that you calculate using the train set. So then you store the means and standard deviation training data and then use them again. So we calculate the means calculate standard deviations. Apply those to the train set. And then now I can see that I can, I now have standardized values. So these should be a lot friendlier for my sgd operation means of the same shape. And then I can also perform standardizations using those calculated means on the on the test set. So now let me try this again and note the much larger learning rate here. And so now the standardized values my root mean squared error is now in 50 epochs down to about 3.3 as opposed to 9. something before. So now I can make my predictions over my test set. And these look like they're a lot closer to those true values. So now let's try it again with test data and plot the results. And this seems to be a much better thing. So with standardized variables were much less sensitive to different values of the learning rate. Finally, what's most important, what's the most important feature for predicting this with a linear model, we can actually see this with a neural node is much more difficult, but with linear model, we can actually see which weights are correlated or inversely correlated with the outputs. So which of these attributes we used are most important for predicting mpg. Maybe you can remove some if they're not useful. So if I looking at the magnitude of the weights, we can see which ones are positively or negatively correlated with the output. So, for example, the bias is the bias that has no real correlation. So if you look at the, or this is the min max. So you look at the ranges, you can see no change in the bias. The standardized variables range from like negative 1.5 to 1.5. Let's look at the weights. So these are the weights that are associated with everything. Now we can print them according to those different values they're associated with. So, I'll tell you what you observe about these values. So the bias is 23, which is probably pretty close to kind of the average amount of this data. And so if I've no other information, 23 seems to be pretty good guess. We see some inverse correlation. So, for example, we observe that mpg increases with time and in fact, year is highly positively correlated with mpg. We also saw that it's a negatively correlated with weight. And so we see a negative weight associated with the weight input. Right. And so, if I had a ton of different variables might be easier to sort them by their magnitudes. So I can do that. And then I can plot them according to which parameter is the most important. So, yes. So, I'm sorry, say again. No, this is because this is to, this is to sort them in just descending order of magnitude. And so then I replot them with the signs here. And so now I can see if I that the weight is very important, but it's got a negative value. So it's very important, but it's inverse correlation. Whereas, year is also pretty important, but it's not quite as positively correlated with mpg as weight is negatively correlated. Okay. And so you can look at this data and see what you might expect to correlate with predicting mpg positive weights indicate that the positive correlated negative weights indicate that's inversely correlated. Okay. So I will do the last bit on Thursday before we get in on the near features, because we have no time left. But thank you and I will see you in a couple of days. Bye.