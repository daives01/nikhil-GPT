 terms of customer service. All right, you already going. Okay, so everybody should have turned in assignment two, which is good because I can pick up on the notebook that I left off on last time. We will try to get this back to you within about a week. So today I'm going to go finish this code reuse notebook is a short, then we'll start classification using neural networks and then I will assign assignment three. So I'm going to assign assignment three today. You have like a solid three weeks to work on it because I didn't want to give you something during spring breaks. This is due the Tuesday after spring break. So you have time. I do recommend that you start early, especially if you want to have some some spring breaks. I'm not going to be here. And so of course, I'm not going to be holding office hours. So recommend you start early. And give yourself time to to work on on this. So, I guess without further ado, let's do this one for real. I hope you enjoyed the extra 30 minutes I gave you on Thursday. So these these notebooks are now available again. Note that we're not going to do a re-raid on assignment two because basically the answer is now given to you, or an answer is not given to you so you know this this one is not going to be eligible for. And if you do want to resubmit assignment one reminder to those are due. That's a hard deadline so we will not be accepting anything else on assignment one after midnight tonight. So, as you recall, you know, if you want to modify your neural network implementation or any other implementation, you can either add arguments to parameterize the different behaviors, or you can replicate code from the original class using class inheritance. So first, let's just show our neural network implementation. I'm not going to go through the code because you've already seen most of this before here's optimizers and has an admin implementation there. So now we will import optimizers and then here's a version of the neural network code, you'll notice the familiar functions that these have all been filled out. So your this is basically your implementation or something close to it if you if you've got full credit on assignment two. Remember that what we had before was we had activation function argument, and it, you have to change this to specify whether you want to use 10 h or Ray Lou. That was that was part of your assignment, and this had to be added in the neural network instructor calls in that in function. And now, what I can do using this is I can now define two different instances of the neural network at 10 h version and Ray Lou version that have the same architecture otherwise simply by just passing activation function to the to the constructor. So now if I just print this it will show me that I've got an instance of neural network that has an input input size of 10 hundred hidden units followed by 50 hidden units, and then alpha size of one uses the 10 h activation function. The other one is the same just uses the real application function. So, the same two kinds of neural networks could actually be implemented just using two separate classes. Right. So we can say we can have two classes one called neural network 10 h and one called neural network Ray Lou, but you would observe already I think that most of the code in these two classes is going to be identical. And so, if I duplicate all this code into separate classes, you are effectively by yourself a future headache because one day, you may decide that oh there is a bug or I want to change some functionality, and you do it in the 10 h version, you have to replicate it exactly in the Ray Lou version or your code is going to work differently. So you make one mistake. And all of a sudden you have diversion implementation. So, you know, one of them might not work or may not work the same and suddenly your results not directly comparable. So, instead what you inherit, most of the functions for one class to create the second one and only change those things in the second class that would directly overwrite things in the first class. So, this would be going through using real time or I can find my typos. So this would be readable if you just define two functions. So we'll call the activation function activation function gradient. And of course the things that I want to change about this, this new version of neural network is going to be the activation function. So, if I just to find these in the first class then I can overwrite them in the second class with a different functionality and everything else can remain the same. So, it makes sense to define the second class first, and we'll just see how this looks in terms of code implementation. So if we assume that neural network 10 h is already defined and I can just define my neural network Ray Lou by passing the neural network age class as an argument into the class definition. So, we have neural network Ray Lou will inherit everything from neural network 10 h except now I have these two functions for the Ray Lou activation and the real gradients that have the real specific behaviors here and so presumably they were just overwrite any equivalent implementation in 10 h. So we run this. I didn't give me an error because I'm sorry, there's an error there previously but then I ran the rest of the notebook so if I if I cleared the kernel and run this get an error. Okay, that's because the neural network 10 h function the first time you'd run this notebook has not been defined because I've already run the notebook completion once it has been defined so it doesn't give me that error. Okay, but if you got that error, what you need to do is you need to find the original neural network class redefined to use this activation function and activation function gradient functions, and then I'm going to rename that to neural network 10 h that it matches the definition that the neural network Ray Lou implementation is expecting. So if I define neural network 10 h you will observe that it looks pretty much the same as the current neural network implementation, except when I get down to here, and now have instead of, say, the 10 h function, or the Ray Lou function as you define it I just have a generic activation function and activation function gradient. So of course these have to be when I define this is basically have to be initialized in memory of some behavior, right I could just say pass, for example, just ask you were here, that would basically say do nothing, but then, of course, if I tried to run this. And then I would not have that that requisite behavior so I'm going to define some default behavior, and for the purposes of this demonstration I would just assume that my default behavior is going to be using the 10 h function right so if, if not defined your activation function is 10 h. So, you'll see that we now return the 10 h and then we return one minus y squared which is the same as the gradient 10 h. So now forward pass same functions as before. So now I can define my second class. So now I have an instance of neural network Ray Lou that inherits from that 10 h version, but over writes the activation function as gradient. So now, you'll observe that this version here instead of having this activation function argument that specifies in a string form, what activation function I want to use. I now can use this one. So I'm going to compare these. So here's neural network using the activation function argument and then here is the differences, different classes, where I don't want to specify that argument so there are different advantages and disadvantages to this so like one advantage that in the small example is not that significant but might be if you're using this at a large scale is that like I don't have to specify the activation function name in a string. So, I'm not taking a typo and that string or something. So, in that sense it's a little bit cleaner, but there are some obvious disadvantages, and in general, we'll see one of these techniques is preferred yes. Would it be well to implement the way that the data is functioned just one, you know, that would last, would it give them a different value because you're referring. So you mean both the tenage. Well that's what we're doing in this first version here right because then you have if you have if I have all these functions available. Whenever I run the neural network I have to specify which one of these I want to use. Right so that's what this activation function argument is doing that's what you did in a two effectively right. So like there's both of these are valid strategies. And we'll, we'll see at the end that in fact the strategy that we were using is probably on balance preferable. But it's important to understand how you can do this. So we when we do, I think it's assignment three you have to basically take your neural network implementation or a neural network implementation for regression and redefine it to classification, which is you if you've been paying attention there are some differences there but you don't have to change the entire neural network architecture. So it makes sense to kind of inherit from a generic regressor neural network and then overwrite certain functions to make it classifier. Yes, like an example of what we might do but this is the series for this. No this is not necessary for Simon this is a, this is an example of how to use class inheritance. It's simple enough to illustrate in a few slides but it's probably not what you actually want to use this for. Okay. Nonetheless, let's assume that you know that I'm just going to be using this to define different activation functions so now if I put instances of this you can see that now I've got these two separate instances of what are different classes, although this one neural network is the same as the first one, they have the same architecture. So now you can see that this approach you know worked pretty well, but now imagine if I have like a bunch of different activation functions right we talked about 10 to talk about Ray Lou. Some of you may have implemented the switch activation for a to write there are a bunch of other different activation functions talked about, you know, J Lou, E Lou, etc. So I don't necessarily want to define like a different class for every single one of them when I'm just overriding like two functions. So you know you have to implement you know, let's say, if I have three variations with each with two choices, right, I'd have, you know two to the three eight different classes. So even this bit here just doing it for these two, these two variants seems a little bit excessive. So you have to remember like all the class names so on balance for this for defining the same type of neural network for this for similar tasks where I'm trying to do, say change the hyper parameters on balance for that approach. So if I have an argument that I can specify is probably the better approach that allows me to implement the different functions that I need all in the same class I don't remember different class names. And I just have to specify which arguments I want, because here we can effectively define a neural network with these four arguments where NH is a list, and it's just specify the input size the network architecture and the output size and the activation function for arguments for this function doesn't seem excessive. And it would be more so like if I were trying to define radically different neural network architectures in the same function, and instead of specifying, you know, feed forward versus convolutional versus recurrent in the actual constructor itself. I have a like type argument where it's like CNN and then I specify all the other things I have to set up my neural network as a convolutional neural net based just on this argument. So I'm not necessarily the best way forward for that so when deciding whether I want to use class inheritance or arguments for specifying neural network parameters. It's kind of important to consider what exactly you're going to be editing right so for activation functions. I would argue that probably using this, this type of argument based method is preferable for different types of network architecture or for different types of network like classes entirely. So feed forward, regressors classifiers, the convolutional nets recurrent nets, etc. Then it makes more sense maybe to have some sort of base class that has like all the functionality you know is common to all these things, and then I just have to modify certain functions. So that's what we're going to do next. So we can take, you know, create different types of neural networks and then use, say, the same implementation of like your optimizer your training function those those things that maintain their same basic shape, and don't change a whole lot, even when you may change radically change the particulars of the architecture using class inheritance is probably the better way to go. And so for example that torch dot and module that we used briefly kind of provides you with all of this basic functionalities right so when you when we, when you do a assignment three for example you're going to be using pie torch and you need to refer back to the autograd notebook notebook eight. And so if you see things like you know, lost dot backwards, right, single function called it basically does all the backdrop for you. That's part of that neural network module and so I wouldn't have access to that function of I didn't inherit from the neural network module. So these lower level things with regard to the, the functioning of the neural net is probably a better use for class inheritance whereas some of the more hyper parameter tuning like things that you're going to be doing in most of your neural network usage, probably can be specified in in argument structures. All right, questions on this. All right. So let's start classification. And I will try to get through all of this so I have time to talk about assignment three, if we believe a little bit of this to Thursday it's probably okay. So, previously, we talked about regression, right, we did linear regression non linear regression all of these are predicting continuous values, right so you use the neural network as a way of introducing arbitrary non linearity to effectively construct a universal linear for predicting continuous values. So, the principles are that we have some non linearity that's applied to the output of some hidden layer so that would be say I X times w gives me some set of scalars I apply some 10 age to them. And this, then the output layer is going to be linear in w and that gives me my, my prediction. So now when I'm optimizing my neural network, the values of w are going to be optimized, effectively with the assumption that there's going to be a 10 age or just some other non linearity applied to it so that of course, if I optimize the weights for a 10 age network, and this like clone them into a relude network going to get drastically different performance for us because the actual outputs are going to be different. So, we have this scalar output, then what a classified categories instead, right what we did is we basically want to classify these things into probabilities that they fall into one of a set of k classes. For that we use in the previous notebook number number 10, we use logistic regression, this included the softmax calculation given here. So this does you know just exponentiate basically the output of the, the output layer and then some overall possible outputs. This is going to take the I prediction of X is going to turn this into a probability and that probability represents the probability that sample X of I falls into whatever category is denoted by these weights or more properly, since all our weights are going to be starting in a big matrix each column is going to be associated with a particular category, and so weight sub k of that multi class weight matrix w. So the softmax on this this part here right this is the prediction this is the output layer in the sense that this is the output of that final multiplication by those output layer weights. So this is going to be again still some scalar value, then by applying the softmax function, this allows me to turn it into a probability, and then turn the linear model into a logistic problem. So, when we previously introduced neural networks as this way of arbitrarily introducing non linearities into regression problems. So now we want to do classification so what might be some thoughts you might have about how to do logistic regression as you may remember from notebook 10, but in a non linear way. Yes. So if you have neural networks that have multiple layers and activation functions that's our way of arbitrarily introducing non linearities right so if we just had that which ended up with would be a non linear regression function. And then we discussed that how we can turn a regression function into a classification function is the application of the softmax. So this is going to turn those k predictions that I want to make about some sample into k classes and the probability that it falls into each one. Right, so basically what we're doing is we're now just putting together the pieces of things we've already learned we talked about softmax. Last week, and we've been doing neural networks now for a couple of weeks, and so we're just going to apply the principles of turning scalar values and probabilities using softmax to the use of neural networks as universal non linear function approximators. So, let's just review some of the math. So, remember when you're doing classification, we're basically trying to arrive at the set of weights that would allow me to maximize the log likelihood of the training data. We're trying to maximize the likelihood of the training data but we work in logarithms because of these nice properties that allows to add and so multiply. So we don't get these very infinitely small probabilities. Instead, what we get is just a set of negative numbers and you're basically trying to figure out which of these numbers is the least negative. So, it's a lot of maximum likelihood. So just recall we're going to be using more or less the standard variable definitions so dub big w is going to be the whole weight matrix. And then x is going to be all the inputs where began as a number of samples. Therefore, X of n is the end sample. Big K will be the number of classes and therefore the little K will be an individual class index. So these are going to be the target values or remember that the target values are now class indices. And so these are indicated variables where I have a string of zeros and then a one at the index index that represents the appropriate class. And so therefore T sub T sub and K is going to be whether or not sample and falls into class K. So you just think of this as being basically binary for K columns. And so if it's a member of it either is or is not a member of class zero and either is or is not a member of class one so on and so on until class K, and then by n rows, read sample. So, now I basically just have an N by K matrix representing my outputs. So now P of C equals K given X of n is going to be the probability of class K, right on the left side of the bar, given sample X of n. So for simplicity sake, usually just say P of K given X of n. We can also rewrite this as some function G sub K of X of n. And in fact we'll shorten it further to G sub n K. And then we talked about how this arbitrary function G that we arrived at is actually the softmax function. So we're going to be involving exponentiation and logarithms to basically show that if we perform a certain set of transformations, we can then drive the probability for a set of classes. So, if we have the likelihood of W, this is going to be the probability for all N for all K of the probabilities of some class K given some sample, exponentiate it to the indicator variable. The other thing that I notice is that this value is basically only, the only exists only not is only not one when T sub N K is one, right, so if I raise anything to the zero it becomes one, and then their product of course that just cancels out to just that. So similarly, if I then take the log likelihood all I'm doing is I'm now just turning all my products into sums I'm bringing my exponent down in front. And so now the logarithm of one is of course zero. And so the same is true if this T sub N K is zero, then that also goes away. Okay. So for the log likelihood is going to be the sum for all and over the sum for all K of the indicator variable times the the log probability basically. So now the gradient of log likelihood will be given as follows. So if this is our log likelihood function. And then we have G being realized as a softmax function. And let's just define why sub N K is being that prediction for the output of sample and for class K. So in other words, this is going to be the weights of that class multiplied by that sample. So therefore, we've now arrived at the same definition softmax function we had before. So now if I take the partial derivative of both sides, I end up with the following so now I'm just taking the sum for all and overall K of T sub N K divided by G sub N K right this is the actual target. And this is going to be the actual the prediction value. And then I multiply that by the partial derivative of G with respect to w. So if the general gradients looks something like this right so now we have effectively the partial derivative of the prediction with respect to the weights times T sub N K minus G sub N K so this is going to be my ground truth target and minus my prediction. So once again, this part is my error term. And the same as T minus y in the linear regression problem. This is basically what's my ground truth minus one that I predict how wrong am I. So again, T minus softmax is going to be how wrong am I just going to be how off are my probability distributions. Right so if I'm very correct, then that for that ground truth, it should be very, very close to one, because in the target values my only choices are zero at one, and then I just do that. And then I take the sum for all classes and then for all samples. So for linear logistic regression, why sub NJ that is the product of the weights time input. So therefore the derivative that will only exist when Jay is the class of interest. So I'm going to do this for each of my classes. But for all my classes except for the one that actually is the truth value, I'm going to get zero. So I just want to optimize away from those and toward the thing that I actually have a value for. So therefore, the partial derivative of the log likelihood of the weights with respect to the weights is going to be equal to the sum of your error terms times x sub D J, where D is going to be that particular input. So the nonlinear version is in some ways a little bit simpler if you remember how our neural network operations work, because effectively all I'm going to be doing is the same neural network operation that we've been doing just with the softmax at the end. Let's remember the general form here. So we just have some weights w. So to include the nonlinearities they have to have a hidden layer. And so what is called this V. And so then the log probabilities of the K classes given X are going to be H some activation function over X times V times W. So remember the quantity here X times V that's that hidden layer output before the activation function. So previously we call that Z, or maybe a, and then I'll apply H over a maybe call that Z over the output the final output of my hidden layer. Then I take that multiply it by my output layer, and that gives me my pre softmax prediction. And because we're not still dealing in the world of logarithms. So we're going to take the top part of the softmax function, right, e exponentiated to Y sub N K. The log of that of course this will just cancel it out so we'll assume that all logs here are natural logs. So we have Y sub N K. So now, why some NJ where J is just whichever class index I'm kind of focused on at the moment is going to depend on V and W. So, therefore, the log likelihood of V and W with respect to V is going to be just the same as as above except for the partial derivative of Y sub N K with respect to an individual weights in V. And I do the same thing, just with respect to W. So now here at the end, the only thing that changes is going to be just what happens in the, and the dominator of the partial derivative. And so now the log likelihood of V and W with respect to W is going to be just the sum for the error terms times the partial derivative of Y sub NJ with respect to W. So we calculated these, these two things, it turns out in the previous neural network lecture, right so we already went through the derivation of how we calculate the, the derivative in order to, in order to do back prop. So this is in the training by gradient descent section if you need to review. Again, eventually we'll see this in Python so this is all getting a bit sorry for you I don't think you need to worry. When you compare the above with the derivatives of the mean squared error in regression problems you can start to see the parallels. So here, E, this is going to be our error term, this is the thing we want to minimize in a regression problem. The distinction between that and log likelihood is going to try to maximize the log likelihood, but the operations are probably the same. So this is the formula for squared error. And so then below that we see the derivative, the partial derivative of the squared error with respect to each of those weights. So you now start to see the parallels between these right so here we have my absolute error term, right and a square that to get my, my root mean squared error. And then here I just had sort of the class, the class relative error term, I'm not sure that's really call it that but this is the error term in terms of my probability and then I take that and subtract my softmax. Yes. Yes. So basically what we're not thinking of some of all the classifications of the large partial derivative. And in this one. Yeah. The partial derivative above that is pretty much the same. Right yeah so what we do here is we're basically taking for this is going to be some class specific class K. And this is going to be for a arbitrary class of J. So I'm just trying to I'm just I'm trying to compete the partial derivative of Y sub NJ for this particular class which may not be the actual class of the out the ground true class of the output. And so I'm just, I'm just trying to compute the log likelihood the derivative of the log likelihood with respect to the weights that define this class. Okay. So, so we're going to go to the regression. So we can just compare these to the actual likelihood. And basically see that there's a strong parallel between the regression version and the classification version, just by recasting the error in terms of log likelihood we're now my prediction is basically the softmax distribution over different classes. So, the previously derived matrix expressions for neural networks. We can just use those in as we have been all we need to modify is the output calculation so this is squared error right so standard first two lines are my kind of standard neural network operations. So I take my inputs times hidden layer weights applies an activation function, take the output of that times the output layer where it gives me why. So now I have all my T is minus all my why is I'll use that to compute my error term. And then the derivative of the gradient of the hidden hidden layer weights is going to be the error term times the times the weights. So again, I'm going to multiply that by the derivative of the activation function from that from that layer, then multiply that by the input. And then the gradient for the output layer weights is basically much more straight forward all I have to be concerned about is the actual error. So, now the changes needed for linear sort of nonlinear logistic progression follows. So, T is going to be the indicator variable version of T. So remember this is going to be some N by K matrix, where there are all these one hot vectors. So the first two things are identical. Take inputs x multiply them by hidden layers, take an activation of that, then take the result of that multiply them by the output layer this gives me some scalar prediction, so far the same. So now what I do is an exponentiate that scalar prediction. This is going to give me you know some some other scalar value, and then this I just sum across all the columns, and then divide by that some. So, these three lines didn't work out well. Okay, f s and G. That's the softmax calculation. So I take the exponentiation, and then divide that by the sum of all the exponentiation. And so then the log likelihood is going to be the sum of the indicator variables times the log of the softmax. And now, these two are having these two lines are partially highlighted are effectively the same as above. The only difference here is instead of a scalar prediction why I have a softmax prediction G that is a probability distribution. And I still have I can still use the same activation function, the derivative to calculate the gradient. And then the only difference with the output layer is I just have my softmax probabilities and subtract those from the indicator very. So, yes. I just found the very last layer just in the very last layer so you can think of it as like neural network is proceeding as normal. And then at the very end I just decide, well I don't want to continuous value actually want a probability distribution slide perform the softmax operation that turns that into a probability distribution. And what that means is that the error term is literally just, it's still a distance metric. It's just now for every the ground truth for every indicator variables basically going to be a bunch of zeros and a one. Think of that as probabilities instead it's basically 0% except in one case where it's 100% because we know this is the class for that sample. And so now I'm just trying to maximize, or try to minimize the distance between my predictions and that ground truth, and that only makes sense if I'm also predicting probabilities I need to have some functions going to turn my output into a probability. When you graduate they will call you begging for money. Okay, so how do we do this for two dimensional data. Let's just try to create some two dimensional data and then try to separate the distinct segments using using a nonlinear logistic regression. So I'm going to use kind of similar example to this one. So if you remember from when we did really activation I kind of had this this chart where you have these sort of two curves. And I gave it as an example where you can combine some nonlinear activation functions to fit a curve to it right so if you get a 10 h function, you kind of want something that rises and then peaks and starts to fall for relu, you're going to get a more piece wise curve, but with enough to get a 10 h value to lose, you can try to fit this pretty approximately. So let's do something similar except not trying to not trying to fit a curve to this data. I'm trying to fit a curve between sections of data, and this curve would be an example of what kind of function. Decision that's not a bad choice but wasn't quite what I was going for but when you make a decision what are you doing between choices. Like the first five letters are correct. This gray as we call this a discriminator function. Yeah. So basically what I'm trying to do is I'm trying to find a line that's going to keep as much of the blue dots on one side and as much of the orange dots and another side and it's not going to necessarily be perfect, but you can see sort of I just trace my mouse, kind of like that. This might be an example of like a suitable discriminator function. So I'm going to make some two dimensional data this time that has similar properties. So, this thing looks like a tide pod. Don't eat it. And so now obviously just by looking at this you can tell that like, there's no way that I can fit a linear function between these areas. Right. There's just, there's no, no such linear function, unless I add a third dimension, where each of these are like this are like distinct along some z axis or something right. In fact, it would be pretty difficult to just fit, you know, an average kind of deformed linear curve to this. Right. What's single curve. Can I draw between regions is going to separate all my points, not not one. There's nothing that works very particularly well. So what we're going to try to do is we'll try to classify this data using a five hidden unit neural networks nonlinear logistic regression. And my goal here is to basically separate the portions of the tide pod right all these individually colored points are taking the instances of a different class. And so I need to be able to classify them accordingly so you can think of this now as clearly a problem that has to happen in multiple dimensions I've got three classes, just by looking at the data we can see that if I'm restricted to working in this plane that you see here. I cannot do this even using like the most nonlinear function I can compute. So we need to have multi dimensional data. So what I will do is I will now define a new class called neural network classifier, and we're going to do this by subclassing the existing neural network class and making relevant changes. So this is where code inheritance becomes very useful. I'm no longer trying to change the activation function or something I'm actually trying to change the purpose of the network from a dresser to a classifier. And that's going to require more than just specifying some arguments I could do this, I could say like you know neural network and then pass like type classifier, but that it would end up probably duplicating more code that is necessary when in reality as we've observed. Kind of all I need to do is change what happens at the very end of the network so I'm going to need to define a softmax function, and we need to define my back propagation functions to use the output of that. So, I will import a neural network class. And then I what I will do is I'll define and implementation that I've already started in this neural networks implementation here. Neural network classifier this subclasses from neural network. This allows me to specify the input size. And then the hidden layer size in this case just a single hidden unit with fire or layer with five units, and then three for the classes. And so now I train my specify my number of epochs and my learning rate, and then I can plot my outputs and then I can plot, you know, my, my likelihood function and my training over time etc. So let me just run this. And it'll take a few seconds to run. Like last time, because I'm subclassing from neural network, and I didn't I changed the functions necessary to turn this from a aggressor into a classifier. I didn't change the print functions. So it's still printing error but you notice that number goes up when in fact, as we've done before, we're just actually printing the likelihood. So this is the likelihood of the data. I'm getting a pretty good number. And so here is my. This is my training likelihood plotted versus training epochs you can start you can see how we started blow point seven and and end up getting close to point nine five. And here is the data again. And here's what it predicts. So, you can see that he's doing a pretty good job. It's fine. It seems identified that that outside region belongs to the blue class. And it's kind of top region belongs to the red class and the bottom region belongs to the green class. And it's also doing it in a way that is effectively capturing kind of the shapes in this data, not not too bad obviously it's going to make some mistakes like here, these green samples seem to be pretty dismembers of the red class. But overall, it's probably doing a pretty good job. And then there's some white space here that is just sort of filling in someone arbitrarily, but it just it doesn't have data for that. So what we can now do is we can plot this in multiple dimensions to get a better look at it. So, this is the distribution probability distribution for the red class right CC, when I have samples that have these x y coordinates, the probability of being a member of the red class is given by this function here in three dimensions. So, similarly for the green class you can kind of see how this one, and this one sort of fit together. Right. And then there's the blue class, which has this big ring on the outside, and then it's the, it descends to zero probability in the center. So now you can see how with this two dimensional data we're basically fitting a three dimensional function to model this highly nonlinear class distribution. So, you can actually plot the outputs of the hidden units, you can actually see what it is learning. So you can actually see like for a given input what one unit is going to output you'll kind of see how those curves which would also could be visualized in three dimensions, when combined should allow you to predict this probability distribution. Okay, questions so far. Yes. There is a reason why you just show this one hit of there. In this case this this problem is like simple enough that that can solve it. So you can. Well, you can really run this. Let's be a lot let's just do it right let's just change the hidden size to try 10. Now, and let's see if it if it does better. Right, we can already see that we're doing slightly better and maximizing the log what the data. Here's my prediction, maybe it's like a little more symmetric. Okay, and there's that right so same things. We can try one thing that one thing that might be interesting note here is actually, you see there's a bit of a dip there. It's kind of hard to see. But we've basically got some place where the problem you find that the green class is not as certain as it is in some other regions but it's still higher than anything else so that you look at this part here. And this chart doesn't show the probability, but it's probably at least greater than than point three point three three, but maybe it's not that much. We can try, you know, making this a bigger network. And this might end up you know fitting even better to it so it looks like it is so far, right getting pretty close to fully maximizing the likelihood. And you know this is probably the best fit we're going to get to this data. And then we look at our shapes. Right, this is like close to as exact to fit as you're going to get. And so in this case, that single that single hidden layer is like just fast enough to train on this machine even on the CPU, you can have a slightly bigger network and it's, you know, fitting slightly better to the data. So that was just a function that is nonlinear enough to capture this effectively, but also just really fast to run. Okay, any other questions. Okay. So let's try some actual data. So let's, let's finish the toy problem move on to some real real data. So we have this human activity data given in from accelerometer so basically we there's a bunch of data where people had some accelerometer might have been like a smartphone or a smartwatch or something. And then based on how people are moving over time the goal is to classify what kind of activity they were participating in. So, am I climbing stairs and I playing tennis and I running and my jogging and my, you know, just resting, am I eating dinner. So basically, this, the name of the files just accelerometers are sort of obscures what's being, what's being done. But basically, based on how I'm moving can you tell what I was doing so I'm like classes include things like walking and playing with Legos playing into we climbing stairs. So X is the motion data and then T are some class labels corresponding to the activities. So, what, how do we define class labels for the data. So how would you do that. Yeah, each class can have a different integer value, right. Yeah, you have to encode that in some way does it. What's your intuition about like does it matter. If I put like more similar activities like numerically closer together or not. And then I was like, yes, who thinks yes. Okay, who thinks no. Okay, so generally, at least for these for classes, like this generally doesn't matter that much, because you think of them as, as vectors. The vectors are kind of orthogonal to each other say I've got 12 classes you can think of just like 12 dimensional unit vectors each is orthogonal to each other. And basically what it is is I am if I'm not doing one thing I'm doing something else. There's no real overlap. So that is I can just decide arbitrarily like walking is your playing with Legos is one eating dinner is is six. And it doesn't really matter because the probability distribution the ways should optimize for that label set. Of course if I change the label set, then those ways are going to be completely wrong. So it's very dependent on the label set that you choose when you train it to make sure that you're evaluating against the same label set in the same order, where this falls apart of course is problems where similarity matters in the final output so in particular in like language problems. It doesn't make a lot of sense to have the word puppy be equally orthogonal to the word dog as it is to the word truck. Right because obviously to these things are much more similar to each other than either of them is the other thing. So, in problems like that you have to have more sophisticated ways of representing your classes. But in this case we can just assume that you know they're arbitrarily chosen. So, here we have you know 225,000 samples, each of them has four outputs. And so then data looks like this we can see what do these look like inputs in which these look like outputs. Yes, first column looks like an output it's it we just talked about how these are in your class labels so this looks like integers so I'm going to guess these are the class labels, and then these are continuous values. It seems like I can take my first column turn that into my T and then the remainder will be my inputs. So here's a function to generate K full cross validation sets where we talked about cross validation. Anyone remember what that is. If you do it's going to help you with sign them three. So, I'm going to do this for like K times right so I'm going to have each each time going to hold out a difference, a different set, and then rotate that through so that each time I'm training on K minus one folds evaluating on the k fold. And this will tell me a decent average picture like how long model can be expected to perform on arbitrary unseen data. So here's function that does that I will randomly order X and T protection them in the folds. And then I will basically return each one for X train validate and test. So, if I do X dot shape, I end up with this number of samples times three three dimensions for each one. I'm using this yield keyword at the end of what is that so this is basically something that suspends execution and then returns the current state back to the color, but it will retain the state information so I can continue where I left off. So return keyword will just exit the function entirely at that point yield will basically say here that I've got right now, I'm going to return you some values. But if you want to keep executing, I'm going to maintain my state information this is kind of a functional like operator in Python. So it's sort of like the continuation operator in Haskell for example if you know anything about that. So just a demonstration of how that works I can have some function here that is just a times two function it's going to return I times two for in range of I. So now if I turn. If I print out list of times two is going to give me, you know, I times two for zero through nine. But if I just return the result of the times two function actually gives me this generator object. So the generator object allows me to basically call this next function over it to prompt it to return whatever it's going to yield at the next step. So remember we're keeping the state information. So it's basically was the last thing that I returned, and then I'm going to continue where I left off. So if I call if I return my generator function is basically an instance of the output of times two. And so now actually to actually get into that I have to call it next over it so if I call next Z the first time, so you can give me the first item that times two return, which is zero, then if I call next Z again, same thing, right I did not change the syntax of this call at all, but now it's returning to because Z is an instance of this function that preserve the state information because I use the keyword. So using this in my K full cross validation sets, means that I can then just call next to basically get the next cross validation said it's going to segment everything just right return my train Val and test partitions. So now the size of these things you can see, I have 75,000 samples by three and then by one. And then these are equally partitioned right now so I now have trained validation and test partitions, all of equal size partitioned into different folds. So now I'm going to call the NP. I'm going to use this unique function is going to find the unique elements of an array. So if I run unique over T train and with this return counts keyword, what this is going to tell me is, what are the different elements of T train and how many times to each does each them exist. So, now we can see that I've got 10 classes, they got labels on them one through 10, and I have roughly 7500 of each. So, this is a decently balanced sample. So there are 10 classes for each class K and then their K prime instances of that instance in our data. We can also control how many digits after the decimal pointer printed for an umpire a this will be important for doing the confusion matrix. So I can set my precision to five. And so now if I just divide the counts by the total shape of T train. So basically this is accounts for class divided by the number of samples we can get the percentage of the data that falls into each class. And so you can see that's roughly 10% so this is a well balanced sample, we can do this also for T val and T test. And we can see we have roughly the same distribution across all of them, which means that for cross validation we can expect that this result is going to be relatively accurate. So these steps are very important to do. If you are performing an evaluation on a network. So, see where we at right now. Okay. So, what I will do now is I'm going to construct a neural network classifier, where the input layers of size and ran is number parameters in every input sample. In this case that's three, a step two a miracle occurs. And it's step three we get the answer. So, what we do here is I'll just define my neural network classifier that we did before. I'll call train on it. All that stuff happens. And then I will just see how long it took and I'll plot my training likelihood versus the versus the training time. All right, any questions on this wall it's training. Yep. So, the reason why we're not using fun hot. Sorry, I guess I, I sort of elided this, because I didn't show you the neural network classifier codes you have to write that yourself. One of the things that you're that it does that you will have to do is it takes those integers and turns them into one hot vectors. So, so you'll see that if you look at the definition of the class. So, what's the input size is going to be the second that second dimension of x dot shape so in this case three pram, three values for each input. This is the hidden layer size, and then end classes, this is the, this is the number of output this is the number of things I want to predict about each sample. In a regression problem, these would be and scalar values pertaining to something about that sample for a classification problem the thing I want to predict is I for every class I'm going to predict the probability that falls into this class. So, basically, this would actually have an output size of 10. Okay, so that did that so it looks like it is pretty. It's decently maximize the training data likelihood. So for classification problems you want to see the percent of samples that are classified correctly. And then it's also interesting to see which ones are misclassified so you can see if maybe there are some classes that are being confused for other classes more often than not. So, this is this as basically a grid where you have along the rows of the columns you have your predicted classes and then on the other one you have your true classes. And so those things along the diagonal, which for a perfect model, you basically have 100% along the diagonal as we'll see. So this is called a confusion matrix. And so this is just like a table of classification percentages for all the target classes and predicted classes. So in our version, the row is going to be the target class the columns of the predicted class. This is not universally true I have seen cases where people have flipped it so just be careful when reading to use matrices. This is typical, I believe this is more common. And so then the diagonal is going to show the percentage of samples that are correctly classified for each target class, and you want it to be as close to 100 as possible. Yes. So, in this case, it's probably due to the number of samples because there are 75,000. So, the data here it's three dimensional data so yeah it's like an extra dimension and say the tide pod example we did before. So it takes a little bit longer there but mostly it's going to be the number of passes through the data at friends of the entire data set to 75,000 samples versus. I don't know, a couple of hundred probably for most things we've done before. You wouldn't expect like a big, if the samples are the same samples either. Yeah, no, I mean if you're dealing. Yeah, so the thing about the number of numbers that it has to pass through it's going to be n by D. So the longer the longer the input dimensionality is of course the longer it's going to take to go through each sample, and then the more samples you have the longer the longer the input dimensionality to go through the entire data set. Okay, so we can then just run the use function. And then we'll end up with a basically an end dimensional array showing all the percentages. So this will convert the predictions into into percentages. So I'll put it on the table. I'll put it on the table. Of course this is not very useful to look at it's just a bunch of numbers. If you can mentally conceptualize how it's being arranged you can see there. This seems to be a good percentage for that first class, and maybe a less good percentage for that second class, but let's arrange it in a way that's actually easy to read. So if I put in a pandas data frame I'll put some headers on it. So I can see all the class names and their indices and I can see the class one is rest coloring Legos we tennis we boxing movement at very speeds and climbing stairs. So now I put these into a data frame I can put this out into a nice grid. So I can see by stepping down along the diagonal, which samples are which classes are well classified in which ones are not. But of course this is still not like the best way to look at it right be really nice if I could get an immediately intuitive grasp of what this showing rather than having to analyze all the numbers one by one. So first of all let's convert things to percentages. So you can look at this tutorial and pandas styling to, to help you with your data presentation. If I convert things to percentages now all of a sudden it is quite a bit easier to read. I'm not no longer staring at so many decimals. Now the above function call doesn't save the style and the confusion matrix so if I run this again it's going to give me the decimal version. So I can add a colored backgrounds to provide a quick, a quick visual comparison using CMAP equals blues is going to give me this nice, this color scheme, right immediately look for the dark cells. Now one thing you'll notice here is that it basically the darkest cell in each column is the darkest one, and then everything is graded relative to that's what that means is that this one we tennis. We're classified correctly 3.5% or 3.8% of the time, but that is the highest value in this column certain things normalized relative to this. So this is the same color as rest being classified correctly 96% of the time. Okay. So now we can combine these two styles in an object oriented fashion. So now if I run this one. I'm going to run the percentages. So one thing that we will want to figure out is like how to how to normalize this is there's some things you can do in in in Python to do that. So now I'm going to try a bigger network. I'm not going to run this live, because it'll take a long time so just going to start from here I'm going to kind of just skip through this. So I now have two layers with 100 units and 50 units. This is the data likelihood. So you can see that as we train this bigger unit has some, some fluctuation in that in that likelihood so if I stop training here maybe wouldn't perform as better but eventually kind of stabilizes. So if I run this again pretty confusion matrix you can now see that, at least the correct class is the one that is classified correctly, most of the time for all classes. They're not all equally classified correctly for example stairs only correct 30% of the time, whereas rest is still correct 9096% of the time coloring is 85. So now let's check the validation and the test sets. The validation percent correct is about 57%. But we see kind of a similar distribution for all the different classes. And this way you can see like, which ones are commonly confused. And this makes quite a bit of sense right it may be difficult to tell from accelerometer data whether I'm moving at 1.775 meters per second or 2.25. Right. So I'm going to end on, you know, by height my stride length maybe the type of shoes that I'm wearing. So by looking at confusion matrix you can see which which classes are commonly confused and maybe consider ways you might process the data to make that easier so confusion matrix is kind of the most common way of presenting multi class evaluation for most machine learning problems. Okay, so then same for the test percent. Basically we're seeing very similar trends in terms of overall accuracy and also prediction between different classes. So we've got some issues here. So for example, obviously some of the really easy ones like rest and coloring, and even Legos it's getting right, you know, most of the time we boxing. So this is probably like a relatively distinct movement pattern that is picked up in the data. But kind of the walking jogging ones and even climbing stairs. The overall accuracy is just not that great, particularly for like class eight and class nine. So what if there's a different data representation that we could use to represent movement so we can use this thing called a continuous wavelength transform. So here is some code that's going to apply a CWT to this accelerometer data. I'm not going to go into this but basically what it's doing is just converting this into a waveform. That's going to approximate the frequency and amplitude of the motion. So imagine if I'm walking really fast right imagine that accelerometer like hitting the floor or the or the sidewalk. You know, every time I my foot touches down. It could be like a pulse every time I take a step right and so the frequency of that pulse is going to be correlated to say like how fast I'm running or my whatever my pace is. And then the amplitude is going to be like how how hard my foot is hitting the pavement, whereas if I'm sitting there playing Legos, you know, sitting on the ground, not going to I'm going to get a different pattern of movement that's going to have a different frequency and a different amplitude this is a useful technique for transforming this rocks or arm data into something that's maybe a little bit more intuitive. So if you are familiar with CWT is you can look at this code and you know apply it, maybe just some of your own data. Okay, so if we just look at some of the different, the different properties. Basically we can see you know we can define a max frequency, and then we can see for the different samples, you know what what some of the properties are might be easier to look at this in terms of a visual chart. So what you can do is I can actually plot some of this, and you only see like three distinct regions here because there's actually 10, but it keeps repeating the same colors, and they're kind of all plod on top of each other. So if you look like real close to my ability to see some other ones but not really. So if we now look at the individual samples. Luckily they're ordered we have a 7500 of each one so you can see okay this these are the samples of class one class two and so on and so on. So we can plot the frequency for these three dimensions for each of these so if you look at instances of like class. What five I guess this is one two three four five. So this is we boxing. And so these, you can just go down below this, and you can see the amplitudes for that so this particular class seems to have quite a bit of distinct frequency and amplitude compared to the other things. Right. And now it's looking the ones that got confused right these were sort of fast movement maybe running or jogging. So if you look at these segments here is not a lot of difference between them. So kind of makes sense maybe that that these are getting confused. You'll notice that like there is a slight difference maybe the amplitude in why for this class is slightly less than that for the next class and maybe this representation will allow us to tease that out a bit more. So just think about you know how you would move in terms of doing each of these, each of these activities, and that's reflected in the frequency and amplitude of the signal. Okay, so now I'm going to take this representation, and they call it my CWT net I'm not going to train again because it takes like a minute. And but then I will run a prediction, and then I'll see how well this is doing. So clearly, if I look at test percent correct 92% compared to like 58. So clearly this data representation is a good way of representing this for this task. Now look at the confusion matrix. Wow. So really nice numbers there. So the thing that is maybe not coming through very closely is coloring is often misclassified as rest. Right, because if you look at it may make sense because of converting my data to frequency and amplitude and maybe it's going off of like the accelerometer data for my pocket. It's, there's no real distinction in frequency or amplitude of motion associated with coloring versus rest that would be picked up by an accelerometer, and that CWT transformation maybe squeezing out data that was useful for that. So we had some cases where like coloring that percentage actually goes down right now it's like 50 something forward 64 right so maybe we lost some information here. So that was classification. Basically, key points. Everything is converted to a probability distribution but when using neural networks that all happens at that very end of the operation. But also the way you represent your data, you can make a big difference. And this is true for all kinds of neural networks from just how you're encoding the classes to how the inputs represented. And so you have to think pretty hard about how you want to represent your data for a neural network classification operation. Okay, questions. Okay. So before we go, let me go through assignment three. So the purpose of this assignment is to build an implementation of a neural network in pytorch so you're going to be doing a lot of the similar things that you did to assignment to, but you're going to be doing it the Python, the pytorch way. So, what, what you'll do is once you've done that you're then going to conduct some training experiments on some some data and you're going to be doing this using cross validation. So notebooks you're going to look at eight for the pytorch stuff. The cross validation notebook whose number I don't recall I think maybe it's seven though it might be nine. And that should cover most of it I think space you're going to want to review pytorch implementations and cross validation. So we have this end net class what you're going to need to do is you're going to complete the train and use functions, the pytorch way so you cannot just copy and paste your a to code although the principles remain the same. Obviously, you've done it in NumPy, but NumPy is limited by the CPU so let's move to pytorch so that you can make use the GPU for for more substantial operations. So you're given definitions of like say the activation functions you can do, you know, 10h regular that's done for you. What you need to do is you need to complete the train. So you need to calculate the do the forward pass calculate the mean squared error take the gradient. And remember in the pytorch method, most of all these things just happen in single lines. So, you'll find, if you find yourself working out the math for things, you're probably on the wrong track, you've done that already. So I need to do this using pytorch is built in functions. So what you need to be careful are things like zeroing the gradient making sure that you're detaching things from the computation graph etc. So this is function. So, same operations right you need to standardize x to the do the forward passing on standardized but again, you're gonna need to do this the pytorch way. This thing here, if you run into errors about the computation graph just like review that line. See you a lot of a lot of trouble. So for example, we'll give some data like we do before run it through implementation of and that and then calculate the RMSE. If you do it correctly your plots should look like this. So then you then need to perform experiments over actual data after performing stratified cross validation so we give you the complete code for generate cable cross validation. So you don't need to change anything with that. And then here's some example data using just some dummy data using this function. So you can compare outputs to this. And now you need to train create a function that will train the neural nets, and then average the RMSE you overall the ways of partitioning so you have to do all your, your cross validation, take the average, and then report that. So you just have to find this function and that's going to do things like define an instance of neural net, and then call generate cable cross validation sets, and then, and then get retrieved the output and report it. So basically this is the same as you did in assignment to accept your calling the cross validation function, and you need to call your pytorch neural net instead of the numpy one. So the application is going to be to this airfoil data you can go to this website and download it. And then it's gives you these parameters like frequency angle cord pressure. So you need to apply your run cable cross validation function to the airfoil data. X will be the first five columns and TV the last column pressure. So basically trying to predict pressure and using the other five things. And below you'll find an example run over some real data. So you need to, again, collect your outputs into a data frame, where you report the architecture and the RMSE for train valent test. And then you can plot the results. Okay, so this is a much more coding heavy assignment. So you'll score most of the credit. If the train use and run cable cross validation functions are defined correctly. And then you can test this with the greater same as before. So unlike this one you need to complete this one individually. So a two in the final project the only thing you can work with the partner on. So you can earn 10 extra credit points in this assignment. So there's significant, you know, advantage to to doing that. One is to add a keyword argument to allow you to use the GPU. You have free access to any of the CS machines. Then if you need to use those if you don't have GPU in your own. And then also you can find another data set and apply this to to that data set and report on your, on your conclusions. So you will get five points for doing one and five points for doing two you can elect to do one but not the other. If you have the time or lack thereof, or you can do both. And this is due March 21. Questions. Okay, all right. We'll see you Thursday.