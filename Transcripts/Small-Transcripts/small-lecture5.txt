 Okay, let's go ahead and get started. So, hope you all made a start on the assignment. So it's going to be due a week from Thursday. By default. So hopefully that's going okay. I will have office hours this afternoon. And as I mentioned, I think I'm on the faculty and we may have to cancel some office hours, depending on like what we're doing with that. But currently this this week, it looks like I'm going to have off. And if you're interested in our faculty hiring process, I encourage you to come visit the faculty candidates talks, there's usually going to be on using Monday or Thursday at 11am. We will send out an announcement to the CS list when those are scheduled. Other than that anybody got any questions, concerns about the assignment yeah. No, that's fine. Good question. Don't you don't need to do that here. I that is probably good skill to practice. I had this conversation the other day. But you don't need to do that for this assignment. We will have one assignment that is explicitly about that and from that point on you will be expected to do train test splits. But any other questions. So, we're ready to talk about neural networks. So, I understand neural networks can be somewhat scary. So, going to introduce the neural networks in the easiest way possible everybody please open your textbooks to page one. This is neural networks for babies. I'm going to read your neural networks for babies real quick. This is a ball. This is a neuron. It sends messages throughout your body. Give the neuron input and output, and it can help us learn. Give the ball input and output and it acts like a neuron. The neuron can have one input and output, or many starts to sound familiar. Is there a red animal in this picture. The neuron can tell us, based on its input. When the neuron has an answer it sends its own message. This animal have eight arms. The neuron could tell us based on its input. When the neuron has an answer it sends its own message to plus two plus two plus two equals eight. Where did the messages go. They talk to each other. They connect in a network. Input neurons look at parts of the picture. Output neurons have answers in the picture. Neurons in between don't see the pictures or give answers. They're hidden. How do the hidden neurons learn to decide? The neural networks can have correct labels on them. After training the network has learned to label new pictures. A really big network can solve even harder problems with the help of computers. Now you know neural networks. Thank you. Classes dismissed. Now you know neural networks. As you can see there's a whole lot missing from that. The treatment of convolutions and backprop is not up to the standards of a major AI conference. The part of the end is now you know neural networks is a little bit weak. For the remainder of this we will go from linear regression to neural networks. Not the baby version. We'll fill in some of the details. I'm going to read the book. People don't believe me when I say this book is real. I read my kid repeatedly. Now my daughter is at the point where she vastly prefers my wife to read things. I'm not offended. She wants to read the same books over and over again. She's a favorite book like a week ago. She was taking it to my wife to have her read it. She's very smart but not in computer science. Now I know neural networks. Let me share my screen. We'll go through neural networks for adults. If you remember from the linear regression lecture, I briefly mentioned that linear models can't solve the XOR problem. I assume everybody knows what the XOR problem is or what the XOR operation is. I'm looking for the XOR problem. If I have two inputs, I'm only looking for cases where one of those things is true. If I have X is zero, Y is zero, zero is false. Neither of those things is true. X or Y is zero. If Y is true but X is false, then X regular or Y is true. If both of them are true, X and Y would be true. X or Y is zero. Only one of the inputs can be true for the XOR to be true. We can also graph this. In the version below, we have the blue X's where the XOR is true. The red X's where the XOR is false. If I have zero and zero, it's false. If I have one and one, it's also false. In the cases where only one of them is one and the other one is zero, then it's true. You can tell by looking at this already, if I'm graphing like this, this is clearly not a problem that a linear model can solve. There's no way to fit a line to these points when the points are in a square. That should be pretty evident. What I'm going to do now is I'm going to present the solution to the XOR problem done with matrices to motivate how we use the introduction of nonlinearies to solve more complex problems. Basically working backwards, this is the solution to the XOR problem. If I have the following weights, one, one, one and one, then C equals zero and one, W equals one and negative two, and then this bias is zero. Let's write these just in NumPy form. We set those variables. Now I'll set X to be some matrix that contains the inputs. The first column can be taken to be X. The second column can be taken to be Y, so zero, zero, zero, one, one, zero, one, one. Write this as a NumPy array. We get the following. Now if I take those weights, W, and then multiply the input matrix by that first layer, I'm going to get the following. If I do X at W, I get this, zero, zero, one, one, one and two, two. Now I take this bias vector, C, add that, then I get the following there. Now this is going to be this nonlinear step. The so far I've just done a linear operation. I do the inputs, time some weights, and then add some bias. That gets me to this point. This is not the solution to the X-ray problem as we can see. We have zero, negative one, one, zero, one, zero, and two, one. It's not clear how that maps to the solution to the X-ray problem. Now what I need is some function that's going to allow me to take the input to an output that begins at zero, rises to one, and then drops to zero. I'm going to apply this nonlinear transformation where if Z is less than zero, it's zero, otherwise it's Z. Otherwise I'm going to take the max of zero and Z. I can write this function f of Z that does that, and so then f of Z will give me the following output. Now I have zero, zero, one, zero, one, zero, and two, one. All that's done is basically taken this part here, and the only thing that's changed is it's changed this negative one into a zero. The result is that now I have these things mapped into a learnable space. What's going on here? We have the input being zero and zero. The output is zero. If the input is two, the output is one, and if the input is one, the output is zero, and we have two cases here. That's why I only see one point there. The output of these linear steps, effectively, among other things, turned this point here into basically two, one. This one here used to be before the nonlinear operation used to be kind of down here. This is zero and negative one. So if you see where my cursor is, and then the blue X and then the point in the top right, you can see you fit a line to that. That was the linearization of the input. But now, applying this nonlinear step, this gets me this. Now it's in the continuous space that I can actually learn. Now I multiply that final weight vector w. We had inputs X times big w, which is one set of weights, plus a bias. Now I'm taking that, applying some function to it to turn it into this space here, then I'm applying another set of weights to it. And that gives me the output here, 0110, which if you remember corresponds to the XOR. So now all in one function, I can effectively take this neural network where I have the weights and biases pre specified. That will give me the output that is the XOR for those inputs. So if my inputs are 00, 01, 10 and 11, I apply this function XOR and N, and it gives me 1001. So I've done this all in one line, right, so it's kind of hard to tease apart exactly what the different components are. So I'll write it more legibly out to a version of XOR and N. So we take the hidden weights, right, we first of all we take this input X. We have the specified weights of w and bias vector C. So now the hidden weights is going to be, I should probably call this hidden output I guess X at w plus C. Then active stands for activation functions, we're going to a minute this is some function F that we defined earlier over that value. And then output is going to be the output of this. So the activation times another set of weights. And all that will give me the XOR. So by introducing this nonlinear function that allows me to take some inputs that are mapped to a line, and then deform that and then multiply some other weights by that will allow me to solve this function that solve this problem that a linear function was not able to do. Any questions. So this example, of course, involved no training, I basically gave you the solution what the right weights were and then showed you how once those weights are in place we can use that to solve this problem. If you want to know how we actually train to solve this particular problem. There is an, there's an article here that you can prove. And not really doing that until we get to the end of the notebook because it's going to assume that you know neural network operations like back propagation, which you presumably don't yet you haven't got there. But once you do if you're interested in how to actually train a neural network to solve a problem like XOR is very logical. This can this can show you how to do that. Okay. So basically the takeaway that I hope you have seen is that all neural networks have the same basic form, where we have some function applied over some other operation, whether operation is just a linear operation. Right so if we take the inside of this function, W X plus B, this should look exactly like what we're doing in the previous lectures. We have some some affine transformation weights W, shift it by some bias vector B, and that gives me the output. So, I have a line, and I'm just trying to take inputs and map it to some place on that line. So, what's F, F is some nonlinear function. Okay, these functions are usually called activation functions. So, last time we saw how we could do these fixed nonlinear inputs to introduce nonlinearity, when it seems like there's not a linear solution to the problem so this is somewhat labor intensive, in that we first look at all of the data and see that there are some places where there actually appears to be some correlation between some parameter in the output, but that correlation is not linear so if you remember in lecture four we had like resistance of the vessel on the y axis, and this thing called the food number on the X axis and there was some sort of quadratic looking curve, they're basically trying to figure out what actually is this curve, it looks quadratic is it actually quadratic. It turned out that the best answer is probably like X to the power of 13 or something. But that took a lot of effort trying trying different feature functions over those inputs to see like what exponents allowed me to convert that input into a linear function or to convert the input into a form where I can apply a linear function get the output. And that's not going to scale very easily. What if we had some arbitrary way of introducing nonlinearities. So, we don't know which nonlinear functions to use. But what we can do is we can pick a form of nonlinear function that has its own parameters or weights that will determine kind of the grade of the nonlinearity to introduce. Right, I mean, I know I'm going to deform the data in some nonlinear way. How much what kind of nonlinearity and how nonlinear I'm going to be going to be making that transformation. So, we want the parameters of this to control the actual shape of the function. And there are a bunch of possibilities for such functions and I'm sure you can think of any number of nonlinear functions that just satisfy the property of being nonlinear. But we need some desirable properties that I'll illustrate here and then go into why we want those properties later. So, first of all, I want to be computationally simple. One major reason for this is that we're going to be doing this a lot. We don't need to have some wild polynomial being calculated for every data point over 1000 trading epochs or more. We also want initial small weight values we want the volume of that function to be close to linear. And then as the weights, the magnitude of the weights increases the function becomes increasingly nonlinear. So now you can think of, you know, let's say we on the x axis is wanted to be closer to linear and then as the values grow to extremes you want to be more nonlinear. We also want the derivative of the function to be computationally simple for similar reasons as a function itself to be computationally simple. We also want the magnitude of the derivative to decrease as the weight magnitudes grow. And perhaps you want this to be asymptotically. This is not always true, but it's generally a desirable property. We also want the maximum value of the magnitude of derivative to be limited. So we want the derivative itself to basically have, you know, some known maximum value. So let's go about driving you know some properties from these properties what a desirable activation function my book. So first let's start with just a linear weighted some using the, the familiar formula, XTW. So for some input sample X, we want s the output of this function to be small. So the magnitudes of the weights in W are near zero, as those magnitudes increases, we want the magnitude of s to also increase. So, for example, if we have some, some data here, just weights that are just kind of arbitrarily chosen numbers, and then inputs. And then if we change these values here, let's just say as make them, you know, make a bunch of them much bigger. And then we can also see the value of s also increases right that should be pretty intuitive. They're still dealing in the world of linear functions right now. So now, if we want, we want this function s, let's try to construct a function where s is the shape of the derivative that we want so basically s is going to be the derivative of some function. And then we want to derive the function f, where s is its derivative by first constructing derivative and then seeing what the interworld antiderivative of that function is. Okay. So first of all, we know a couple of things if I were to take the negative s and use that as an exponent. This means that I can take whatever function that is, and make it asymptotically decreased to zero. So we want that, according to point number four. So, we can use base e base e has a lot of nice properties. One of which is that ease derivative is the derivative of the x is, I should say, the x, right. And the antiderivative of the x is the x, right. So the ease allows us to deal in natural logarithms has some very nice properties with regard to differentiation and integration. So what I'm going to do here is I will just plot some inputs that are evenly spaced, and then I will plot the e to the negative s. So of course, as we as we all know we can see that as the value of s increases, e to the negative s is going to decrease and approach zero. Okay, so now remember we're constructing a derivative want the maximum value of that to be the to be the limit the maximum value of that derivative. So here what I can do is I can then take, say one divided by one plus e to the negative s. And so now unlike this one where the maximum value is basically going to be infinity, right as I get more and more negative. And the minimum value has a limit by doing this, I now have basically a limit on the minimum and maximum value. Right. And so the maximum value is the important one they want to control here. And by virtue of that also, we would also want like the negative of this to also be limited right now we're in a window of an interval of zero to one. So we don't have that problem, but we'll see what happens with that in future. Okay, so this doesn't be want as s goes more and more negative. But we also as s becomes more positive we want to bring this function down to zero. So one way I can do that is just by taking one minus one over right so now this is going to start at close to one and eventually decrease to zero. So I want some combination of these. Right so I basically want something that starts like this, and then rises and then falls again so I kind of want the left half of this function at the top, combined at the right half this function at the bottom so what if I just multiply them. Okay, so that looks pretty good. So this is doing what I want. It has as some just to zero in at both extremes. And then the minimum value is limited to point 25. So, the last desire ability that we want is wants us to be computationally simple. So, we take a look at this function. And we can see that there are some common terms. So for example, what I can do here is I'll just create a bunch more points. And then I will recompute this function. So we have, you know, basically, e to the negative s, in terms of one plus one over. So, all numbers we know how to deal with, right, one and effectively with an exponent. Okay, great. So now what I can do is I can, I've got this and I got this function now let me see if it has property if it's anti derivative has properties that are also desirable. So the next thing, well, library you can use this is thing called simpi symbolic Python. This is the only time we're going to use it in class but it is kind of fun to play with. Basically what this allows you to do is define operations, and then actually perform differentiation or integration on them and it'll give you the resulting formula so effectively, you can use this symbolic Python to sort of solve those, you know, problems that you've probably done before. So first need to in it printing, allow me to use Unicode. So I'll define a symbol s and so just s symbol will just be the symbol symbol s. So now I can run this dot diff function. So what this does. This is just going to differentiate f with respect to the symbols. So in this case, I some function f of s, but I want to differentiate with respect to s. So, what I do here now is I've got to find my function. So s to the fourth, and I want to differentiate with respect to which symbol s. So, and now we can see if you remember your, your, your calculus. We should expect the derivative of s to the fourth to be four s to the third. And so this will actually put that out for us. So, you can see the simple integrate function should be pretty, pretty evident what that does this is going to integrate the function with respect to the symbol. So what I'll do now is I will define the function that I defined above right one divided by one plus e to the negative s. So I'm just writing this in terms in the symbol formula, in terms of the symbol I just defined s. So I'm going to integrate the function y times one minus y with respect to s. So, this is going to give me this one over one plus e to the negative s. So, if f of s equals this, then the derivative of f of s is f of s times one minus f of s. So, we are now just arrived at the common sigmoid function, using neural networks. So, remembering that s above was defined as just a linear function, XTW, then we have some function x, some function of x parameterized by W equals one over one plus e to the negative XTW. Right. And so remember what this is this is just going to be the output of that linear operation, where we have our weights, and then make some sort of prediction by multiplying the input by those. So, I'm going to talk about this so far. Okay. So let me define some helper functions. So I'll just define f of s. And then I will define its derivative. So, Df, and then I'll plot the function and then versus the value of s and the derivative function versus the value of s. And so we get this. So, this function s in blue, we can see that it's it rises asymptotically to one, whereas its derivative is that function we saw before I got a caps out at 2.5 and has asymptotes at zero at both extremes. So, this is called the sigmoid function because it looks a bit like an s. Right. And it is bounded between zero and one. And so now we can use this function because it has these nice properties that we have identified in neural network operations. So, first thing we're going to do before we get to like the neural network of hidden layers is to just apply SGD to fit the sigmoid function to some data. So, we're still working more or less in the world of linear regression is just we have this final step of applying the sigmoid function, so that we have some sort of nonlinear output. Okay. All right, so we're going to do is going to find weight values that minimize the sum of squared errors in the output this function. So, what I will do here is I'll just define again some points. I'll take this function here and add some noise. So basically this is awesome. I'll take a T times other T equals X times point point one, plus some randomly sample noise from the uniform distribution. And it's going to give me some data looks like this right this looks like I could reasonably fit a line to this data might not be the best fit in the world. But it might be nice if that line had a bit of a wiggle in it. Right, maybe that would fit to the data a little bit better than just a straight line. So, if you think about what this data represents the values and X are at this point those are just inputs, right, they're actually represent any real data points. So, the values and T though, are targeted values. And these are derived in this case, by some known function applied to X, where we've applied some random noise to it so those targets are not going to be neatly identifiable determinants to be identifiable from X, but you should be able to still fit a curve to it. So, here's a training function. So, here I will put in my, my inputs my targets my learning rate and some epochs, and train for, you know, certain number of steps. So what I'll do here is I'll just train this for 100 epochs, and then plot the results. So here we go after training ends up with these weights. In this case, negative 1.7 point four. And then if we apply F here, which is our sigmoid function. This is going to give me this output for the sample, according to the input and then apply times the weights and then apply some nonlinear function. So, we get this and we can see that it's probably a decent fit. Right, this is a, you can see that it's nonlinear. And it does fit to this data decently well, right, I'm not sure that it's necessarily a better fit than the linear operation. It's hard to say. But you can see that also the non linearity being applied is quite slight, right, it's this is not hugely different from a line. So let me create some other data. So, different distribution, different function. So one plus negative x times point one. So now we get this again, probably mostly linear, but again could be fit to with a nonlinear function. Let me try this. Okay, and that fits pretty well as well. So, seems like I got a decent way of taking my sigmoid function, computing an output according to linear operation applying the sigmoid function to that, and I can use that to fit to what might be some somewhat nonlinear data. So, the question now is what if I have this data. How can I fit this function to that data. Okay, this is nonlinear. I would want my sigmoid function to be able to capture the non linearity that is obviously present in this data. What I've got is the ability to train weights. And once those weights are trained, take those inputs times the weights apply my sigmoid function, and then fit to some fitness and nonlinear data. And if I try it with with this data with this kind of in this curve here, what I end up with is here are the weights that it's trained. And the result is that it gives me this. That didn't seem to work very well and we tried again, try me compute some more data. Right. It fits decently well on like one part of the curve, but not the rest. Right, so we can see here in the, when x is positive, it seems to be kind of fitting to that okay, but when x is negative it's just more or less a line. So, there seems to be some sort of inflection point here around x equals zero. And we want to find out what kinds of weights will make the sigmoid function go down from negative infinity to zero, and then rise again. Right, this is what this is what will be needed to actually fit to this data here, whereas here we're only kind of getting one side of the equation. So, we don't know what those weights are. And they're not really easy to find, because the only weights that I've got here are two weights that effectively the first weight here that's a bias as before so how much am I shifting up and down the y axis. And then the second weight here is, what do I apply to the linear operation, or what way do I apply in the linear operation before I apply the nonlinearity. I'm not really doing anything that affects the slope of this nonlinearity in any real way. All I'm doing is like, I've defined the sigmoid function, and I apply that over the output of the weights times the input. So, we could try maybe using two of these functions adding them together. So what if they're like one set of weights that caused f of s to decrease until around zero, and then remain roughly flat here, and then another set of weights will call those V, such that if I take x times v and apply f over that. It would be roughly flat and then start to increase. Right, so we expect there now to be two sets of weights will hold w and V. So now we're now we're talking about the world of multi layered neural networks. One layer is going to have, in this case, two units that output f of x times w, each with their own w, and the second layer is going to have a single linear unit with its own w. Okay. So does everybody get the motivation for having these two different sets of weights. All right, so now let's talk about linear models, as we're familiar with, as neural networks. So, what I'll do here, and I cannot guarantee you we're going to get through the entirety of this notebook today, it is fairly long, and there's quite a bit of math. So what I'll do, like usual is I'll present the mathematics first go through, eventually how we are deriving the different operations are going to be using in the construction of the neural network. And then at the end, I'll have the Python version that translates the mathematics into code and demonstrates you know how you would actually write these operations. Okay. So remember how, how we do just linear modeling, we have inputs x targets t. And then we have for every sample k want to find the weights k that minimizes the squared error and the kth output so we'll say T for for x sub k, I want to find the weight vector w sub k that minimizes the out between T sub k and the actual or the prediction why sub k and the actual output T sub k. Okay. Then we'll use that to make predictions. So, what we'll do to make this, make this go faster is we'll take all these weight vectors w sub k, what will collect them as columns and a big weight matrix w. Some the exit the total above it I'll use to denote x with the constant one column. So remember, we always add this bias column so we have values against which we can train the bias weights. The target value for the kth outputs for the end sample is going to be T sub nk. So, remember how we set this up in a linear model if I have n samples number of things that I have got each with d dimensions number of things I have measured about that sample. And then I have k things that I want to predict about that. So this could be just a single value could be multiple values. So, if I have the first sample, and I'm trying to end this in trying to predict like the second thing about that in the output. This would be assuming that we skip the first one actually being the second index zero. This would be, you know, T sub one comma two or something like that. Okay. So we're using this to calculate the error. So we have E of w. And so what I'm going to do is going to take for all samples for all outputs. So some of all n over the sum of all k, I'm going to take that that output for that sample minus the prediction, and then I'm going to square it and then I'm going to sum this for all combinations. Okay, so now I'm looking for effectively the value of w that will allow me to minimize this function. Now w can also be calculated as remember if we rewrite these as matrix operations as x sub t me increase the font size a little bit. So we can see x to transpose this. And then, or to the inverse of this right, and then x total transpose times T. So, we can compare this to solving for the value of w in notebook three. So for the contents of all these matrices. Remember w is going to be w for every associate with every output, and every input, right so for their k things I'm trying to predict, and then d dimensions to every input. So I'm going to take the weight value that's correlated with each of them. In linear model what I can do is I can actually look at my weights and decide what was most important for predicting the output in a neural network that becomes less easy, right, because of these hidden layers. So, if w looks like this, then my prediction y is going to be biased x times w. What are the shapes of these things. So, I have n samples d dimensions, add one for the bias so x total is n by d plus one. So, I have d d plus one by K, in order to multiply with this course. And so if I multiply these two things together then why must be an n by k matrix. And so, this should make sense, because the things that that are represented and why those are going to be the k predictions for each of the end samples. So if I have 100 samples, and I'm predicting two things about I should have 200 individual numbers represented as 100 rows and two columns. So, for every element of that output matrix why it's is going to be equal to the end sample with the bias times the kth weight vector, and this can be drawn kind of like this. So, what's going on here. I have my different inputs x zero through x d. And I'm going to multiply each of those by the associated weight, right, and then some those that's going to give me the associated output. So, if I want to add nonlinear combinations of inputs, what I'm trying to do is I'm trying to transform x into some function will call it phi of x. So, for example, if phi of x is phi or this big weight matrix. And you know if I'm trying to add nonlinear combinations what I might do is I might raise this to a power or something. So this is the same thing as introducing nonlinear features in the inputs. So what you can think of that is that instead of raising it to a power and stacking a bunch of those things together. I'm going to have some arbitrary function that is applied to this. And I'm just then I'm just going to replace the output x by phi. And so I'll use phi to represent phi of x. And so therefore, phi of phi sub n is going to be this function phi whatever it is. So, I'm searching for x sub n. So, I'm searching for a function. But we have learned now that functions can also just be represented as a linear operation with a set of weights. Right. So if I have f of x parameterized by w my goal is try to try to solve for w. So I'm just trying to find out if I'm doing some algorithm like SGD that allows me to minimize the error between my predictions and my outputs. So what I'm doing here this is the part that's going to fit into the interior of the neural network and what I'm going to do is I'm going to try and predict the weights that give me the output, and then minimize the prediction error, when there are multiple transformations being being performed at every step. So, when we talk about, I should have pasted this again down there. The neural networks have the same basic shape, which I did like way up here, I think. Okay, so they all know that we have the same basic form. What we can now do is we can expect this function to kind of be stacked on top of each other so I'll take this output. I'll perform another operation over it, and maybe another operation over that, and every layer in this neural network represents one more function being applied. So all of these things can now just be nested. Different functions, yeah, so remember a function you're just talking about f of some x parameterized by w, which means that the w could be different each time. So, when we talk about the when we talk about neural networks, right, so even new is going to come in useful at some point. Right, so you see this diagram that you've seen neural networks written like this right so every layer here there's every column of red dots is a function. And so each one of these is parameterized by a different set of weights, meaning that each one of these is a different function. And our goal is now we're just trying to solve for those weight that parameterize each of these individual functions at the same time. It's a function of a function of a function of however many layers you have. So are we implementing these functions to the basic function that you never have in your opinion on that. Effectively, yes, yes, so I'll come to the, I'll come to the mathematics in a moment, but you can kind of think of it like this. So, if I have just a linear method linear model it's got one input and or a known input and just like a known set of outputs it's a linear transformation between them. So I can compute the error and then use SGT to optimize the weights that are going to minimize the error. Right. Let me insert a hidden layer in the middle of that. If you just look at those first two layers. And let's just disregard the activation function for a moment. So it would be just like a linear operation in that if I knew what the output of that second layer was. I could use that to to minimize the error between the predictions of the office but the problem is the targets that I have I have a two layer neural network actually correspond to the input that will come out of that second layer, which haven't even touched yet. So, the input is going to be transformed by some function into the hidden layer. But what that number is, is not directly is not clearly correlated with the actual output is because there's another, there's another function that must be executed over this intermediate number to get the output. And I don't know what that function is just yet. Okay. So the output we get is not the actual right the output you get is it can just be considered like some sort of scalar that is not interpretable. So that's why I talked about these as hidden layers. So like if I get the output I know what what the units of the output would be what's it what it's supposed to represent is it a class is it a you know, miles per hour or something like that. But that hidden layer in there is going to give me some scalar outputs like it doesn't really have units or anything like that, because it's kind of combined multiple channels that input data on its way to getting an output but I haven't got the output yet. So I can't assign any meaning to it. Sure, so it can be. So the idea is and we are getting a little ahead of ourselves. This is interesting. When you have, when you've correctly optimized a neural network for a task, you can actually get very useful representations out of the interior. For example, I think I mentioned in the first class a lot of my research involves these things called embeddings, which are basically continuous representations of classification labels. And so you can actually take these embeddings that are hidden layer representations and use them. They're just numerical values or numerical vectors by themselves are not interpretable but you can use them for other tasks and actually they preserve a lot of information. So these are the way representations preserve the information that is necessary when the network is well trained, but a human would have a hell of a time trying to figure out what the actual meaning is you can do things like cosine similarity if you're like, where the clusters in this thing. What things is it similar to, but you know it's not something you can say like, okay this number represents a bird this number represents a feather this number represents a microphone. Okay, so we have some function. Sorry, any, any other questions. So, we can easily spend two days on this notebook so that would be fine. I think that's how much time actually built into this. Okay. So, because we've got some function phi that is going to be a an operation over over x. So now what I want to do is, if this is if phi times w is going to give me my output. Now I want to find I want to do the derivation is going to minimize this error. So, whatever, when I multiply five times these weights, and then the square the sum for all my samples that's what I want to minimize. So, I want to find so you can see now that I end up with w is going to be equal to five times five raise negative one times five times T, right. So now I can use it in the same in the same formula that I had before, where I have y equals five times w. So, now I'm, now I'm focusing on like if w is this output layer. This thing is actually going to produce the prediction. I want things that are going to be useful going into w. I want the things that go into w to be useful to predict that output. But the trick is, there's kind of the separation between the inputs and the output so the x is the input, it goes into some weights will call them V that produces phi. I want phi to be useful when multiplied by w for predicting the output. So, I want to find these two functions that I'm trying to optimize at the same time, but I can't there's no generic way of arbitrarily separating those that allows me to do this over a large number of samples at scale. So, if I know that this is a non linear function I want to introduce some arbitrary way of having non linearities and non linear operations performed over my data. So, I have activation functions. So, get to that details in that new moment. So if we take a look at this, right this is what I just discussed I have the inputs, something happens to them. Right, we'll call that thing phi, and then whatever happens to them, I can multiply by weights w to get my outputs. And so this yellow box is the black box of an neural network, because I don't know what I don't know the nature of this transformation. So this is, you know, pass through some non linear function multiply by w to get the output why. And now I'm just trying to figure out what the hell goes in this yellow box. So, because this is serving its purpose right can use training data to find out training data can have correct labels on it. Right so if I know what the correct output is, maybe I can use the training data to actually optimize the weights of the text book. And so, as I speak, talks about vision will talk about convolutional networks and like lecture 13 or something right now it is doing regression. So it's also numbers, but the same principle applies. I can use the training data to figure out what needs to go in and find. So we've now just entered the world of neural networks, where 5x is going to be the output of some layer of adaptive units. And so, we'll call it H, which is typically what we use for the activation function so I've used a bunch of different terminology here right f of f of s, 5x, h of x, all referring to the same thing. Right. So because the neural network is a universal function approximator it's not really useful to talk about like the function and abstract. We know what function I'm talking about so we'll use H to represent the activation function in specific the activation function is this nonlinear function is applied over the output of a hidden layer. Right. So, this sort of looks like this so now, before we had kind of something that look like this side of the equation with the X is going straight into these blue nodes here and producing outputs. The only thing that's different here is that instead of X going directly into the blue nodes going into these yellow nodes, where they have weights V, these X is multiplied by the V is and then before the output is produced instead of a sum, you have this activation function H. So, let's say X goes into the first hidden layer, it's multiplied by weights V which at start is just going to be kind of arbitrarily initialized. So, you have a different number, you apply the function H over that number. It gives you a different number. We'll call that Z. And then you have a bunch of different Z's and Z's go into the next layer, which have weights w in them, then also maybe randomly initialize different numbers. These Z's are multiplied by these W's. And then each Z, you take the linear sum of Z times all the W's that gives you your output. So, now I'm still in the world of trying to optimize weights, I just now have two separate weights, two sets of weights V and W to try and optimize. So, the dimensionality of each step will be as follows. So, and will be the number of samples is the number of things you measure about and so X tilde will be X time X by D plus one. So, V is going to be D plus one multiplied by this times some other dimensionality M, right and I'll just specify how many M's I want to get out of that first layer. So now, Z tilde. So right if I have X times V is equal to Z. This means that it should be a dimensionality and by. So, I have the D plus ones that should, those should cancel out. But this also has to go into another matrix operation so I need to append a bias vector onto it. Right so now this will be Z total is going to be Z with the bias, which is going to be a dimensionality and by M plus one. So, naturally, it would have to be how many things are going to come in M plus one, how many outputs do I want K, so this should be an M plus one by K. And so Z tilde times W, the M plus one should cancel out and so we end up with an output that is of size and by K. So, the final operation looks something like this. So if I have, if Z tilde is H applied over X tilde V. So, this is H, this is X tilde with the bias times V, then that gives me Z. Then I append my bias again to Z is going to be Z tilde. And so then Z tilde times W is equal to why, which means that I can write this all as a single function. So, here we have why is equal to H of X tilde V I apply the bias again to that multiple that by W. So, the layers in this case are called the hidden layer and the output layer in larger neural networks. The last layer of course is always the output layer, and then anything besides the input layer going to be hidden layers. So we talked about like the last hidden layer or the first in layer and we can talk about the things that are represented at different points in the neural network. So, we have the activation functions for units in the hidden layer, if you have multiple hidden layers you may have different activation functions, and we'll talk about some of the different activation functions. And so we'll be doing gradient descent in the squared error. So, we want an H that has some of those nice properties the outline before, right we want its derivative to not grow out of control as V grows. And what that derivative to be easy calculate. So, let's try a couple of functions what about a polynomial. We can plot a polynomial and it's derivative to see if it satisfies the properties that we want. We have H given by this, and then it's derivative given by this. We can plot the derivative of the dashed line and H with the solid line. So, does this look like take a look at this do you think this is a well behaved derivative. It's kind of the opposite of well behaved right. Well, what we want is we want things that as the magnitudes grow, the value doesn't grow out of control. This is doing exactly that. It's a polynomial function. So we'd expect that. So, we don't want this because remember, the gradient descent procedures are going to take steps that are in other sites proportional to the derivative. And this derivative gets huge. And so it's a high positive as a increases, and it's a high negative as a decreases. And so the gradient decided it could be very unstable. So, what we want, we don't want to be skipping back and forth across that global minimum again and so if the gradient grows out of control we risk that we also have, you know, things like the exploding gradient problem. This can be solved the floating gradient problem can be solved through relatively simple techniques a bigger issues this thing called the vanishing gradient problem that we'll get to. But for the moment, we, we don't want these derivatives to have properties like this so two common choices for functions with well behaved derivatives are the sigmoid function as we saw before right one over one plus either negative a, and then this thing called the tan H function. Right. So the tan H function is given by this differences are the well do you know, anybody know the difference just off the top of your head between the sigmoid and the tan H function. What are the bounds on the sigmoid function. It's bounded at zero and one right. What are the bounds of the tan H function. One and one. Yeah, so the sigmoids an asymmetric function that it's bounded at zero and one and the 10 the 10 h is a symmetric function for its bounds. So let's work out their derivatives. So we'll work out the derivatives and then I'll give I'll give them to you and plot them. So these are the two functions so each one is sigmoid each to his teenage and then we have the derivatives of both of them. So now let's take a look at these. Okay. So the blue lines that was the sigmoid function that we plotted earlier. We see the value top out at 2.5. We also see those nice balance at zero and one. Then there's a tan H function in red. So similar. It looks very similar function and it is. It has the same overall shape except it's bounded negative one instead of zero. So we have a deeper derivative here around x equals zero. And so we actually have a maximum value of this at one, but both of these functions will still satisfy those nice properties of derivatives that we want earlier. So it's got a maximum bound. It doesn't go out of control as the magnitude increases. So both of these are friendly functions. Okay, so these derivatives are computationally simple. So are there anti derivatives. So the magnitude as the weight magnitude grows in this case both of them do so asymptotically and they have limited maximum values. You satisfy a lot of nice nice properties. So anyone know kind of what what the sigmoid function can be used for. Say I have some arbitrary scalar number the sigmoid function will switch this into a range between. The sigmoid function again, zero and one right so if I take a 10, the number 10, take the sigmoid of 10 is going to give me a value that's like pretty close to one. So sigmoids are nice for like turning things into binary probabilities, for example, and so you can use sigmoids for say binary classification tasks. The 10 h function is useful, particularly in hidden layers, because what it does is it will actually preserve some negative values. These may be useful, because there may be things that are inversely correlated with some input to that layer, be it a hidden layer or output layer, and you may actually want to preserve that so generally you will see 10 h functions being used in the interior of neural networks. It's not the only activation function of course there are plenty more that we'll go into later. Sigmoid functions are useful for things like binary classification tasks and more often will be seen in output layers. Alright, questions. Alright, so now this is like the gnarliest part of this I think training by gradient descent. So remember the intuition behind gradient descent. I assume that there is a high dimensional derivative. I'm trying to find, I'm trying to descend that I'm trying to find where is closest to zero. So, the gradient is going to be defined by the error, and try to minimize the error. So I want to, I want to get to a point where I am so close to the true solution that when I move along the gradient. So just the error update is being so small that I can have, they can be said to have arrived at something arbitrarily close to the solution. So remember that the we use the mean squared error in this case so between each target value t sub nk and the output predicted value, why some NK, I'm just going to take the difference. And so I'm going to take that and because every target and every output is going to be defined for a given sample and a given measurable output that I'm interested in. I'm going to sum this overall and all K, and then average it for the sizes of N and K. Okay, so now he is no longer a linear function in the weights. So this means that we can't set the derivative equal to zero and solve for the parameters like we did before. So what we can still do is we can do gradient descent in E by making these small changes to those individual weights in V and W in the negative gradient direction. So it's not I can't use like the, I can't use linear algebra to like solve for the inverse function anymore, because he is no longer a linear function. So I'm going to go to the high gradient descent trying to find some global minimum worth as close to it in this high dimensional derivative as I can still holds. So I'm sort of doing this a little bit blindly in that I don't know where I'm going, right, but I know where I've been. And so I'm just going to look where I've been and walk backwards, go down the slope. The update is more or less the same is that if I have, I want to update this value for V sub JM I'm going to take whatever previous value it was minus some learning rate row times the derivative. And this is the same for the or W. So often for the for this I'm going to have these two learning rates, row H and row OB this be different. Often they're presented as the same. There are cases where you can actually have different learning rates and different layers and this can help convergence. Most of the major packages don't allow you to do that by default you have to do some kind of pie torture TensorFlow hacking to get that to work. In most cases, a constant learning rate or at least a single learning rate across all layers is what the package will give you by default. But there are there are cases where it may be desirable to have different learning rates. So, we want to use this to find the global optimum that is the values of V and W that minimize the mean squared error. So for this take kind of a more simplified view right and not sure that this looks very simple to you with all the errors but this is the simplified view. We have this full picture we want to focus on modifying a single way let's say you know V 11 this one here. This is going to be based on a single error between the target T one and the output, why one. So for the moment, to make things a little bit cleaner let's drop the subscripts let's just focus on the single hidden unit and the output unit that are relevant to this computation. So this input x whatever it is goes into V. And then this gets multiplied by all those elements in the matrix V. Those get some to be then have some value that get then gets turned into an act putting the activation function, which then deformed that by some non linearity this gives a Z, Z is then multiplied by W and I take the sum this gives me the target the output, and I just want to measure the difference between the prediction why and the target T. So the forward calculation. But this is simplified so I'm going to ignore the bias and all of the terms right now we're just looking at single terms be multiplied so no need to worry about the major multiplication. So, if y equals W times h of V times x, in other words, why equals W times Z, Z equals H of a and a equals V times X. Since E is equal to T minus y squared. DEDV should be D of T minus y squared DB. So, chain rule to the rescue here so basically I'm trying to represent T minus y in terms of things that I've already calculated here. So the the error is going to be D of T minus y squared with respect to the y times d y d z, e times d z da times d ADV, because each of these terms like why is represented in terms of Z, Z is represented in terms of a and a is represented in terms of the. So, again, if this looks intimidating, no fear. This is presented for your interest if you are interested in how the mathematics works. When it comes to the code, all this will be done as matrices basically going to be doing this over the individual elements show how it's done as matrices and then show the code which most likely won't happen until Thursday. But we'll get there. So, now if I take the derivatives of all of these, I end up with something like this. So two times T minus y times negative w times DHA da times X. So, what this term here of course is this will depend on what H is, which function I'm using. So for the moment we can assume that if that H is 10 H, the derivative of 10 H happens to be one minus 10 h squared. So, this page here is exactly change will explain why, if you care to go into that. So now we have a formula that I actually plug in for this. So remember that z equals H of a so I can rewrite this as Z. So, one minus z squared can be written as one minus the square 10 H of the input, because the 10 H is is H. So now the entire thing D, D, V can be reduced to negative two T minus y times w times one minus the square times X. So, let's break each of these terms down. This is the derivative of the error this first thing here. So T minus y that is the error between individual sample. W, that's the weight that's being updated. One minus z squared as derivative of the activation function and access the input. So, with the exception of the activation function here. This is the same as we were doing linear regression. The three components I need are the error, the weight and the input. The only thing here that I'm adding that is new is this activation function because there is this nonlinear function that I have that I've performed over the input. So, that's the way that. We go back to this. So we broke down the EDV in terms of all of these things above, right. So these are the individual elements to the of the weight multiplication. We can use the chain rule to break it down into each of those, basically the multiple of these derivatives. We can easily take the derivatives of all terms except for DZ, right, because we don't really know, we know that Z equals H of a, but we don't know what H is we can actually turn this into a formula, but we, there are limited number of things we can use for H right it's got to be an activation function that has one and has a set of nice properties. The only one we've talked about so far and any real depth is 10 H. So we will assume that H is the 10 H function. The derivative of the 10 H function is one minus the 10 H squared. It's just, it is, it's a fact. And because if this is if H of a equals Z, then Z is effectively 10 H of, let's say X the input. So, this one minus Z squared can be also be thought of as one minus 10 H squared of X. Okay. Okay, everybody cool with the rest of. So, so far so good if this is more or less just a linear operation with an added nonlinear function, and it's derivative. That seems intuitive. Okay, let's add another output. Okay, now we look like this. So, same thing. So, as you guys are happening I've got a single value being multiplied by some weights V apply my function H gives me see, okay now Z is actually going to places. Right so there's a weight w one, and there's another weight w two. So, just like in linear functions, I want to predict two things about the output. I have two columns in my final weight matrix. So, that's pretty straightforward. So this is going to be that first value. This is going to be the second value and they're going to give me different output values depending on what those weights are. These have some meaning that I can use to compare to the prediction. And so now this will now get a different error for each one. Okay. So now things get a little bit hairier. So, chain rule again. So what's new here now is that instead of just having T minus y squared. I've got two things. I've got a sum. So I need to take over the sum of derivatives equal to the derivative of a sum. And so what I'm going to do is I'm now going to sum these errors, the square errors. And now this has to be taken with respect to be. So this works out like before. The only thing that's different here is now the numerator this equation. But now we can distribute the. Sorry, I'm trying. I need out. I now need to compute this with respect to the different wise, right? D, D y one and D y two. Okay. So, if I compute this with respect to D y one, I can then put this other term out here. D y one, respect to DZ. This is the equivalent to what's going on here in the single output version. But now I have two wise, because I have two outputs. And so now I need to compute with respect to both of them. Okay, so now I can have D y one, respect to DZ and D y two with respect to DZ inside the inside the parentheses. I can compute these derivatives. Similarly, so this works out okay. So, D A DV is just X. D Z DA can be again be written as DHA DA. And so now I'll put in the derivative of the 10 h function here. Okay, so now we can think of the error is calculated in those output units as being sent backwards through to the units in the previous layer. So if we call these Delta values, then the derivative expressions will be referred to as Delta rules. And those Delta values are back propagated so send backwards into the previous layer so this is that back propagation you might have heard of in, you know, when you discuss neural networks, and is notably not addressed in neural networks for babies. So that's basically the small error value that is being used to update the weights. So just like in the near regression with SGD, we use that error value to update the weights. The thing here is that in those weights, w, the value that is being used to optimize w is dependent on the value of V. So V is very, very wrong. w might also be very, very wrong. And so the output could be very, very wrong. So if I get an output if my, you know, if my target is here, pretend more arbitrary space, and I, my output is here, and they're way, way different. I don't really know, is this because the output weights were wrong or is because the hidden weights were wrong. I have to allow for both of them. And so I have to assume that there might be something that's wrong about V that's making the prediction when a z is multiplied by w also wrong. So this error block back propagation should be used not just to optimize the weights the output layer, but also to optimize the weights in the hidden layers, so that when an input flows through the hidden layer into the output layer it's going to get me a better, a better result. Okay, so intuition behind back propagation. Everyone clear on that you can sort of think of like, you're playing like one of those Pachinko machines, you put like a coin into the top and it bounces down to the bottom each and you can think of like those. The bottom slots those are your targets right you know where things want you want things to go and let's say you want a coin of a certain size to end up in a certain position. The weights then would be something like the sizes of the pegs in the Pachinko machine. Right so you want to you want to increase decrease the size so that your input of a certain value is going to go the right way through the Pachinko machine. The non linearities could be something like you replace the peg with a spinner or something like that. So it's effectively just sort of this big machine where you want that you know the input, you know where you want it to go, you want to just, you know, mess around at the interior of this machine until all your inputs get where you want them to go as closely as possible. It's just instead of the wooden rods it's numbers. All right, let me see how much what we got left okay. Okay, that's going to be like bad. Okay. Maybe I'll get as far as the full version of that problem. Okay, so remember these derivatives. If you don't remember these derivatives you can forget these derivatives and just come back to them before class on Thursday. So, we're basically differentiating with respect to two things. W one, which is going to be an element of this output layer and V, which is going to be an element of the hidden layer currently the only element of the hidden layer in the simplified example. And DEDV is the function that we see up here. Right it's got these components. It's the summed derivative of the squared error times the derivative of the activation function times the input, and then DEDW is much simpler. There's only one output. So there's one error, and then the input to this layer is Z. Right so. That's much more straightforward so the hidden layer, the weight, the respect to V that's much more complicated, because you have multiple outputs flowing backwards into this single unit and the other errors for both of them. Yes. Is it not required to derivative for with the W2? Well, it's the same thing here. So the formula is the same. It's just the only thing is that the value in this, the specific numerical value in this would be different. So this can just be cloned for W2. Alright so now, if you go back and look at those update rules that we had earlier up here. Now let's just plug those back in down here and see what falls out. So the update rules for the delta. Right so new value of W is W minus DEDW. Same for W2. And then so that's going to be W plus the learning rate times the error times the input. So this, this delta is going to be rewritten like this. So now V is going to be previous value of the minus DEDV. What is the EDV we gave it up here. So now this is going to be a learning rate times the different errors times the individual weights times the derivative the activation function times the input. One question you may be asking where did this negative two go. At this point this is just a constant. Right so the if I multiply this by some constant learning rate, we can just assume that this is going to be factored into that. So that if you're, if you're worried about this, don't. Okay, so now D delta H is going to be delta O delta one O times W1 plus delta two O times W2 times one minus. Z squared. So this here. How do we do this as well the reason we have this here is because of the update rule for W. We're just taking this error to be one of these delta values. And so now if there are two outputs, there are two delta values. However, this function here for the V update accounts for an arbitrary number of delta values. All I need to know is which one is which and to slot it in the right place and you add all of them. Okay, so we have two minutes left. So I'm going to stop here. If there are any questions. Let me know. I will have office hours starting when I get back to my office. All right, thank you. We'll see you best you on Thursday.