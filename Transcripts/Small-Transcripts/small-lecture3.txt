 All right, let's go ahead and start it's 2pm. Okay, welcome back. Can you all hear me in Zoom? All right. People still connected to audio. Zoom folks is the audio. Okay, give one thumbs up. Then I will assume it's good for the rest of you. All right. So I think only announcement, Sarah, you're doing a tutorial tomorrow. Okay. And can you just recap the tutorial on what and where? I was thinking that there is a part of 5pm in the studio. I have posted the number in the announcement section of the channel and also it will be recording. So I will be covering a few of our books, how to help them and how to use them. And also how to use the same machines on the studios and all that like installation and distribution. Okay, great. So if you are not familiar with how to do any of those things, I really encourage you to attend. The first assignment is going to come out. What are we doing that? So first assignment is due to be rolled out on Thursday. So make sure that you are familiar with everything that you're operationally going to need to know just to get the Jupyter notebook up and running. We won't be using GPU for an assignment, I think until A3. Nonetheless, you're going to need to know it or you need to be able to use it if you want to run any notebooks from 8, 9, 10, etc. So just make sure that you're at least comfortable with all those procedures. I think that was the only announcement today. So if there are no questions, I will go ahead and resume. We were picked up last week. So let me share screen. All right. So where we left off. Hide. What do you mean, controls? All right. So we kind of motivated the problem of linear regression. This is probably something that you're all familiar with. Basically, at this point, we're still trying to fit a curve to a set of points. And so if we have a set of observables, so we can take those to be the ground truth. And we have a set of inputs that correspond to those observables in the use case we outline those basically. I have these springs and I'm trying to effectively figure out what the spring length is that's going to allow this rod here to basically rest at equilibrium. And so we want to minimize the potential energy in a set of springs. And one way we can do that is basically if you have the spring length stored as weights, we're trying to solve for that, where the observables are the energy stored in any particular spring. And this can be applied to any linear problem. Effectively, what I'm trying to do is I'm trying to find the rate of change and then minimize the rate of change in those inputs. And so I'm trying to find the coefficients that correspond to those inputs that's going to minimize the derivative or the gradient. Just a recap of terminology. What is a gradient? A slope, but in multiple dimensions, right? It's basically the high dimensional derivative. And so this is what we're trying to find. If I have a bunch of inputs, I'm basically trying to minimize the gradient with respect to every dimension represented by those inputs. So we talked about just using the least squares and stall functions in NumPy that will do that with relatively small inputs. But often we'll have a bunch of samples. This can be very time intensive to solve. And so we don't want to have to do these huge matrix operations. You want to minimize, matrices are very useful, of course, and can minimize the time complexity of these types of operations. But still, trying to do these operations over these huge matrices is still going to explode. So what we can do is we can use this incremental form where basically we're trying to find some sequential algorithm that use the fact that the derivative of the sum is the sum of derivatives. So now we can express this derivative as that gradient. That's just going to be a matrix of derivatives. So just like everything else, where your inputs can be a matrix and your outputs are usually going to be a column matrix, as you see, you can have multiple columns. The derivatives, of course, can also be represented as matrix. So this upside and triangle, pronounced del, represents the gradient. So we have some function g of x parameterized by w. This is just the linear function. Remember, this can be written as basically the transpose of x times t. And if I'm doing this for every combination of weights and inputs, it's just going to just be written as a sum. So now we have this error. This error function e is expressed with the arguments of the inputs. The target's t and the weight is w. So effectively what I'm trying to minimize is the difference between x times w and t. So if t is my ground truth, x times w is my prediction, the correct model is going to be one that minimizes the difference between the prediction and the ground truth. And that's just expressed by this formula here. So inside the summation, every element of t, the target, minus the output of function g for input x of n, this is just going to be the squared error. I'm trying to minimize the squared error. So now we're just back in familiarly squared territory. So of course, I take the error gradient. So now this is going to be the gradient with respect to w, the weights of that error function. Of course, I'm just going to apply that same gradient to the other side of the equation as well. And so then ultimately, if I take the gradient, it simplifies to the thing at the bottom by very pretty straightforward calculus operations. I bring the x-minid 2 down in front and multiply by the base. And then eventually we end up with the formula here. So now instead of summing over all of the samples, if I just take the equivalent weight, then I can update it for the gradient for that sample. So that is one input sample. And then I have some weights that are just at this point arbitrator. And then the input times those weights is going to be some distance from the ground truth. And if the weights are wildly unoptimized, it's going to be very distant. If they're very closely optimized, it should be pretty close. And so I'm going to take that error, and then I can optimize the weights that correspond to that input sample and optimize them with the error for that sample. So the gradient for some sample n can be considered to be basically a noisy sample of the true gradient. So that is there's some true gradient that represents the gradient over all of the samples. And for a single input sample, this is going to be a sample of that entire gradient that is just subject to some perturbation or noise. And so I can take a small step in the direction of the negative gradient. Try to bring the current guess for that weight closer to the actual truth. So for some iteration k, I'm going to have this new value for some weight w. And then on the next iteration, I should have a value for that weight that's closer to the ground truth. And this is called stochastic approximation. So in this case, we have w k plus 1. So this is going to be the value of w at iteration k plus 1. This is going to be the previous value for that weight minus the gradient of the error function. So this is written here. And then for this algorithm to converge, we have some constant here, rho. We want this to decrease the reiteration not too fast and not too slow. So this is the least mean squares algorithm, as is drive by these folks with Dr. Andhoff. This is often referred to as SGD or stochastic gradient descent. So now here's an issue. I have two output variables. Let's say that I'm trying to predict two things about a car from other parameters. Let's say I have a bunch of information and I'm trying to predict what it's miles per gallon and its horsepower is, then this value t sub n is no longer going to be scalar. So to predict two variables, I now need two linear models. So I could do this by changing w, my weight matrix, from a single column to two columns. And so now the first column will contain weights used to predict one value. And the second column will contain weights used to predict a different value. So now effectively, what I'm looking at is if I have my inputs x, this is a matrix that for every sample contains the number of things I measure about that sample. So let's say I have a thousand cars. This would be a thousand rows in that matrix. And if I measure five things about them, there would be five values for each row. And you can assign some meaning to those values. And in the case of linear approximation, those values are pretty interpretable. And then I have some weights that I'm trying to solve for that will multiply by those inputs that I'll predict a number of other things that I'm trying to predict. So if I'm just trying to predict one thing about each sample, I'm just going to have one column of outputs. If I'm trying to predict two things about each, I'm going to have two columns of outputs. And so then if I have, let's say, a thousand rows and then five inputs for each one, and then I have two things that I'm trying to predict. I'm trying to solve for weights that will take those five inputs and predict the two outputs. And that means that it should have weights that are associated with every output that I'm trying to predict. So I'm trying to predict a thousand things. I should have a thousand different weights. So the linear model in this case would look the same, right? Because I have weights that are just a matrix W. And as long as those matrices are the right shapes, they'll multiply together and I'll get the expected number of outputs. And so that's just one of the advantages of using matrix math, is that if I just take that input vector and then then take the dot product of each of the two columns or n columns of W, then those resulting values will be the predictions of the items that I'm looking for. And now I just have to optimize those weights to predict both things at the same time. Now, you think this is going to take longer, shorter, at the same time as predicting the weights to predict one value? Who thinks it's going to take the same time? Longer? It will take longer to converge to the same level of error. And that's because if we have two things, like if MPG and horsepower are not very closely correlated in those the two things we're trying to predict, then I'm trying to optimize those weights at the same time. So it will take a little bit longer. But the formula is pretty much the same. So what do we do to the update formula in order to make this happen? So we have to modify W to be the right shape. And then also for every sample, for every input, we have to specify the two target values. So this T sub n here, this is also no longer scalar. Now this is two values in a vector. So now I have to note this is bold T sub n. So now instead of a single value, I'll have some number of output samples I'm trying to predict. And that's just going to that will be an arbitrary number just based on whatever it is you're actually trying to predict. And so now to update the weights, you have to multiply each error by every component. And this sounds like you would take a double loop. So in the last equation, we use matrix math and numpy. And we did this. This operation can be done using broadcasting. We'll see the code shortly. If I use numpy broadcasting, then that allows me to remove the loop over all the components in X and W. So now if I use broadcasting again, then I can remove a loop over the target output. Right. So now, yes. And here is referring to particular samples. So if we have usually the number of samples would be denoted as big N. So if I say I have a thousand samples, that's rows in my matrix. And so I say big N equals one and then sub N is referring to an arbitrary individual sample. Okay. Any other questions? Okay. So right now, just operationally, if I'm trying to effectively scale up to an arbitrary number of inputs and outputs, this naturally means we're going to have to scale up to the output. We're going to have to scale up to the number of weights. I want to avoid doing things like having for loops. There's a number of reasons for that we'll discuss in a moment. And so I can use the functionality provided by numpy broadcasting to effectively remove those for loops. So if I use it to say remove the loop over the target components in T, as long as your matrices are the right shape, then the resulting matrix will be the correct shape for W. And so here, if you've all the convention that the vectors are column vectors, then the new weight update at iteration K plus one will be the previous weight at iteration K. And then plus some scalar value times those inputs, except of N. And then what is this last term here represent? This is the gradient for the error, right? How far is to how wrong am I so that you can think of it this way? So the model is always going to make a prediction and you want to measure how wrong your prediction is. And the amount of wrongness will tell you how much I need to update my weights. So if I'm really wrong, then making a very, very small update in my weights is maybe not going to get me very close to the actual value. But if I'm very, very close, I don't want to update the weights by too much or I could sort of skip over that local minimum or the global minimum and just end up at some other so often location. Right? Okay. So if row here is a scalar, then the input would be D plus one by one. So this is going to be D dimensions. That is how many things I'm measuring about my sample plus one. Because does it remember from last time? What's the what's the one here referred to? Well, it has that effect. It's not really why we do it. Yeah. Yes, that's that's it's the bias. I haven't really talked about the term yet. I'll talk about that in a moment. But remember, we have we're basically taking weight times input plus weight times input plus weight times input. So we have w zero plus X of zero plus w one times X one plus w two times X two until we get to W n times X n. It makes things a lot easier if I assume that there's going to be some place that I have to basically shift my shift shift my curve. Right? So it may not necessarily intercept the y axis at zero if we're talking about say just a two dimensional curve. And so it basically the math works out much better if I assume that that X of zero value is one, and so then I can multiply by some weight associated weight value. And that allows me to do the entire operation as a matrix because it's basically a sum over every weight times every input. So one is like zero. Yeah. Well, one is like the constant. One is the constant. This will get multiplied. This is this is the the feature that will get multiplied by weight zero. And so effectively, we'll talk about this in a minute, but effectively this is a dummy feature that contributes no real information, but can be useful in optimizing the weights. So your input should be of size d plus one. So the number of dimensions per sample plus this constant one. And so then T sub n will be K by one for K being the number of things I want to predict the number of outputs. And so the transpose of that will be one by K. And so then if this XTW is also one by K, then I can I can effectively subtract those and I'll get meaningful information. Right. And so if I string these together in the calculation, this will give me D plus one by one times one by K. So these two inner values, this should cancel out. And so this should give me a D plus one by K matrix. And that's the shape that we want that weight matrix to be. Questions. Concerns. Okay. So in Python, if you look at the implementation, you can see that effectively this is the same as this part here. So I assume everybody knows Python syntax. I take some value for W, I'm going to update it plus equals row. That's our value here. And then times X one. So the X one is going to be my inputs with this column of ones that I append every sample. And I'm going to take, you know, basically one of these samples, transpose it and then multiply that by T for that that particular sample and then the predicted value, whatever the output of my function should be. So the non matrix way of doing this would look like this. So if I have the number of outputs would be my target shape. I'll take the second element of that element number one, and then number of inputs will be X one, take the shape of that. And then for every, every element of an outputs, then for every element of an inputs, I will then update the weight W sub I K for basically the way the corresponds to for that input for that for that output, plus the update function. Okay. So more lines of code generally lead to more potential for bugs. And that's something that you want to avoid. So we prefer to do this the matrix way. And so that way you're either doing everything right or you're doing everything wrong. If you're doing everything wrong, it will become obvious and you can fix your operation. So hopefully this is motivated, you know, couple of things. One, why we use matrices for these types of operations to the different components that we go into computing an error update. And three, the intuition behind trying to minimize the rate of change in your gradient. So hopefully at least have some, some, some idea of, well, that all those things are important and why they matter. Any questions before I go on to the example. Yeah, your notebooks are available. These notebooks, yeah, these notebooks will be here on. So this one, if you click there, get you to it. Any questions? Yes. That's one, that is one technique that you can use. So row here will correspond to something called a learning rate. And this can be a constant or it can be changeable. And so it depends on your use case, basically, you can start with a very high learning rate and decrease it as time goes on, or you can assume that I'm just going to specify a constant learning rate. So it, you can do that if the use case is appropriate, you don't necessarily require to. Okay. All right. So an example of SGD in action. So let's actually see this actually executed over some data. The data is not necessarily going to be meaningful, but we'll see exactly how the update works. We will also do a little animation so you can kind of see the line that we're trying to fit to this data actually be shifted and moved and rotated in real time. So remember, this is basically an affine transformation. So effectively, I take a line and I can rotate it, I can stretch it, I can move it up and down. But the things that are co-linear in the input should be co-linear in the output. So there's going to be a limited number of things you can actually do with linear regression, but it's always a good first step to try. So we'll just make some random data. In this case, I'm going to have 100 samples of random values between 0 and 10. And then I'll assign the target to be some function, the output of this function here where epsilon is just a bit of noise, sample from a normal distribution. So that can be done here. So here are my 100 samples. I will take my inputs and create random values from uniform distribution between 0 and 10. I will create this into an n sample by one matrix. And then I will apply this function to create t. So basically 2 minus 0.1x plus 0.5, the quantity x minus 6 squared plus epsilon denoted here by just this sample from a normal distribution. What is np.random.normal? This derives random samples from a normal Gaussian distribution. And so we'll have a default mean. What is used at the, has default mean as 0 default standard deviation of 1. In the above example, we're using standard deviation of 0.1 because we don't need that much noise. So I do this and this doesn't look very good. Right? Just a little pie plot thing. Be careful exactly how you're plotting your data. So by default, it'll connect everything with a line. But remember that the inputs are generated randomly between 0 and 10. They're not generated in order. So it's going to basically connect these points in that random order. So instead, I will just plot them as points using the period. So here's my input data. And it's just some random samples between 0 and 10. Then I apply that function to generate the outputs and we get this sort of curve that looks kind of like the Nike swoosh reversed. Okay. Do you think we can fit a linear model to this data? Who thinks yes? Who thinks no? I mean, it's kind of a trick question. You can. It's not going to be a great model, but you can do it. So let's actually go about that. The first thing we're going to do is we're going to take that input matrix. So remember this was created up here as x. And I'm going to include this initial column of a constant 1. So now I will take my x insert at 1 at the front and we'll call it x1. Where do I put that constant column of 1s? Actually you will see that vary across implementations. And in fact, I do it differently in my two classes. In this class, I inserted it at the front. In NLP, the code is written such that we inserted it at the back. It doesn't really matter as long as you know where that constant column of 1s is so that you're updating your bias weights in the right place. For this class, we will be fairly consistent and we will be inserting that constant column of 1s at the front. So your data always consists of your input value. So this will be the sample, which is x or x1 at the bias, and the output values, which are the targets t. So let's make sure that we have the right number of inputs and targets. This is a little correct. 100 by 2 and 100 by 1. That should be. So we have our targets. There should be 100 outputs that have them arranged in a column. And then here I have my 100 inputs, which are just single numbers, except now I've added this constant column of 1s. So now that's 100 by 2. Okay, so learning rate. So that's that row that we saw earlier. So I'm going to specify it to be some small number. So in this case, I'll do .001. And then I need to make sure that the, you know, I get the number of samples. So this is just going to be the number of rows in my input. And so I can just save that out as into a variable that I can reuse. So I'll initialize the weights to zeros. And so here I will train for however many epochs. In this case, I'll do 1000. So basically an epoch where sometimes pronounced in epic. I've observed this to vary between mostly UK and American English. I believe I'm actually saying it the UK way maybe. Anyway, that's basically number of, in this case, a number of passes through the data set. So when you get to more complicated models, we have things like batch size. And so there's a difference between like step and an epoch. But effectively, when people talk about this, just consider passes through the entire data set. So when you have like a huge data set, say a big language model that you're training on, you may hear like, oh yeah, we trained chat GPT for 40 epochs. So you're like 40 epochs doesn't sound like a lot. But remember how much data that's being trained over. First of all, it takes forever. And also that sheer amount of data is contributing so much information every pass through it that you only need 40 epochs or whatever to converge. So this is when we talked about neural nets, this is one of those hyper parameters, things that you can vary that you have direct control over in the process of training your model. So let's step through this code. So if I train for 1000 epochs, I'm going to make a prediction. That prediction is why, right? So why is now going to be one sample? So let's say I'm doing N for range and N samples. I'm going to get the Nth sample, multiply it by the weights W. So that should give me some predicted value for this input sample according to whatever these weights currently are. So now I have the target. And so this T should correspond to this input. So this should be the ground truth target of whatever these inputs should are intended to predict. I'm going to take that and subtract Y, the prediction that I made. That's the error, right? How wrong am I? There's the difference between the predicted value and the target value. And so then I'm going to update the weights by a fraction of the negative derivative of that square error with respect to the weights. And so that's this learning rate. That's the row. And so now here, this is going to be the input transpose times the error value. So and then when I'm done, I will print my weights. So try that. And we end up with these two weights of 3.125 and negative 0.264. So now this should give me effectively a weight that corresponds to the input feature and the second weight corresponds to what? Sorry, other way around. This way corresponds to the input feature and this first weight here corresponds to what? The bias, right? So sorry, for momentarily forgot where I put the column of ones. So now that bias is this is this basically this is the y intercept. Right? So the bias is what do I assume about my model if I have no other information? So basically, if my input contributed no information, what's the best starting point that would minimize my distance from the actual data? That's the bias bias in a technical sense. This would be how we're using it in the class, although at the end we will talk about bias kind of in the colloquial sense. The way you can think about it is this bias is, you know, we think of it as a prejudice. It sort of is if it's like what do you what conclusion you're going to leap to about something if you have no other information? Right? It's you prejudge something that's your prejudice. I gave this example of if I if my going sometimes I see someone wearing a backwards baseball hat, I assume that he's a jerk. But I don't know anything about him. But I see someone walking down the street and I just looks like a real loser. And I gave this example in my first NLP class. I'm looking in front of me and there was a guy wearing a backwards baseball cap. Sorry. I've since taken him on as a research student. I have observed he hasn't worn it back to her baseball cap since. Not going to be too much into that. Could be not a trick. We got a great paper out. So I'm. But basically this is like and I don't actually think that about people who are backwards baseball caps. I'm just an example that I happen to notice there was someone in front of me. But basically that's your that's your that would be like a prejudice or something that you would assume. And then once you get to know the person or the sample, right, you actually know like these. These are the other ways that I need to be. I need to be calibrating when I'm when I'm deciding things about about this phenomenon that I have encountered in the most abstract sense. But at this point of biases, basically, if I know the information of my model, if all my other features are zeros, for example, what's my best starting point? And so that's the bias and that corresponds to effectively there's a dummy feature this one that we train that way against. Yes. The. Yeah, great question. So there is there's a whole lot of research into how we do this hyper parameter optimization for neural networks. Effectively, a lot of people will just be using trial and error. And so in this class, that's mostly what you're going to be doing. There are some techniques you can use like say grid search, you can try out a bunch of different values of different, you know, say different training lengths and see which one of these is giving me the least error. And then maybe I can try and narrow down exactly what that sweet spot is. But it's actually especially when we come to deeper neural networks, there's like just a whole lot of research and how can I optimize all the different hyper parameters that I'm trying to deal with because it's not just epochs here. Well, here is just epochs, but it's not just epochs in broader use cases to have things like the batch size, the number of samples that you could pass through at each time. The learning rate, you know, so, for example, the trade off between training number of epochs and the learning rate, right, that can be directly proportional in fact, or is something inversely proportional. So if I take a smaller learning rate, I might train for longer and get a better result. Or if I were to take a larger learning rate, I could maybe get away with training for less. So there's no like this definitive answer, but it's an area of experimentation. Yeah. For assignment plus for like research. You will need to loop them manually if to do grid search. At least there's one assignment where you have to experiment with a bunch of hyper parameters. And so for that, you're basically given code that does it for you. You just have to fill in like what numbers you want to try. For like your project and stuff. Yeah, you can import whatever libraries would help you. I'm not going to try and make you write all the code by hand for that. But for certain assignments. Effectively, you're given starter code and you cannot modify outside of certain places. Other questions. All right, so we train this model and this is effectively doing y equals and x plus b in two dimensions at this point. And so now I'm going to see how well this linear model fits the data. So I can just do this by plotting the model's predictions on top of the actual data. And this is The, this is our prediction. So the blue dots are data, the red dots are prediction. And so here you can see this x one map model w that's that prediction value again. So what do you think? Not It's all great, I guess. Let's actually see what happens as we're doing the optimization over those thousand epochs. So I can actually Write this code that will basically run an animation so you can see where that line is as it's processing every sample. So in this case, what I will do is initialize all the weights to zero. And then I'm going to collect the weights after every update to plot them. This isn't just part of training. This is just part of visualization. And then I'll create a bunch of x values and then for every Every pass through all the samples. I will update my weights and then we'll plot the line for those input samples across the actual inputs. So you can see the prediction. So let's go. And so now you can see the black dot. That's the last sample that was just trained on the line is the current state of the model. And then you can see also how those values of w zero and w one are changing over time. Right. So, you know, you can you're free to adapt this code to do animations and we'll do we'll have some examples of these in other notebooks. But eventually we can just run that again and we can see how the line just starts. They kind of pretty much wildly opposite the general direction of the data and then eventually we can see, you know, it's being that that wire intercept is moving up toward that three point something value. And then it and then we can see the data. And then we can see that the the slope of the line is also decreasing. And so you can see that those values are getting close to these two values here. Right. So the the approximate wire intercept is just shy of three and then the slope of the line is like slightly negative. Right. So that makes sense. I hope. Well, pretty quick. Okay. And so now we can see also those those values that I'm sort of I'm going to qualitatively evaluating based on just looking at this line are being plotted here. So again, w zero ends up just short of three point oh and then W one is in this case, it's just a little bit below 0.0 or negative point one and five. Okay, so all this is to say that matrix multiplication is basically just solving systems of equations. Right. So I have a bunch of inputs and I have some output corresponding to them. And I have a bunch of these different samples and I'm trying to optimize for the values that solve that large system of equations. So to give a simple example, we can solve a pretty simple system of equations here. So if I have a four X minus three Y equals 17 and then X plus four Y equals nine. I'm trying to solve for the value of both X and Y and I assume that you have done this probably in like high school algebra class. So one way we can do this, the way that you may have learned is just through substitution. So I can solve for X at first. I can solve for X at first and I'll say, okay, if I solve for X using the bottom equation, I ended up with X equals nine minus four Y. Okay. And so now I can take this value that is solved for our solve for Y and or X in terms of Y. And then I can take that value and substitute back in for the value of X and the top equations. Now I have four times the quantity nine minus four Y minus three Y equals 17 as a top equation. So now if I expand this out and end up with 36 minus 16 Y minus three Y equals 36 minus 19 Y, which is equal to 17. So if 36 minus 19 Y equals 17, then I subtract 36 from both sides. I have 19 Y equals negative 19 Y equals negative one. Now I can take this value for Y substitute back into any one of my equations to solve for X and it turns out that X equals five. So this way, allows me to solve the system and I end up with two values for X and Y of five and one. But we can also do this with matrices. So the way this works is effectively the coefficients here in front of the two values I can just plot as the inputs, right? And then the values on the right hand side of the equal side, those are the targets. So I basically have some sample four and some sample negative three and then I have some sample one and some sample four. Right? So these two constitute one input. These two constitute another input and then the corresponding outputs are 17 and nine. And so if I solve it this way, so let's say I have my input X and I'm trying to solve for the values of these coefficients here X and Y, I can do this by taking the transpose of X and multiplying it by T and this should give me something close to the expected value. So let me make sure I run everything. And if I do the inverse function here, I end up with five and one. So pretty neat way of solving systems of equations. Using matrices we and we can demonstrate that we're getting the right values comparing to another method that we were already familiar with. We can also use least squares. So this is where we're trying to least square solution. Remember, we this function returns a few different values. So just to make sure that we get the right values. So we're going to look at W residuals the rank of the matrix and S. If we just look at W, so those are the ways we're trying to solve for it also gives me five and one. Okay. A couple of questions. You know, what are residuals. So from the doc string basically if the rank of a is less than n or m is less than or equal to n, this is going to be empty arrays. That's what we get here. There are no residuals. And so now if I print the shape, the rank of matrix X and then the shape of X and T and then compare them, we can see that. A is not less than n, but M is less than or equal to n. And so that's why the residuals are empty. What are residuals. Okay, so here is the definition in a nutshell of errors versus residuals. So the error is going to be the deviation of the observed value from some unobservable true value of a quantity. Whereas the residual is going to be the difference between the observed value in the estimated value of a quantity. So in this simple linear example. These don't really apply on that is we get exact values and we know what our true values are and they're also the same. But the prediction step is basically X transpose times T to solve for W. So if T contains an exact values. Or the values that correspond to X don't linearly predict T, then the best you can do is some form of approximation. So we have residuals in larger neural networks and also working with more naturalistic data. Sometimes a residual is better than an error because it allows you to optimize for the approximation. All right, so in the last part we're going to play with some real data. And so basically, if you want a hint about how to do assignment one, you're going to want to refer back to this section because we're doing doing some very similar things just the different data. So first we're going to use this automobile data set from this UC Irvine machine learning database repository. So there are two things auto data or auto dot auto and auto data. So autompg dot data and autompg dot names. So let me download those. So now look at the data first. So this is the first step that you're going to want to do before beginning any experiment. Is to actually understand how your data is set up. And so every, every data set that you download is going to be represented slightly differently. You need to understand that how the data is represented and how it's organized before you can really make any progress. So let's take a look at the contents of auto dash mpg dot names. So you'll find that there are 398 samples and each of them has these eight numerical attributes and a string. So the names those attributes are going to be the MPG. It's going to be continuous value. Number of cylinders, which should be a multi-valued discrete displacement and horsepower and weight and acceleration are all continuous values. Model year is going to be a multi-valued discrete right just just on years. Origin is going to be a number corresponding to some in this case country and the car name is a string. So this just allows you to look it up. So first thing you want to do is import it into Python and look at it. So we're going to use the pandas package that you all are should be familiar with. Generally, in this course, import numpy, import high plot, import pandas and later assignments import torch should get you pretty much everything you need with the exception of like, you know, sys and OS and the some other system level Python packages. But generally those four should cover everything that you need where where the difference you will be notified of that. So let's take a look at some of the lines and figure out how to read it in. So just a note in this in this notebook there are two cells, one for unique systems and one for Windows systems is the man is slightly different so depending on if you're running the notebook, depending on which system you use you're going to run one or other of these of these cells, since using a Mac will use the Unix version. So here's our data. So let's look at say the first 40 samples. Let's take a look this remember remember what those values stand for. So 18 miles per gallon eight cylinders, displacement of 307 horsepower 130 acceleration of 3504 model year of 12 this is or. Oh, sorry, the weight. Yeah, weight of 30 seem like a lot of acceleration weight of 3504 it's a very fast car. So 12 model year 70 in this case, 19xx so 1970, and then one in this case corresponds to I believe the options are us Germany or Japan. And then so one here corresponds to us, and this is a Chevy Malibu. So that's how the data is organized it's not necessarily the, the most friendly organization, but you can do some things to make it more readable. Also you'll see that there are some na values here. Right so in this case there are some cars in this data set that for example we don't have the MPG value for. Right, so we're gonna have to handle that, and there may be any values in elsewhere in other columns. So, for example, I think it's maybe. Yeah, so one is us to is at least Europe, and then three is is Japan or Asia, more broadly. So, let's load this into a data frame. And here's what we get and this is not friendly at all. Right so, first of all, a couple of nasty things one it just read in the first column is the header. We don't want that. And then it also read everything in in under the in a single line. Right so we have to format this a little bit better. So, the pandas out reads CSV Dock string will basically tell you all you can do in pandas, or you can read through this pandas tutorial. But we're going to just go to format this it's a little bit easier to read. So I'm going to pass in header none so they don't get that first row as the header, and then I'm going to do limiter set white space as a limiter. So now I get a nice format. So now I can actually get a nice looking data table. And I have my values in the first seven columns and then the name of the car in the eighth. You can see I also have 406 rows, nine columns because they have this one index column here. So take a look at just a subsection here. So if you look at rose 30 to 39. I see a couple of things. One, there's some any nans here. So this is going to mess things up so I need to get rid of them. So here, I can just do this by setting any values equals question mark. So now if I load this again. Let me look at, I can't see any change here but I did know that there were some nans in rose 30 through 39. So let me look at these again. So now let me do this drop in a and so now I have 396 rows or 392 rows. So it got rid of about 10 rows or so that had unfriendly values. So now let me look at that same sample. And I still have that na. Well, something didn't quite go right here. Any, any ideas. The name was removed in a specific place, but not in the data frame. Yes. It didn't happen in place. So I did that and then return that but it didn't modify. Right, so I did, I said I did df dot drop na, but I didn't I didn't actually we save this into df so I'm basically doing df. I walk and so it didn't do that in place so the drop in a function is not by default in place. So now if I do df dot is na dot some, this will tell me you know how many na values do I have in each column. Right, so there are eight and column zero and six and column three. So now if I don't do it in place if I do df equals df dot drop na, and I look at that same subset. Okay, now it looks nice and clean. Right. And so now if I run df dot is na dot some, these are all zeros. So this is what you want. This is one way to make sure that you have no NANDs in your in your data. Okay, so if you run into difficulties with pandas, I recommend this reading the tutorial. Some things to note if you're not familiar with pandas, but you are familiar with numpy, the way that rows and columns are handled in numpy versus pandas are different. And so it can be kind of frustrating and I personally like whenever we do a paper and I'm working on stuff. If it involves pandas, I usually spend like an hour trying to figure out like what I'm doing wrong with pandas. So just fair point, you know, if you start working with this, do allow time to figure out what the errors are and make sure that you are processing your data correctly, especially if the data is a large set that you can individually examine every row of. Okay, any questions. Yeah. Numpy pandas, pi plot and torch. So, and you think we should import those for everything or we should pick up one of those. Um, you will always you will always use numpy for this class in the in the code you're given usually the standard imports that you need. But just if you're, this is mostly for the people who would like to import like your favorite third party package that like no one else has ever heard of. I'm just telling you, those four will get you everything you need to do is no need to get fancy. And it's an even torch like we're probably not going to we're not going to use that until a lot of assignment three I think. Yes. So that you converted man values to a question mark that just make sure that they're not done. So you can just do this if you look at the the read CSV doc strings will tell you like what all when everything does. So basically, did it. Where is it. No God's lost up near. So, I'm going to use so additional strings to recognize as Nan. So like if there's if there's a question mark in the data set. It might just be like someone mistyped something that they don't have the value. So basically I will just I'll turn that into a man, and then I can remove it. Okay. Okay. Other questions. So one step to doing any kind of data processing is examining the data the next step is going to be to visualize it. So one thing we can do is you can spot the value of every attribute in a separate graph. And so I'll make an array of columns, column names to label the y axis. So instead of doing zero through eight. I'll just use these with some meaningful values so I'll set the names of those different parameters and PG cylinders, etc. So now if I set DF columns equals names and I print the data frame again. So now I can actually see what every column corresponds to I don't have to keep referring back to that list above. So again, easier to present easier to interpret so don't neglect these preprocessing steps because it will save you a lot of time. It takes more time up front saves you a whole lot more time at the end. Okay, so now if I just do DF dot plot. Well, that's not terribly helpful is it was a couple of reasons why one, one big one. What are the numbers? Right, right, weight isn't pounds. It's like it's between you know 2000 to 5000 pounds. These are cars. So of course I'm calling these raw values, but I'm looking at weight 3500 versus year 70. I'm not going to be able to tell which one was made in 1970 versus 1971 I can't even really tell, you know what the displacement values are. So, I want to separate these out. So, take a look at everything except the car names I can just look at, you know, the basically see the different ranges of the different values, and already I can absorb even though there's some missing values here because there are nine columns. I have things that range from 70 to 82 and then also things that range from like in the hundreds to the 300s. So, if I look at the type of my value they're all folks 64. Okay, I can work with that. So now I can plot every data column separately and use this code here. So I can plot all of my different samples kind of nicely side by side using subplots. And so I'll plot the sample number on the x axis, and whichever parameter value is on the y axis. So, take a look at these charts and tell me if you notice anything interesting about these about these samples. What sticks out to you about this what relationships you see between the samples and the different parameters. Yeah. So, it's ordered by years we have this like step function here. Anything else. It's all for young get better over time. I think so yeah because like it's ordered by year and we can see that as if we can use this the sample numbers are proxy for time. We can see that MPG seems to be getting better over time. What else do we see. Yeah, of course, power tends to be decreasing. That may be a slight correlation. So, a couple of the things you might be able to observe. The first observation though that you have to make is that the sample number is ordered by year. Otherwise, if you didn't have this this one in the bottom left, you don't know what order user right. And so, now that I can see this, I can draw some conclusions based on what I know about cars we know that auto technology has gotten better over time and so a car that was made in a later year is probably an average going to have a better miles per gallon than it made early. So, yeah. Anything anything else that seemed interesting about these. Yeah. What's the common to me. You're basically. People have their life. Well, we don't really know. I mean we want to look at we need to look at the data kind of an aggregate so just from looking at the individual graphs. The first thing that we can make is that they're ordered by time and so that can tell that can give us some other intuition about like what things are correlated with time but we don't see things like how does horsepower correlate with displacement or miles per gallon. Yes, in the corner. Yeah, displacement is decreasing over time so like some of these things seem to be correlated with time, but we don't know are they really correlated with each other. Right. Is it that cars are getting heavier or what's just any correlation with weight. Yeah, our car is getting lighter over time and is that correlated with is it really the weight of the car that makes the the horsepower go down or the displacement go down or it's not going to be something right as opposed to the year. So plotting displacement as a function of year may not be all that meaningful when really the dependent variable is something else. Okay, so let's try to predict one attribute, namely miles per gallon from the other attributes. So, first we're going to make a 392 by one column vectors that's going to be the target values containing all of those MPG values, and then a 392 by seven to hold all the other values. So I have these eight samples and trying to predict the value in this graph from the other ones. And so that this can tell me whether MPG is correlated with any of these other things we observed is correlated by year. One thing we can do with this knowledge we can see whether our model is making some of the same intuitive judgments that we are. And if it is, then it stands to reason that it's other predictions can probably be believed. So, let me get the target values this is going to be stored in T. So I'll just print all of those. So these, this is the MPG data for every car in my data set. And now give me the input variables. And so this is the, these are all those other seven values. Let me just check my shapes to make sure that they are what I expect so I expect 392 samples. I have seven inputs associated with every sample now in a single target value. All right, so now let me make sure that I have the names associated with the right values so I want MPG to be my target name, and all the others to be my my ex names. So now let me see if a linear model makes some sense. I can do this by plotting the target value MPG versus each of the input values. All right, so now take a look at this. And this is miles per gallon in terms of the other variables. What do you notice here? So say again, the lighter car will have a better. Right. Yeah, so there's a correlation between weight and miles per gallon. So, right, so the lighter cars here have higher MPG. What else do you see? Yeah. Yeah, so the cars with greater displacement have little miles per gallon, which might suggest there is some correlation between weight and displacement. Right. What else do you see? Same with horsepower. So we see basically similarly shaped curves. So let's look at the weight, displacement and horsepower relationships with miles per gallon. So these are the, those are some of the continuous values. Any correlations between some of the other ones and miles per gallon. Yeah, so, well, there should be. Yeah, here. So is there, is there, is it an inverse relationship or a positive relationship? I would think of being positive. Yeah. Yeah, so I do not know. Some weird things happened in 1981. So I heard this guy called Ronald Reagan, right? I would have to look at my history to see if there were like any major deregulations that happened in 1981, the automotive industry. So, it is possible in fact that maybe miles beyond did get worse from 1980 1981. So, yeah, there's literally just recording me just now. So, yeah. And then also a couple of other things to note here. Cylinders right cylinders are a discrete value, we only have three through eight. But there seems to be an inverse relationship between miles per gallon and cylinders. Right. And those of you who know anything about cars that makes sense. Also, Yeah, and so origin also. So the American cars, European cars and Japanese cars. And definitely in the time span that this data was gathered. Japanese cars had a reputation for being a lot more fuel efficient and American cars were like pretty lousy. So there is a correlation between the, the origin of these, according to this coding and the miles per gallon but just keep in mind. So there's a huge arbitrary number that was assigned to each of these categories if it had been if Europe was one America was to and Japan was three what we see would be the sort of e shape. Right, it would not be easy to find to fit with linear relationship to that. So, in certain cases with these like multinomial classification labels, the way you organize your data because very important this one simple change could throw off the entire linear model. Okay, so let us, yes. Yeah, so you could I mean the first of all, with multinomial inputs, a linear model is always not is like not good anyway. It just so happens that the way this data set up there is a linear relationship that this could be a helpful feature. But in most cases this is not. So if you any sort of language work, right if you how do you represent word as a number of a one technique would be to have a big one hot vector for the size of my vocabulary, and if a word exists I have a one in that space. What that means is that every word is orthogonal to every other word, and I have no way of telling if cat and dollar more similar to each other than cat and truck. Right. And so that's the way that you organize your your inputs and the way that you represent your inputs using more sophisticated techniques can be very important. Alright, so in the last 15 minutes, let me finish this example. So we've observed some linear relationships between some of these parameters. And these seem to make sense, given you know what we know about cars even if we don't know very much. So, now that this seems like this. So these relationships that could be useful. Let's build a linear model. So first let's tack on this column of constant ones to the left side of my inputs. So now this will take care of that coefficient multiplication with w zero. And so you just do this using NP inserts and the inserts to basically the array where you want to put the new value, the value that you want to put it on and then access so the access that you want to be computing over. So here I'm just going to transform x into x one using that command. So now I have a 392 by eight array. If I look at say a couple of samples the first three samples. It's now represented like this. And so it's in exponent notation here but you can see that the first value is a one now for everything. So we'll add the name to the X names to the constant column. We call this the bias weight so we'll add bias to our names is to now if I were to show this in the data frame, my first column should be biased and it should be all ones. That's not very useful, because we know that's the bias, but this will come in handy later when we're trying to interpret the weights in our train model. So we can try to fit the model to all the data and see how accurately we project the mouse per gallon for each sample. But that means this model is going to do really well on this data but if we show it other data, there's no guarantee that it's at all going to fit to that data. It could be, you know, wildly off, or it could fit perfectly we just don't know. So a much better way to avoid this kind of overfitting as we call it is to basically hold out some samples from the training so I'm going to train on a subset of the data and then demonstrate that the model is working by evaluating it on new data that it hasn't seen. So this will work here, because we are reasonably assured that any data we remove will more or less resemble the data it was trained on. But we want to be kind of careful in how we partition that test set from that train set. So one way this could go wrong. What if I just held out all the samples from 1982. Right, or what if there was some weird anomaly in 1981 is Reagan deregulated something. What if I held out my 81 and 82 data and it trained on 7380 and suddenly it's not a good fit for that 81 and 82 data. So we have to be kind of careful about how we select that so how do we partition these joints, these C subsets. So a common practice is to randomly select some portion as the test set, and then keep the rest of the training set. So a typical partition would be 8020. But you know you can you see you see different distributions 7030 9010 even 5050 sometimes if the you know if the data is particularly sparse or particularly information rich. But for the most part you know we'll stick to 8020. So we'll partition our samples into training and testing sets will just deal with the row indices, and then we can randomize those and then take that same selected slice to get those corresponding rows and X and T. So let me calculate the number of samples in the training set. So I've got 392 total. If I take 80% of that and round it it's going to give me 314, then the remainder 78. So if I use an 8020 train test split. I'll have 314 training samples and 78 testing samples and that'll cover all of this, the data that I've got. So now I want to randomly select those 314 rows and take the remaining samples as the training as the testing set. So what I'm going to do is I will just shuffle all the rows. So now I have my rows arranged randomly. And then I will take my end train which is computed previously as 314. And then I'll take that first 314 as the train and the remainder as the test. So now I have, we see we started 40158. So I take those first 314 these rows are going to be be my training data, and these rows are going to be my testing data. So I either disjoint to intersect 1D this should be empty. Okay, so now I have successfully partitioned my training for my testing. Okay, so now I can take those train indices elements of x1 that will be my x train, similarly for T train, and then you know the same for X test and T test. So I have three shapes to make sure that everything looks good. I have 314 training samples 314 targets, 78 testing inputs, 78 targets. Okay, great. So now I can use my SGD loop previously shown to find good weights. So, first thing we're going to do is we'll add a calculation to track the error. So I want to see how quickly this sum of squared errors overall samples decreases. So I'm going to use my weights, that's some of squared errors overall samples should be going down that means I'm optimizing my models toward that global minimum. So, more meaningful is actually the square root of the mean of squared errors to RMSE. This will be a common metric for these regression examples. This allows us to have the units of the error and the same units as the target variables, rather than their square. So I'm trying to predict miles per gallon. I'm trying to know how many miles per gallon I am off not how many miles per gallons mile squared per gallon I am because that doesn't really make sense. Okay, so this allows me to have an intuitive metric that I can then report my results and say I'm I am literally this far off on average. So RMSE is going to be taking all the residuals I'm computing over the training data, or all the errors of the testing data. So here we come back to that residual versus errors. So I don't have any ground truth in my from my test data in my training data so I can use the residuals to compute an approximation. Then I compute their quadratic mean where R is an element of the set of residuals or he is going to be an element of all those individual errors. Okay, so now, let's run this. So in particular, let's look at the tiny size learning rate, and we can try running it again. If I have a train for in this case, what 50 epochs, we can see that this root mean squared error value is in fact decreasing. And this is what I want to see. Right. So 9.77 down from 19.1. If I increase the learning rate or decrease or decrease the learning rate. So we start with a higher value, but we end up or we start with a lower value we end up not quite as optimized right. So we can play around with this learning rate. Let me increase it. But if I make it too big, then we run the problems. So effectively what is happening here is learning rate is too big is I'm there's some global minimum, I'm trying to approach this sort of keep skipping back, back and forth across it. And so I will never reach that. So learning rate is going to be very important hyper parameter. We could also train for longer by trained for 100 epochs instead. And I'm going to see that now I'm getting a RMSE of about 8.2. So let's see what happens with my linear model, which is now just these weight matrices, and I'll use it to predict w for the first four samples, or predict miles for the first four samples. So this gives me some, some values. Remember, these are randomized so let me predict compare them to the actual MPG values. So I'll take a two column matrix, or I can use a for loop to print them. So now it's predicting a value of nine for a true value of 14 a value of 19 for true value of 17 and so on. So it seems to be off but it's hard to tell like if it's consistently high or consistently low. So you can play around with the values of learning rate and number of epochs to find the values that result in the lowest RMSE. Let me print these four samples. So this is just a pretty print version of this matrix above. So let's see how all the tests did and plot the results we can see over the entire test set, how good my model is. So, there we go. Okay, so this is, you know, choose one of these, I would say this is not great. It is consistently low. But I also want to know how numerically how wrong I am so let me calculate the RMSE. Our predictions are about eight miles per gallon off on average. So what we can do to fix this. One thing is to standardize the variables. So, we've discovered that the learning rate has to be really really small to prevent these updates from resulting in man. And this because this is because this larger learning rate when I multiply by these inputs x. This will basically send me back up the far side of that gradient curve. So, is there a general way to deal with this problem. So let's take a look at the different ranges of our values. So I plot the min max of everything. We can see that I have, you know, ignore the bias but things from like three to eight but also things from 1600 to over 5000. So since each input value is multiplied by its own weight, the magnitude is those weights are going to be very dependent on those range of those inputs. So the step size and the gradient descent is going to be very dependent on the range of input values as well. So to minimize this will standardize our variables this means that according to the min max of weights. I just get I want to know like how close my to the minimum maximum values rather than what's the absolute value, and that means that the min max of weight can be rated from like, negative one to one or zero to one, and so can the min max of cylinders or or year or anything else. So we need to do this. So basically what we'll do is we will adjust the range of all those input variables we have a mean is zero and a standard deviation of one. Overall the training samples. And so those values that are most dispersed from means at the highest standard deviation of the set. We don't want to do this with the, with the bias, because they're all ones, you can't compute a standard deviation over a set of constant values. So you want to make sure when you do it when you're doing the homework like standardize your values before you append or prepend the column of ones. And so now also to do this correctly when you're purchasing data into training and test sets. You need to also only calculate those means and deviations using the train set, that you're standardizing the test set to the same range. Right, you might have something that is outside the min max of the train set and the test set, but at least that that value that you standardize it to be meaningful if you're using the same means standard deviations that you calculate using the train set. So then you store the means and standard deviation training data and then use them again. So you calculate the means calculate standard deviations apply those to the train set. And then now I can see that I can, I now have standardized values. So, these should be a lot friendlier for my SGD operation means of the same shape. And then I can also perform standardization using those calculated means on the on the test set. So now, let me try this again and note the much larger learning rate here. And so now the standardized values my root mean squared error is now in 50 epochs down to about 3.3 as opposed to 9. something before. So now I can make my predictions over my test set. And these look like they're a lot closer to those true values. So now let's try it again with test data and plot the results. And this seems to be much better fit. So with standardized variables were much less sensitive to different values of the learning rate. Finally, what's most important what's the most important feature for predicting this with a linear model we can actually see this with an early note is much more difficult, but with linear model we can actually see which weights are correlated or inversely correlated with the outputs. So which of these attributes we used are most important for predicting MPG. Maybe you can remove some if they're not useful. So the magnitude of the weights, we can see which ones are positively or negatively correlated with the output so, for example, the bias is the bias that has no real correlation. So if you look at the, or this is the min max. So look at the ranges, we can see no change in the bias. The, the standardized variables range from like negative 1.5 to 1.5. Let's look at the weights. So these are the weights that are associated with everything. So we can print them according to those different values they're associated with. So, I'll, three minutes left I'll tell you what you observe about these values. So the bias is 23, which is probably pretty close to kind of the average miles per gallon of this data. And so if I know other information 23 seems like a pretty good guess. We see some inverse correlation so for example, we observe that MPG increases with time and in fact, year is highly positively correlated with MPG. And so we also saw that it's a negatively correlated with weight. And so we see a negative weight associated with the weight input. Right. And so, if I had a ton of different variables might be easier to sort them by their magnitudes. So I can do that. And then I can plot them according to which parameter is the most important. So, I'm sorry, so again, no, this is because this is to this is to sort them in just descending order of magnitude. And so then I replot them with the signs here. Right. And so now I can see if I that the weight is very important, but it's got a negative value so it's very important but it's the inverse correlation. Whereas, year is also pretty important, but it's not quite as positively correlated with MPG as weight is negatively correlated. Okay. And so you can look at this data and see what you might expect to correlate with predicting MPG positive weights indicate that this positively correlated negative weights indicate that's inversely correlated. I will do the last bit on Thursday before we get in on the near features, because we have no time left. But thank you and I will see you in a couple of days.